======= README.md ======
# m1f - Make One File 🚀

**Because your AI assistant deserves the full story, not just fragments.**

## You know that moment when...

...you're trying to get Claude, ChatGPT, or Gemini to help with your codebase,
and you realize you'd need to upload 500+ files individually? Yeah, we've been
there.

Or when you're excited about Tailwind CSS 4, but your AI is stuck in 2024 and
keeps suggesting v3 syntax? Frustrating, right?

**That's why we built m1f.**

## The Big Idea 💡

m1f transforms your sprawling codebase into AI-ready context bundles. One
command, and suddenly your entire project – thousands of files, millions of
lines – becomes a single, perfectly formatted file that any AI can digest.

```bash
# Turn this nightmare...
src/
├── components/     (247 files)
├── utils/          (89 files)
├── services/       (156 files)
└── ... (and 2000 more)

# Into this dream:
m1f/
├── project_complete.txt    ← Your entire codebase
├── project_docs.txt        ← Just the docs
└── custom_bundles/         ← Whatever you need
```

## Get Started in 30 Seconds

Works on Linux, macOS, and Windows. Because we don't discriminate.

```bash
# 1. Clone it
git clone https://github.com/franz-agency/m1f.git
cd m1f

# 2. Install it
source ./scripts/install.sh    # Linux/macOS
.\scripts\install.ps1          # Windows (restart your terminal)

# 3. Use it
cd /your/amazing/project
m1f-init

# 💥 Boom! Your AI just became a project expert.
```

## Why This Changes Everything

### The Problem We All Face

Modern software isn't just code anymore. It's:

- 📁 Hundreds of source files across dozens of directories
- 📚 Documentation scattered everywhere
- ⚙️ Config files in every flavor (JSON, YAML, TOML, you name it)
- 🔧 Build scripts, test files, deployment configs
- 🎨 Assets, styles, templates

**You can't just "upload a project" to AI.** Until now.

### The m1f Solution

We didn't just build a file concatenator. We built an intelligent context
creator that:

#### 🧠 Thinks Like a Developer

- Respects your `.gitignore` (because `node_modules` shouldn't go to AI)
- Deduplicates files automatically (why send the same content twice?)
- Handles symlinks properly (no infinite loops here)
- Detects secrets before they leak (your AWS keys are safe)

#### 🚀 Works at Scale

- Async everything (because waiting is so 2010)
- Streaming processing (10GB repo? No problem)

#### 🔒 Security First

- Automatic secret scanning with
  [`detect-secrets`](https://github.com/Yelp/detect-secrets)
- No passwords, API keys, or tokens in your AI conversations
- Path traversal protection (hackers hate this one trick)

## Real Magic: Teaching AI New Tricks ✨

Here's where it gets really cool. Your AI has a knowledge cutoff, but your
projects don't wait. When Tailwind CSS 4 drops and Claude is still thinking v3,
here's what you do:

```bash
# 1. Grab the latest docs
git clone https://github.com/tailwindlabs/tailwindcss.com
cd tailwindcss.com

# 2. Create AI brain food
m1f-init
# Creates: m1f/tailwind_complete.txt and m1f/tailwind_docs.txt

# 3. Get fancy with topic bundles (optional but awesome)
m1f-claude --setup
# AI analyzes and creates:
# - m1f/tailwind_utilities.txt
# - m1f/tailwind_components.txt
# - m1f/tailwind_configuration.txt

# 4. Link to your project
cd ~/your-awesome-project
ln -s ~/tailwindcss.com/m1f/tailwind_docs.txt m1f/

# 5. Blow your AI's mind
# "Hey @m1f/tailwind_docs.txt, show me how to use the new v4 grid system"
# *AI proceeds to give you perfect v4 code*
```

## The Complete Toolkit 🛠️

### m1f

The core bundler. Smart, fast, and secure.

```bash
m1f -s ./src -o context.txt --preset code-review
```

### m1f-init

One command to rule them all. Analyzes your project and creates instant bundles.

```bash
m1f-init  # That's it. Seriously.
```

### m1f-claude

The ultimate meta tool: Controls Claude Code headlessly and automatically
includes m1f's complete documentation in every prompt. This means Claude knows
ALL m1f parameters and features without you explaining anything.

```bash
# Ask Claude to create custom bundles for you
m1f-claude "Create bundles for my React project, separate frontend and backend"

# Claude now operates m1f for you with full knowledge
m1f-claude "Bundle only TypeScript files modified in the last week"

# Advanced project setup with AI-organized topics
m1f-claude --setup  # Claude analyzes your project and creates topic bundles
```

Since m1f-claude feeds the complete m1f documentation to Claude automatically,
you can ask it to do anything m1f can do - it's like having an expert m1f user
as your assistant.

### m1f-s1f (Split One File)

When AI generates that perfect codebase and you need real files back.

```bash
m1f-s1f -i ai-generated-magic.txt -d ./actual-files/
```

### m1f-scrape

Because not all docs live in git repos.

```bash
m1f-scrape https://shiny-new-framework.dev -o ./docs/
```

### m1f-html2md

Turn that scraped HTML into beautiful Markdown.

```bash
m1f-html2md convert ./scraped-docs -o ./markdown/
```

### m1f-research

AI-powered research assistant that finds, scrapes, analyzes, and bundles the
best resources into comprehensive research bundles.

```bash
# Research any topic with AI guidance
m1f-research "the best MCPs for Claude Code AI 2025 and how they function"

# Custom configuration with specific analysis
m1f-research --config research.yml --template academic "machine learning transformers"
```

### m1f-token-counter

Know before you paste. Because context limits are real.

```bash
m1f-token-counter bundle.txt
# Output: 45,231 tokens (fits in Claude's 200k context!)
```

## Use Cases That'll Make You Smile 😊

### 1. Code Review Prep

```bash
# Get changed files from git and bundle them
git diff --name-only HEAD~10 | xargs m1f --input-files -o review.txt
# Or use a code review preset if you have one
m1f --preset presets/code-review.m1f-presets.yml
```

### 2. Documentation Deep Dive

```bash
m1f --docs-only -o project-knowledge.txt
# Pure documentation, no code noise
```

### 3. Architecture Overview

```bash
m1f --include "**/*.py" --include "**/README.md" \
    --max-file-size 50kb -o architecture.txt
# High-level view without implementation details
```

### 4. The "New Developer Onboarding" Special

```bash
m1f-init && m1f-claude --setup
# Generate organized bundles for different aspects of your project
# Share with new team members → instant project experts
```

## Smart Defaults Because We Get You

Out of the box, m1f:

- ✅ Ignores `node_modules/`, `vendor/`, `.git/`, and other noise
- ✅ Skips binary files (unless you really want them)
- ✅ Handles any text encoding (UTF-8, UTF-16, that weird Windows-1252 file
  from 2003)
- ✅ Respects `.gitignore` rules (that wasn't easy ;-)
- ✅ Warns about potential secrets
- ✅ Adds clear file separators

## Configuration for Power Users

After `m1f-init`, tweak `.m1f.config.yml` to your heart's content:

```yaml
bundles:
  frontend:
    description: "React components and styles"
    patterns:
      - "src/components/**/*.{jsx,tsx}"
      - "src/styles/**/*.css"
    exclude_patterns:
      - "**/*.test.js"
    output: "m1f/frontend-brain.txt"

  api:
    description: "Backend API logic"
    patterns:
      - "api/**/*.py"
      - "!api/**/test_*.py" # Exclude tests
    output: "m1f/api-brain.txt"

  architecture:
    description: "High-level project structure"
    docs_only: true
    max_file_size: 100kb
    output: "m1f/architecture-overview.txt"
```

## Beyond AI: Surprise Use Cases 🎁

### Universal File Normalizer

```bash
# Got files in 17 different encodings?
m1f --normalize-to utf-8 --output clean-project.txt
m1f-s1f -i clean-project.txt -d ./clean/
# Boom. Everything is UTF-8 now.
```

### Time Capsule Creator

```bash
m1f --add-timestamps -o "backup_$(date +%Y%m%d).txt"
# Perfect snapshot of your project at this moment
```

### The "Poor Developer's Docker"

```bash
# Bundle on machine A
m1f -o myproject.txt
# Transfer one file
scp myproject.txt user@machine-b:
# Extract on machine B
m1f-s1f -i myproject.txt -d ./project/
# Entire project structure preserved!
```

## Pro Tips from the Trenches 🏆

1. **Start with `m1f-init`** - It's smarter than you think
2. **Use presets** - We've included configs for WordPress, Django, React, and
   more
3. **Chain tools** - `m1f-scrape` → `m1f-html2md` → `m1f` = Documentation power
   combo. Or use `m1f-research` for AI-guided research and analysis
4. **Set up watches** - `./scripts/watch_and_bundle.sh` for auto-updates
5. **Check token counts** - Always know what you're pasting

## Join the Revolution

We're building the future of AI-assisted development. Want to help?

- 🐛 [Report bugs](https://github.com/franz-agency/m1f/issues)
- 💡 [Suggest features](https://github.com/franz-agency/m1f/discussions)
- 🔧 [Contribute code](https://github.com/franz-agency/m1f/pulls)
- ⭐ [Star us on GitHub](https://github.com/franz-agency/m1f) (it makes us
  happy)

## Requirements

- Python 3.10+ (because we use the cool new features)
- A desire to feed your AI more context
- That's it. Really.

## License

Apache 2.0 - Use it, love it, build amazing things with it.

---

**Built with ❤️ by [franz.agency](https://franz.agency) - Where no AI has coded
before™**

_P.S. If you're reading this, you're probably the kind of developer who reads
documentation. We like you already._

======= CLAUDE.md ======
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.
complete m1f doc is in m1f/87_m1f_only_docs.txt

## Project Overview

m1f (Make One File) is a Python-based CLI tool suite for bundling codebases and documentation into AI-friendly context files. It's designed to help developers feed their entire codebase to LLMs like Claude, ChatGPT, and Gemini.

## Core Architecture

The project consists of multiple interconnected tools:

1. **m1f** (tools/m1f/) - Core bundler that creates mega-files from codebases and stores it in m1f/
   - Async I/O for performance
   - Smart file selection with glob patterns
   - Automatic secret detection using detect-secrets
   - Content deduplication via SHA256
   - Multiple output formats and separators

2. **s1f** (tools/s1f/) - Extracts files back from bundles
   - Preserves file metadata and paths
   - Handles various separator styles

3. **scrape_tool** (tools/scrape_tool/) - Web scraper with multiple backends
   - BeautifulSoup, Scrapy, and Playwright support
   - SSRF protection and robots.txt compliance

4. **html2md_tool** (tools/html2md_tool/) - HTML to Markdown converter
   - AI-powered selector optimization
   - Batch processing capabilities

## Essential Commands

### Development Setup
```bash
# Activate virtual environment
source .venv/bin/activate      # Linux/macOS
.venv\Scripts\activate         # Windows

# Install in editable mode
pip install -e .
```

### Testing
```bash
# Run all tests
pytest

# Run specific test suites
pytest tests/m1f/              # m1f tests only
pytest tests/s1f/              # s1f tests only
pytest tests/html2md/          # html2md tests only

# Run with useful options
pytest -vv                     # Verbose output
pytest -x                      # Stop on first failure
pytest -m "not slow"           # Skip slow tests
pytest --pdb                   # Debug on failure
```

### Code Formatting
```bash
# Format Python code (required before commits)
black tools/

# Check formatting without changes
black --check tools/

# Format Markdown files
npm run lint:md
```

### Development Workflow
```bash
# Run tools in development mode
python -m tools.m1f [args]
python -m tools.s1f [args]
python -m tools.html2md [args]
python -m tools.scrape [args]

# Update m1f's own bundles
m1f-update

# Watch for changes and auto-bundle
./scripts/watch_and_bundle.sh
```

## Key Architectural Patterns

### Configuration System
- YAML-based presets in `presets/` directory
- Preset groups for different use cases (code_review, docs_chat, debug_context)
- Per-file settings with extension-specific rules
- AI-optimized presets in `presets/ai-context.m1f-presets.yml`

### Async Architecture
- All file operations use aiofiles for concurrent I/O
- Batch processing with configurable concurrency
- Streaming architecture for handling large codebases

### Security Considerations
- detect-secrets integration for preventing secret exposure
- Path traversal protection in all file operations
- SSRF protection in web scraping
- robots.txt compliance for ethical scraping

### Testing Strategy
- Unit tests for core functionality
- Integration tests for tool interactions
- Security-specific tests for secret detection
- Encoding tests for various file formats
- Test server for HTML2MD testing

## Important Implementation Details

1. **File Processing Pipeline**:
   - Detection → Validation → Encoding → Deduplication → Bundling
   - Each stage is async and can be extended with custom processors

2. **Preset System**:
   - Presets are loaded from YAML files in `presets/`
   - Support for inheritance and composition
   - Can define file-specific rules and global settings

3. **Output Formats**:
   - Multiple separator styles (xml, markdown, plain)
   - Token counting integration for LLM context windows
   - Metadata preservation (paths, timestamps, encodings)

4. **Error Handling**:
   - Graceful degradation for encoding issues
   - Detailed error messages with file context
   - Non-blocking errors for better user experience

## Development Tips

- Always run tests before committing significant changes
- Use Black for Python formatting (enforced by git hooks)
- The project uses detect-secrets to prevent accidental secret commits
- When adding new features, follow the existing async patterns
- Presets are the primary configuration mechanism - avoid hardcoding

- The `m1f-update` command regenerates the project's own documentation bundles

======= requirements.txt ======
# Core dependencies
aiofiles==24.1.0
aiohttp==3.12.14
anyio==4.9.0
application_properties==0.9.0
beautifulsoup4==4.13.4
black==25.1.0
certifi==2025.6.15
chardet==5.2.0
charset-normalizer==3.4.2
click==8.2.1
colorama==0.4.6
Columnar==1.4.1
detect-secrets==1.5.0
html5lib==1.1
idna==3.10
iniconfig==2.1.0
markdownify==1.1.0
mypy_extensions==1.1.0
packaging==25.0
pathspec==0.12.1
platformdirs==4.3.8
pluggy==1.6.0
pydantic==2.11.7
pymarkdownlnt==0.9.30
pytest==8.4.1
pytest-asyncio==1.1.0a1
pytest-timeout==2.4.0
PyYAML==6.0.2
regex==2024.11.6
requests==2.32.4
tiktoken==0.9.0
tomli==2.2.1
toolz==1.0.0
typing_extensions==4.14.1
urllib3==2.5.0
wcwidth==0.2.13

# Claude Code SDK for m1f-claude
claude-code-sdk==0.0.14

# Web scraping dependencies
httpx==0.27.2
lxml==6.0.0
playwright==1.53.0
scrapy==2.13.3
selectolax==0.3.31

# Test server dependencies
Flask==3.1.1
flask-cors==6.0.1

# Additional dependencies (automatically installed)
aiohappyeyeballs==2.6.1
aiosignal==1.4.0
annotated-types==0.7.0
attrs==25.3.0
Automat==25.4.16
blinker==1.9.0
cffi==1.17.1
constantly==23.10.4
cryptography==45.0.5
cssselect==1.3.0
defusedxml==0.8.0rc2
filelock==3.18.0
frozenlist==1.7.0
greenlet==3.2.3
h11==0.16.0
httpcore==1.0.9
hyperlink==21.0.0
incremental==24.7.2
itemadapter==0.11.0
itemloaders==1.3.2
itsdangerous==2.2.0
Jinja2==3.1.6
jmespath==1.0.1
markdown-it-py==3.0.0
MarkupSafe==3.0.2
mdurl==0.1.2
multidict==6.6.3
nest-asyncio==1.6.0
parsel==1.10.0
propcache==0.3.2
Protego==0.5.0
pyasn1==0.6.1
pyasn1_modules==0.4.2
pycparser==2.22
pydantic_core==2.33.2
PyDispatcher==2.0.7
pyee==13.0.0
Pygments==2.19.2
pyjson5==1.6.9
pyOpenSSL==25.1.0
queuelib==1.8.0
requests-file==2.1.0
service-identity==24.2.0
setuptools==80.9.0
six==1.17.0
sniffio==1.3.1
soupsieve==2.7
tldextract==5.3.0
truststore==0.10.1
Twisted==25.5.0
typing-inspection==0.4.1
w3lib==2.3.1
webencodings==0.5.1
Werkzeug==3.1.3
yarl==1.20.1
zope.interface==7.2

======= docs/README.md ======
# m1f Documentation

Welcome to the m1f project documentation. This directory contains comprehensive
guides, references, and examples for all tools in the m1f toolkit.

**Current Version: 3.7.0** | [Changelog](99_CHANGELOG.md)

## Table of Contents

### 📚 Core Tool Documentation

#### m1f (Make One File)

The main tool that combines multiple files into a single reference file with
content deduplication.

- [**Getting Started**](01_m1f/05_getting_started.md) - Installation and first
  steps with real examples
- [**m1f Overview**](01_m1f/00_m1f.md) - Complete guide with features, usage
  examples, and architecture
- [**Quick Reference**](01_m1f/01_quick_reference.md) - Common commands and
  patterns for quick lookup
- [**CLI Reference**](01_m1f/02_cli_reference.md) - Complete command-line
  parameter reference
- [**Troubleshooting Guide**](01_m1f/03_troubleshooting.md) - Common issues and
  their solutions
- [**Security Best Practices**](01_m1f/40_security_best_practices.md) - Security
  guidelines and protective measures

#### s1f (Split One File)

Extracts individual files from a combined file with preserved structure.

- [**s1f Documentation**](02_s1f/20_s1f.md) - Complete guide for file extraction
  tool

#### Web Tools

Professional web scraping and conversion tools.

- [**Webscraper**](04_scrape/40_webscraper.md) - Download websites for offline
  viewing and processing
- [**HTML to Markdown Converter**](03_html2md/30_html2md.md) - Comprehensive
  HTML to Markdown conversion guide
- [**HTML2MD Usage Guide**](03_html2md/31_html2md_guide.md) - Detailed usage
  examples and patterns
- [**HTML2MD Workflow Guide**](03_html2md/32_html2md_workflow_guide.md) -
  Advanced workflows and automation
- [**HTML2MD Test Suite**](03_html2md/33_html2md_test_suite.md) - Testing
  documentation and examples
- [**Scraper Backends**](04_scrape/41_html2md_scraper_backends.md) - Backend
  options for web scraping

#### Research Tool

AI-powered research tool for automatic information gathering and bundling.

- [**Research Tool Overview**](06_research/) - Comprehensive research tool
  documentation
- [**Research README**](06_research/README.md) - Quick start and feature
  overview
- [**Architecture**](06_research/architecture.md) - Technical architecture
  details
- [**API Reference**](06_research/api-reference.md) - Complete API documentation
- [**Examples**](06_research/examples.md) - Usage examples and recipes

#### Utility Tools

- [**Token Counter**](99_misc/98_token_counter.md) - Estimate token usage for
  LLM context planning

### 🎯 Advanced Features

#### Preset System

File-specific processing rules and configurations.

- [**Preset System Guide**](01_m1f/10_m1f_presets.md) - Complete preset system
  documentation
- [**Per-File Type Settings**](01_m1f/11_preset_per_file_settings.md) -
  Fine-grained file processing control
- [**Preset Reference**](01_m1f/12_preset_reference.md) - Complete reference
  with all settings and features

#### Auto-Bundle & Configuration

Automated project bundling for AI/LLM consumption.

- [**Auto Bundle Guide**](01_m1f/20_auto_bundle_guide.md) - Automatic bundling
  with configuration files
- [**Configuration Examples**](01_m1f/25_m1f_config_examples.md) - Real-world
  configuration examples
- [**Default Excludes Guide**](01_m1f/26_default_excludes_guide.md) -
  Understanding default exclusion patterns

#### AI Integration

Work efficiently with Claude and other LLMs.

- [**Claude + m1f Workflows**](01_m1f/30_claude_workflows.md) - Turn Claude into
  your personal m1f expert
- [**Claude Code Integration**](01_m1f/31_claude_code_integration.md) - Optional
  AI-powered tool automation

### 🔧 Development

- [**Development Workflow**](01_m1f/21_development_workflow.md) - Best practices
  for development with m1f
- [**Git Hooks Setup**](05_development/56_git_hooks_setup.md) - Automated
  bundling with git hooks
- [**Version 3.2 Features**](01_m1f/41_version_3_2_features.md) - Feature
  documentation and migration guide

### 📖 Additional Resources

- [**m1f Section Overview**](01_m1f/README.md) - Overview of m1f documentation
  section
- [**Development Section Overview**](05_development/README.md) - Overview of
  development documentation
- [**Full Changelog**](99_CHANGELOG.md) - Complete project history and version
  details

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/Karrtii/m1f.git
cd m1f

# Install tools
./scripts/install.sh  # On Windows: ./scripts/install.ps1
```

### Basic Usage

```bash
# Combine files
m1f -s ./your_project -o ./combined.txt

# Extract files
m1f-s1f -i ./combined.txt -d ./extracted_files

# Check token count
m1f-token-counter ./combined.txt

# Download website
m1f-scrape https://example.com -o ./html

# Convert HTML to Markdown
m1f-html2md convert ./html ./markdown
```

### Using Auto-Bundle

```bash
# Create all configured bundles
m1f auto-bundle

# List available bundles
m1f auto-bundle --list

# Create specific bundle
m1f auto-bundle documentation
```

## Navigation Tips

- **New to m1f?** Start with the
  [Getting Started Guide](01_m1f/05_getting_started.md)
- **Setting up automation?** Check the
  [Auto Bundle Guide](01_m1f/20_auto_bundle_guide.md) and
  [Configuration Examples](01_m1f/25_m1f_config_examples.md)
- **Working with AI?** See [Claude Workflows](01_m1f/30_claude_workflows.md) for
  optimal LLM integration
- **Need help?** Visit the [Troubleshooting Guide](01_m1f/03_troubleshooting.md)

## Project Overview

m1f is a comprehensive toolkit designed to help you work more efficiently with
Large Language Models (LLMs) by managing context. Built with modern Python 3.10+
architecture, it features:

- **Async I/O** for high performance
- **Type hints** throughout the codebase
- **Modular design** for easy extension
- **Security-first** approach with built-in protections
- **Cross-platform** compatibility (Windows, macOS, Linux)

Whether you're bundling code for AI analysis, creating documentation packages,
or managing large codebases, m1f provides the tools you need to work
efficiently.

======= docs/99_CHANGELOG.md ======
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to
[Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added

- **m1f-scrape Session Management**: Complete session tracking system for scraping runs
  - Each scraping run creates a unique session with ID, timestamps, and statistics
  - Sessions track status: running, completed, interrupted, failed
  - Automatic cleanup of orphaned sessions (no activity >1 hour) on startup
  - Manual cleanup with `--cleanup-sessions` command
  - Session viewing with `--show-sessions` and `--show-sessions-detailed`
  - Clear specific sessions with `--clear-session ID` or `--clear-last-session`
  - Database migration to v2 with session support (auto-migrates existing DBs)
  - Session statistics calculated correctly at end of each run
  - Graceful handling of Ctrl+C, crashes, and kill signals
  - Long-running sessions (>1hr) not interrupted if still actively scraping
  - Optional file deletion when clearing sessions with `--delete-files` flag
  - Interactive confirmation prompt for file deletion (skipped with flag)

### Fixed

- **m1f-scrape Max-Pages Counting**: Fixed to count only successfully scraped pages
  - Previously counted all attempted URLs including errors and redirects
  - Now only increments counter for pages that were actually saved
  - Ensures --max-pages limit is respected correctly
  - Fixed issue where scraper would stop prematurely at 1001 URLs when more pages were available

- **m1f-scrape Test Infrastructure**: Fixed all 65 scraping tests to pass
  - Fixed test server startup issues by changing subprocess.PIPE to subprocess.DEVNULL
  - Fixed test server canonical parameter injection causing 500 errors
  - Fixed mock configuration for async context managers in tests
  - Fixed ScraperConfig/CrawlerConfig parameter mismatch
  - Fixed Playwright browser_config parameter handling
  - Fixed Selectolax allowed_path logic for start URL handling
  - Updated test expectations to match corrected behavior

### Added

- **m1f-scrape URL Support for allowed_path**: Parameter now accepts full URLs
  - Can use both paths (`/docs/`) and full URLs (`https://example.com/docs/`)
  - HTTrack properly extracts domain and path from URL-based allowed_path
  - BeautifulSoup validates URLs in should_crawl_url method
  - Useful for restricting crawl to specific subdomains or protocols

- **m1f-scrape Python Mirror Scraper**: New fallback scraper for HTTrack
  - Pure Python implementation for website mirroring
  - Automatically used when HTTrack fails or for localhost URLs
  - Preserves directory structure similar to HTTrack
  - Supports all standard scraper features (robots.txt, rate limiting, etc.)

### Improved

- **m1f-scrape Canonical URL Logic**: Better handling with allowed_path
  - Pages within allowed_path are now kept even if canonical points outside
  - Respects user's intent to scrape content within allowed boundaries
  - All scrapers (BeautifulSoup, HTTrack, Selectolax, Playwright) updated
  - Added comprehensive test coverage for canonical/allowed_path interaction

- **m1f-scrape Unlimited Pages Option**: Support for unlimited scraping
  - Changed default `max_pages` from 1000 to 10000 across all configurations
  - Added support for `-1` as unlimited pages (no limit)
  - Updated validation to allow up to 10 million pages
  - All scrapers now handle `-1` as unlimited:
    - playwright, selectolax, beautifulsoup, scrapy: Skip page limit check when -1
    - httrack: Uses very large number (999999999) for unlimited
  - Updated documentation to explain `-1` unlimited option
  - Added example for unlimited scraping with caution note

- **m1f-scrape Advanced Path Control**: New `--allowed-path` parameter
  - Allows starting from specific page while controlling crawling boundaries
  - Overrides automatic path restriction based on start URL
  - Start URL is always scraped regardless of path restrictions
  - Example: Start from `/Extensions/eZ-Publish-extensions.html` but crawl all `/Extensions/`
  - Useful for documentation sites where index pages link to different directories
  - Implemented across all scraper backends (BeautifulSoup, HTTrack, Selectolax, Playwright, Scrapy)
  - Added `check_ssrf` configuration parameter to enable/disable SSRF protection (defaults to enabled)
  - Fixed test server to support subdirectory routing for comprehensive testing
  - Added integration and unit tests with proper mocking

### Fixed

- **m1f-scrape Canonical URL Logic**: Fixed canonical URL handling with allowed_path
  - Pages within allowed_path are now kept even if canonical points outside
  - Properly handles canonical URLs when both current and canonical are within allowed_path
  - Fixed across all scrapers (BeautifulSoup, HTTrack, Selectolax, Playwright)
  - Added comprehensive tests to verify the behavior

### Improved

- **m1f-scrape Parameter Help Text**: Clarified confusing CLI parameter descriptions
  - `--ignore-canonical` now clearly states default behavior (pages with different canonical URLs are skipped)
  - `--ignore-duplicates` help text clarified to explain default duplicate detection
  - Better organization of parameters into logical groups

- **m1f-scrape Test Coverage**: Created meaningful integration tests
  - Real HTTP requests with local test server instead of mocks
  - Tests that verify actual functionality, not just configuration:
    - `test_ignore_get_params_actually_works` - Verifies URL normalization
    - `test_canonical_url_with_allowed_path_real_behavior` - Tests canonical/allowed_path interaction
    - `test_excluded_paths_actually_excludes` - Verifies paths are actually excluded
    - `test_duplicate_content_detection_actually_works` - Tests content deduplication
    - `test_max_depth_unlimited_actually_works` - Verifies unlimited depth crawling
    - `test_timeout_actually_enforced` - Tests timeout enforcement
  - Separate integration tests for each scraper backend
  - Fixed test server to properly handle canonical parameter injection

### Added

- **m1f-scrape Missing CLI Parameters**: Exposed configuration options in CLI
  - `--excluded-paths`: URL paths to exclude from crawling (can specify multiple)
  - `--timeout`: Request timeout in seconds (default: 30)
  - `--retry-count`: Number of retries for failed requests (default: 3)
  - `--disable-ssrf-check`: Disable SSRF vulnerability checks (allows localhost)
  - Note: Respecting robots.txt is mandatory and cannot be disabled

- **m1f-scrape Unlimited Depth**: Support for unlimited crawl depth
  - `--max-depth` now accepts -1 for unlimited depth (similar to --max-pages)
  - All scrapers updated to handle unlimited depth correctly
  - HTTrack uses very large number (999999) internally

### Removed

- **m1f-scrape Scrapy Support**: Completely removed Scrapy scraper implementation
  - Removed scrapy_scraper.py and all related tests
  - Removed Scrapy from ScraperBackend enum
  - Simplified scraper selection logic

- **m1f-scrape Comprehensive Parameter Tests**: New test suite for all parameters
  - Tests for content filtering (ignore-get-params, ignore-canonical, ignore-duplicates)
  - Tests for excluded paths functionality
  - Tests for request options (user-agent, timeout, retry-count)
  - Tests for different scraper backends
  - Tests for database query options
  - All tests use local test server (no external dependencies)

### Removed

- **m1f-scrape Scrapy Backend**: Removed Scrapy scraper implementation
  - Scrapy had different architecture that complicated maintenance
  - Other scrapers (BeautifulSoup, Selectolax, HTTrack, Playwright) provide sufficient coverage
  - Removed from CLI choices, configuration enum, and all tests
  - Simplifies codebase and reduces dependencies

### Changed

- **m1f-scrape Canonical URL Handling**: Improved canonical URL logic to respect allowed_path
  - Fixed issue where pages within allowed_path were skipped if canonical URL pointed outside
  - Pages within allowed_path are now kept even if their canonical URL points outside the restricted area
  - Added canonical URL checking to Playwright scraper (was previously missing)
  - Improved help text for content filtering options to be clearer:
    - `--ignore-get-params`: Now explains it strips query parameters
    - `--ignore-canonical`: Clarifies it disables canonical URL deduplication
    - `--ignore-duplicates`: Explains it disables content-based deduplication

- **m1f-scrape Help Output**: Improved organization with colorama support
  - Added colorama formatting to match m1f's help output style
  - Organized parameters into logical groups (Output Control, Scraper Options, etc.)
  - Added colored error messages for better visibility
  - Help text now renders with proper formatting on terminals that support it

- **m1f-scrape Real Integration Tests**: Replaced mocked tests with real server tests
  - Selectolax now has comprehensive integration tests using local test server
  - HTTrack tests check for installation and run real tests when available
  - Playwright tests verify JavaScript rendering and browser functionality
  - All integration tests use local test server to avoid external dependencies
  - Fixed test server environment issues for reliable testing

### Fixed

- **m1f-html2md Config Structure**: Fixed configuration structure mismatch
  - Config loader now properly handles nested configuration objects
  - CLI correctly maps arguments to `conversion.outermost_selector` and `conversion.ignore_selectors`
  - Fixed prompts that were generating incorrect config structure with `extractor.content_selector`
  - Updated all prompts to generate the correct structure: `conversion.outermost_selector`
  - Fixed output message to show "outermost_selector" instead of "content_selector"
  - Config files now work correctly with proper field mapping

- **Claude Code Documentation Scraper**: Fixed config file usage
  - When using `--use-config`, script now creates backup directory instead of deleting existing markdown
  - Backup directories named with timestamp: `claude-code-markdown_backup_YYYYMMDD_HHMMSS`
  - Ensures existing markdown files are preserved when re-converting with different config
  - Added datetime import for timestamp generation

## [3.8.0] - 2025-07-24

### Added

- **m1f-research Tool**: New intelligent research content organization tool

  - Smart content analysis with configurable templates (academic, technical,
    summary)
  - Hierarchical output directory structure with automatic organization
  - Database-driven job persistence and management
  - Parallelized scraping with progress tracking
  - LLM provider abstraction (Claude, Gemini, CLI tools)
  - Advanced filtering and search capabilities
  - Comprehensive documentation and examples

- **Shared Utilities Module**: Centralized common functionality

  - Unified colorama output system across all tools
  - Externalized all prompts to markdown templates
  - Shared validation and helper functions
  - Consistent error handling patterns

- **Symlink Deduplication**: Intelligent handling of symbolic links
  - Internal symlinks excluded when deduplication enabled (default)
  - External symlinks always included with their content
  - All symlinks included when using `--allow-duplicate-files`
  - Comprehensive test coverage for all scenarios

### Changed

- **Output System Overhaul**: Complete migration to colorama helpers

  - Replaced all `print()` statements with semantic helpers (info, success,
    warning, error)
  - Consistent colored output across all tools
  - Improved user experience with visual feedback
  - Test files updated to use colorama helpers

- **Version Management**: Centralized version handling

  - All tools now import from `tools._version.py`
  - Single source of truth for version numbers
  - Simplified version bumping process

- **Claude Integration**: Enhanced headless operation
  - Fixed Claude CLI to use `-p` flag for headless mode
  - Improved timeout handling (increased to 120s)
  - Better error messages and debugging output

### Fixed

- **Test Warnings**: Resolved all AsyncMock and pytest warnings

  - Fixed AsyncMock usage with proper async functions
  - Renamed TestServer to HTML2MDTestServer to avoid pytest conflicts
  - Improved test reliability and performance

- **Import Errors**: Fixed module import issues across tools

  - Resolved circular imports in m1f-research
  - Fixed s1f module import errors
  - Corrected test file imports

- **Package Metadata**: Updated package.json
  - Fixed description to "Make One File - AI-ready codebase bundling toolkit"
  - Synchronized version numbers across all files

### Documentation

- **m1f-research**: Added comprehensive documentation

  - Job management guide
  - Template system reference
  - Integration examples
  - README for shared utilities

- **Colorama Guide**: Added unified output system documentation
  - Complete migration guide
  - Usage examples
  - Best practices

## [3.7.0] - 2025-07-21

### Added

- **Pre-commit Hook Enhancement**: Added Python (Black) and Markdown formatting
  to pre-commit hooks for better code quality enforcement
- **Script Help Parameters**: All scripts now support help parameter (`-h`,
  `--help`) for improved user experience
- **PowerShell Commands**: Added missing `m1f-init` and `m1f-claude` commands to
  PowerShell scripts and aliases
- **Documentation**: Added comprehensive Getting Started guide for easier
  onboarding

### Changed

- **README Overhaul**: Complete refresh with engaging, developer-friendly
  content
  - Clear problem statement and solution narrative
  - Enhanced m1f-claude explanation as headless Claude controller
  - Added personality while maintaining professional quality
  - Updated tagline: "Where no AI has coded before™"
  - Improved flow from problem → solution → examples → features
- **Project Structure**:
  - Moved `sync_version.py` to dev directory
  - Moved setup documentation to docs folder
  - Removed dev/ directory from version control
- **Installation Process**: Improved installation and uninstallation scripts
  with better error handling
- **Hooks System**: Completed migration to dual hook system for better
  flexibility
- **Presets Optimization**: Removed redundant defaults for better efficiency

### Fixed

- **Presets**: Removed incorrect `preserve_tags` usage with `strip_tags` to
  prevent configuration conflicts
- **m1f-claude**: Fixed attribute name for `--setup` argument
- **Examples**: Improved robustness of `scrape_claude_code_docs` script
- **Scripts**: Enhanced watcher ignore patterns and VS Code task integration
- **Hooks**:
  - Corrected installation instructions in git hooks installer
  - Removed unnecessary venv activation from m1f-update calls
- **Documentation**:
  - Fixed misleading examples and clarified feature availability
  - Fixed incorrect `--since` flag example (doesn't exist in m1f)
  - Simplified and corrected script paths in installation instructions

### Removed

- **Version Management**: Removed version management section from README
- **Version Bumper**: Removed version bumper from repository
- **Advanced Terminology**: Removed remaining "advanced" terminology from setup
- **Cleanup**: Removed leftover files and test artifacts

## [3.6.0] - 2025-07-19

### Changed

- **m1f-claude**: Renamed `--advanced-setup` parameter to `--setup` for
  simplicity
- **m1f**: Ensure cross-platform compatibility by using forward slashes in
  bundle paths
- **Project Organization**: Cleaned up project root directory
  - Moved `perfect_bundle_prompt.md` to `tools/m1f/prompts/`
  - Moved `wp-cli.example.yml` to `examples/` directory

### Fixed

- **Windows Compatibility**: Major improvements for Windows platform support
  - **m1f**: Fixed path separators to always use forward slashes in bundles for
    cross-platform compatibility
    - Bundles created on Windows can now be extracted on Unix systems and vice
      versa
    - Added comprehensive cross-platform path tests
  - **m1f-claude**: Improved Claude executable detection on Windows
  - **m1f-claude**: Enhanced subprocess handling and timeout behavior for
    Windows
  - **m1f**: Fixed npx execution method compatibility on Windows
  - **m1f-init**: Improved project type detection across platforms
  - **Dependencies**: Downgraded httpx to 0.27.2 for better Windows
    compatibility
  - **Tests**: Added cross-platform test suite with Windows-specific timeout
    handling
  - **Installation**: Fixed PowerShell installation scripts and path handling

## [3.5.0] - 2025-07-18

### Added

- **m1f-claude**: Add project description and priorities input functionality

### Fixed

- **m1f-init**: Correct project type detection to use file count for all
  languages
- **m1f**: Support npx execution method for m1f tool
- **m1f-init**: Preserve dots in project names for bundle generation

### Changed

- Updated package dependencies

## [3.4.2] - 2025-07-08

### Fixed

- **Version Conflict**: Resolved version conflict issues
- **httpx Compatibility**: Downgraded httpx from newer version to 0.27.2 for
  improved compatibility
- **Configuration Consistency**: Updated `source_directory` to
  `source_directories` in configuration for consistency
- **m1f-claude Subprocess Handling**: Improved subprocess handling and timeout
  behavior for Claude executable detection

### Changed

- **Dependencies Update**: Updated multiple dependencies to newer versions for
  improved compatibility and performance

### Removed

- Removed unnecessary documentation files

## [3.4.0] - 2025-07-04

### Added

- **m1f-init Enhancements**: Improved project initialization tool

  - Added `--no-symlink` parameter to skip creating symlink to m1f documentation
  - Added file tracking to show only actually created files in output
  - Improved output formatting with "Here is your file:" / "Here are your
    files:" section
  - Added proper spacing and bullet points for created files list
  - Now runs `m1f-update` when `.m1f.config.yml` already exists instead of
    creating default bundles

- **Multiple Source Directories**: m1f now supports multiple `-s` source
  directories

  - Use `-s dir1 -s dir2` to combine files from multiple directories
  - All source directories are processed and files are merged into single output
  - Useful for documentation bundles that need files from different locations

- **Include Patterns**: Added `--includes` parameter for pattern-based file
  filtering
  - Works with gitignore-style patterns (e.g., `*.py`, `src/**`, `!test.py`)
  - When combined with `--include-extensions`, files must match both criteria
  - Allows precise control over which files to include in bundles

### Changed

- **m1f-init Git Detection**: Improved Git repository detection messages

  - Simplified output for parent directory Git repositories (no longer shows
    paths)
  - Only shows messages for current directory Git repos or no Git repo at all
  - Better handling of subdirectories within larger Git projects

- **m1f-init Language Detection**: Enhanced programming language detection
  - Changed "Not detected" to "No programming languages detected" for clarity
  - Added file counting for all supported languages (Java, C#, Go, Rust, Ruby)
  - Only shows "Programming Languages:" line when languages are actually
    detected
  - Better label clarity with "Programming Languages:" instead of just
    "Languages:"

### Fixed

- **m1f-init .gitignore Handling**: Fixed .gitignore usage in subdirectories

  - Now only uses .gitignore from current directory, not parent directories
  - Prevents errors when running m1f-init in subdirectories without their own
    .gitignore
  - All m1f commands now check for .gitignore existence before using
    --exclude-paths-file

- **m1f-init Python Project Detection**: Fixed language detection prioritization

  - Now prioritizes by file count to correctly identify primary language
  - Python projects are now properly detected even with mixed language codebases

- **m1f-init Behavior with Existing Config**: Fixed to run m1f-update when
  config exists

  - No longer creates default bundles when `.m1f.config.yml` already exists
  - Automatically runs `m1f-update` to use existing configuration

- **m1f Directory Exclusion Performance**: Fixed severe performance issue with
  directory filtering

  - Directory exclusions from .gitignore now properly applied at directory
    traversal level
  - Reduced bundle creation time from 42+ seconds to ~1.2 seconds (35x
    improvement)
  - Fixed tmp/ directory exclusion that was scanning 362,419 unnecessary files

- **m1f Multiple Source Directories**: Fixed CLI to support multiple source
  directories

  - Changed from single source to List[Path] throughout codebase
  - Now properly processes all specified source directories with
    `-s dir1 -s dir2`
  - All files from multiple sources are combined into single output

- **m1f Include Patterns**: Fixed include pattern filtering

  - Include patterns now properly applied from config files
  - Fixed \_load_include_patterns() to run even without include_paths_file
  - Patterns correctly filter files when combined with extension filters

- **m1f Bundle Configuration**: Fixed output directory exclusion pattern

  - Changed `/m1f/**` to `m1f/m1f/**` to only exclude output directory
  - Previously excluded all directories named "m1f" anywhere in the project

- **m1f-html2md Streaming**: Fixed streaming output for Claude AI analysis

  - Fixed common_parent variable scope issue (used before definition)
  - Implemented proper streaming in run_claude_streaming method
  - Fixed ColoredFormatter modifying LogRecord objects (causing ANSI codes in
    logs)
  - Added elapsed time tracking for progress messages
  - Improved subprocess handling for reliable Claude CLI integration

- **m1f-html2md Config Loading**: Made configuration more robust
  - Config loader now handles unknown fields gracefully (with warnings)
  - Automatic conversion of string paths to Path objects
  - Better error handling for Claude-generated configurations

## [3.3.0] - 2025-07-03

### Documentation

- **README.md Enhancements**: Major improvements to project documentation
  - Added clear explanation of what m1f is (Make One File)
  - Added Tailwind CSS 4.0 example demonstrating real-world usage
  - Added concise tool suite overview with links to docs and m1f.dev
  - Added comprehensive feature list emphasizing dynamic/auto-updating
    capabilities
  - Added security note about detect-secrets with link to GitHub repository
  - Added "Beyond AI" section showing alternative uses (backups, bundling,
    encoding conversion)
  - Added bundle location and Claude reference syntax explanation
  - Improved overall structure with developer-friendly tone
  - **Claude Code Integration**: Enhanced documentation for Claude binary
    auto-detection
  - **Example Updates**: Improved clarity for Tailwind CSS and Claude Code usage
    examples
- **HTML2MD Documentation Updates**: Enhanced Claude AI integration
  documentation
  - Added `--analyze-files` parameter documentation
  - Documented project description prompt feature
  - Added subprocess handling improvements
  - Updated examples with new features

### Added

- **HTML2MD Claude AI Integration Enhancements**: Major improvements to
  AI-powered HTML analysis

  - **External Prompt System**: All prompts now loaded from external markdown
    files in `prompts/` directory
    - `select_files_from_project.md`: Strategic selection of 5 representative
      HTML files
    - `analyze_selected_files.md`: Task-based analysis workflow with individual
      file processing
    - `convert_html_to_md.md`: Enhanced HTML to Markdown conversion with quality
      standards
    - Improved maintainability and customization of AI prompts
  - **Task-Based Analysis Workflow**: Multi-phase analysis for better accuracy
    - Phase 1: Individual file analysis with detailed findings saved to separate
      files
    - Phase 2: Synthesis of all analyses to create optimal configuration
    - Deep structural analysis with content boundaries, navigation elements, and
      special content types
    - Creates temporary analysis files in m1f directory for transparency
  - **Write Tool Permission**: Claude now has write permissions for creating
    analysis files
    - Automatically creates individual analysis files (html_analysis_1.txt
      through html_analysis_5.txt)
    - Enables iterative analysis and refinement process
    - Includes cleanup functionality to remove temporary files after user
      confirmation
  - **Directory Access Improvements**: Enhanced Claude integration workflow
    - Uses `--add-dir` parameter instead of changing directories
    - Maintains clean working directory structure
    - Prevents directory traversal issues during analysis
  - **Improved Error Handling**: Better subprocess management and error
    reporting
    - Fixed indentation errors in subprocess.Popen calls
    - Applied black formatting for consistent code style
    - Enhanced logging and progress indicators
    - Changed all subprocess.Popen + communicate() to subprocess.run() for
      reliable Claude CLI integration
    - Added 5-minute timeout handling for subprocess operations
  - **User Experience Improvements**: Enhanced workflow and configuration
    - Added `--analyze-files` parameter to specify number of files to analyze
      (1-20, default: 5)
    - Project description prompt now includes tip about specifying important
      files
    - Output configuration saved as `html2md_extract_config.yaml` instead of
      generic name
    - Fixed file references to use m1f/ instead of @m1f directory
    - Added debug output for transparency during analysis process
    - Cleanup functionality removes temporary analysis files after confirmation
    - **Increased Claude timeouts**: Extended timeout from 5 to 30 minutes for
      large analyses
    - **Improved configuration templates**: Better organized YAML templates for
      extraction rules

- **WebScraper Content Deduplication**: Memory-efficient duplicate prevention
  system (enabled by default)

  - **Database-Backed Deduplication**: Optimized for large scraping sessions
    - Uses SQLite queries instead of loading all checksums into memory
    - Stores checksums in `content_checksums` table with first URL and timestamp
    - Scrapers use callback mechanism to check checksums via database
    - Significantly reduces memory usage for large scraping sessions
    - Maintains deduplication state across resume operations
  - **Content-Based Detection**: SHA-256 checksums of normalized plain text
    - Extracts plain text from HTML (removes all tags, scripts, styles)
    - Decodes HTML entities (&nbsp;, &lt;, etc.)
    - Normalizes whitespace (multiple spaces become single space)
    - Skips pages with identical text content
  - **Three-Layer Deduplication System**:
    1. Canonical URL checking (default: enabled) - Use `--ignore-canonical` to
       disable
    2. Content deduplication (default: enabled) - Use `--ignore-duplicates` to
       disable
    3. GET parameter normalization (default: disabled) - Use
       `--ignore-get-params` to enable
  - **Improved Logging**: Graceful handling of duplicate detection
    - No longer logs duplicates as "unexpected errors"
    - Clear informational messages when skipping duplicate content
    - Transparent reporting of deduplication effectiveness

- **WebScraper Subdirectory Restriction**: Automatic crawling restriction to
  specified paths

  - When URL contains a path (e.g., `https://example.com/docs`), only pages
    under that path are scraped
  - Prevents crawling outside the specified subdirectory (e.g., won't scrape
    `/products` when `/docs` is specified)
  - Works with all scraper backends (BeautifulSoup, HTTrack, Selectolax)
  - Useful for downloading specific documentation sections without the entire
    website
  - Example: `m1f-scrape https://api.example.com/v2/reference` only scrapes
    pages under `/v2/reference`

- **WebScraper Ignore GET Parameters**: New option to prevent duplicate content
  from URLs with different query strings

  - **--ignore-get-params Flag**: Strips GET parameters from URLs during
    scraping
    - Prevents duplicate downloads from URLs like `page.html?tab=linux` and
      `page.html?tab=windows`
    - Normalized URLs are used for visited tracking and file saving
    - Works with all scraper backends (BeautifulSoup, HTTrack, Selectolax)
    - HTTrack uses `-N0` flag to disable query string parsing
    - Useful for documentation sites that use GET parameters for UI state
  - **Example**:
    `m1f-scrape https://docs.example.com -o ./html --ignore-get-params`
    - Will treat `docs.html?version=1` and `docs.html?version=2` as the same
      page

- **WebScraper Canonical URL Checking**: Automatically skip duplicate pages
  based on canonical URLs
  - **Default Behavior**: Checks `<link rel="canonical">` tags on every page
    - Skips pages where canonical URL differs from current URL
    - Prevents downloading duplicate content (print versions, mobile versions,
      etc.)
    - Works with all scraper backends (BeautifulSoup, HTTrack, Selectolax)
    - Logs skipped pages with their canonical URLs for transparency
  - **--ignore-canonical Flag**: Ignore canonical tags when needed
    - Use when you want all page versions regardless of canonical tags
    - Example: `m1f-scrape https://example.com -o ./html --ignore-canonical`
  - **Use Cases**:
    - Documentation sites with multiple URL formats for same content
    - E-commerce sites with product URLs containing tracking parameters
    - News sites with print and mobile versions of articles

### Fixed

- **HTML2MD Claude Integration Issues**: Resolved multiple issues with Claude
  CLI integration
  - Fixed subprocess hanging when using `Popen` + `communicate()` with Claude
    CLI
  - Fixed incorrect m1f usage (now properly uses `--skip-output-file` for
    filelist generation)
  - Fixed file references from embedded content to proper @ syntax
  - Fixed indentation errors in subprocess calls
  - Fixed undefined variable errors (removed unused `html_contents`)
  - Fixed test failure for outdated CLI parameters
  - **Auto-detection of Claude binary**: m1f-html2md --claude now automatically
    detects claude binary location
    - Searches common installation paths including ~/.local/bin/claude
    - Falls back to system PATH if not found in common locations
    - Provides helpful error message if claude CLI is not installed
- **m1f Directory Structure**: Corrected nested directory configuration
  - Fixed .m1f.config.yml to use proper m1f/m1f/ structure
  - Removed accidental triple nesting (m1f/m1f/m1f/)
  - Created proper symlink from m1f/m1f.txt to m1f/m1f/87_m1f_only_docs.txt
- **WebScraper Logging**: Fixed duplicate content detection logging

  - Duplicates no longer logged as "unexpected errors"
  - Changed from exception-based to graceful skip-based handling

- **WebScraper Resume Functionality**: Interrupt and resume web scraping
  sessions
  - **SQLite Database Tracking**: Automatically tracks scraped URLs in
    `scrape_tracker.db`
    - Stores URL, status code, target filename, timestamp, and errors
    - Enables resuming interrupted scraping sessions
    - Database created in output directory for each scraping job
  - **Progress Display**: Real-time display of currently processed URLs
    - Shows "Processing: <URL> (page X)" for each page
    - Verbose mode displays detailed logging information
    - Resume shows "Resuming crawl - found X previously scraped URLs"
  - **Graceful Interruption**: Clean handling of Ctrl+C
    - Shows friendly message: "⚠️ Scraping interrupted by user"
    - Instructions to resume: "Run the same command again to resume where you
      left off"
    - No Python stack traces on interruption
  - **Smart Resume Strategy**: Analyzes previously scraped pages
    - Reads first 20 scraped pages to extract links
    - Populates URL queue with unvisited links from scraped pages
    - Shows "Found X URLs to visit after analyzing scraped pages"
  - **Enhanced CLI**: Better user experience - Added hint "Press Ctrl+C to
    interrupt and resume later" at startup - Logging configuration with `-v`
    flag for progress visibility - Fixed asyncio "Unclosed client session"
    warnings =======
- **m1f-html2md Claude AI Integration**: Intelligent HTML analysis and
  conversion using Claude

  - **Analyze Command Enhancement**: Added `--claude` flag for AI-powered
    analysis
    - Automatically finds all HTML files in directories (no need to specify
      individual files)
    - Uses Claude to intelligently select 5 representative files from scraped
      documentation
    - Analyzes HTML structure and suggests optimal CSS selectors for content
      extraction
    - Excludes navigation, headers, footers, sidebars, and advertisements
    - Runs `m1f-init` automatically in the analysis directory
    - Outputs YAML configuration with content and ignore selectors
  - **Convert Command Enhancement**: Added `--claude` flag for batch HTML to
    Markdown conversion
    - Converts all HTML files in a directory to clean Markdown using Claude AI
    - Supports model selection with `--model` parameter (opus or sonnet)
    - Configurable sleep delay between API calls with `--sleep` parameter
    - Maintains directory structure in output
    - Progress tracking with conversion summary
  - **Prompt Templates**: All prompts stored as markdown files in `prompts/`
    directory
    - `select_files_simple.md` - Selects representative HTML files
    - `analyze_html_simple.md` - Analyzes HTML and suggests CSS selectors
    - `convert_html_to_md.md` - Converts HTML to clean Markdown
  - **Security**: Path traversal protection using existing
    `validate_path_traversal` function
  - **Import Fix**: Fixed ModuleNotFoundError with try/except import pattern

- **--docs-only Parameter**: New command-line flag for documentation-only
  bundles

  - Filters to include only 62 documentation file extensions
  - Simplifies command: `m1f -s . -o docs.txt --docs-only`
  - Replaces verbose `--include-extensions` with 62 extensions
  - Available in presets via `docs_only: true` configuration
  - Overrides include-extensions when set

- **Documentation File Extensions**: Centralized definition in constants.py

  - Added DOCUMENTATION_EXTENSIONS constant with 62 file extensions
  - Added UTF8_PREFERRED_EXTENSIONS constant with 45 UTF-8 preferred formats
  - Includes man pages, markup formats, text files, and developer docs
  - Removed binary formats (.doc, .so) that were incorrectly included
  - Added is_documentation_file() utility function for consistent checks
  - Updated encoding handler to use centralized UTF-8 preference list
  - Documentation extensions now available system-wide for all tools
    > > > > > > > a5263cc2954dda4397238b4001d4bbae4cea973d

- **m1f-claude --init Improvements**: Enhanced project initialization process

  - **Choice-Based Setup**: Users can choose between quick and advanced
    initialization modes
    - Interactive prompt asks for setup preference (1 for quick, 2 for advanced)
    - Command-line parameters: `--quick-setup` and `--setup` for scripting
    - Quick setup: Creates bundles in 30 seconds without Claude
    - Advanced setup: Claude analyzes project and creates topic-specific bundles
  - **Project-Specific Bundle Naming**: All bundles include project directory
    name
    - Example: `m1f_complete.txt`, `m1f_docs.txt` for the m1f project
    - Auxiliary files also include project name: `m1f_complete_filelist.txt`,
      `m1f_complete_dirlist.txt`
    - Makes it easier to identify bundles when working with multiple projects
  - **Auxiliary File Generation**: Both bundles now generate filelist and
    dirlist files
    - Complete bundle creates: `{project}_complete_filelist.txt` and
      `{project}_complete_dirlist.txt`
    - Docs bundle creates: `{project}_docs_filelist.txt` and
      `{project}_docs_dirlist.txt`
    - Provides overview of included files and directory structure
  - **Streamlined Workflow**: Automatic bundle creation without Claude
    dependency
    - Automatically creates complete.txt bundle with all project files
    - Automatically creates docs.txt bundle with 62 documentation extensions
    - Uses --docs-only parameter for efficient documentation bundling
    - Claude Code only invoked for advanced topic-specific segmentation
    - Simplified workflow: git clone → m1f-link → m1f-claude --init → done!
  - **Verbose Mode**: Added `--verbose` flag to show prompts and command
    parameters
    - Displays complete Claude Code command with permissions

- **m1f-init Tool**: New cross-platform initialization tool
  - Replaces m1f-link functionality (m1f-link has been removed)
  - Integrates documentation linking into initialization process
  - Works on Windows, Linux, and macOS
  - Creates complete and docs bundles with project-specific names
  - Generates auxiliary files (filelist, dirlist) for all bundles
  - Creates basic .m1f.config.yml configuration
  - Shows platform-specific next steps
  - On Linux/macOS: Suggests `m1f-claude --setup` for topic bundles

### Changed

- **m1f-claude Refactoring**: Removed initialization from m1f-claude
  - Removed --init, --quick-setup parameters
  - Now only handles --setup for topic-specific bundles
  - Requires m1f-init to be run first (checks for prerequisites)
  - Focuses solely on Claude-assisted advanced configuration
  - Not available on Windows (Linux/macOS only)

### Removed

- **m1f-link Command**: Functionality integrated into m1f-init
  - Documentation linking now happens automatically during m1f-init
  - Simplifies workflow by combining two steps into one

### Enhanced

- **Auxiliary File Documentation**: Added comprehensive documentation

  - Documented filelist and dirlist generation in main m1f documentation
  - Added "Output Files" section explaining all generated files
  - Included examples of working with file lists for custom bundles
  - Updated Quick Start to show all files created by m1f-init
  - Added file list editing workflows to development documentation
    - Shows full prompt being sent for debugging
    - Helps troubleshoot initialization issues
  - **Project Analysis Files**: Create and preserve analysis artifacts in m1f/
    directory
    - Generates `project_analysis_filelist.txt` with all project files
    - Generates `project_analysis_dirlist.txt` with directory structure
    - Files are kept for reference (no cleanup)
    - Respects .gitignore patterns during analysis
    - Explicitly excludes m1f/ directory to prevent recursion
  - **Better Bundle Strategy**: Improved initialization prompts for
    project-specific configs
    - Explicit instruction to read @m1f/m1f.txt documentation first
    - Removed global file size limits from defaults
    - Added proper meta file exclusions (LICENSE*, CLAUDE.md, *.lock)
    - Clear rules against creating test bundles when no tests exist
    - Emphasis on logical segmentation
      (complete/docs/code/components/config/styles)
    - Clarified that dotfiles are excluded by default
    - Added vendor/ to example excludes for PHP projects
  - **Clearer Instructions**: Made prompts more explicit about modifying files
    - Emphasizes that basic config is just a starter needing enhancement
    - Requires 3-5 project-specific bundles minimum
    - Explicit instruction to use Edit/MultiEdit tools
    - Stronger language about actually modifying the config file

- **m1f-claude Enhancements**: Major improvements for intelligent m1f setup
  assistance
  - **Session Persistence**: Implemented proper conversation continuity using
    Claude CLI's `-r` flag
    - Each conversation maintains its own session ID
    - Multiple users can work in the same directory simultaneously
    - Session IDs are extracted from JSON responses and reused
  - **Streaming Output**: Real-time feedback with `--output-format stream-json`
    - Shows Claude's responses as they arrive
    - Displays tool usage in debug mode
    - Provides immediate visual feedback during processing
  - **Tool Permissions**: Added `--allowedTools` parameter with sensible
    defaults
    - Default tools: Read, Edit, MultiEdit, Write, Glob, Grep, Bash
    - Customizable via `--allowed-tools` command line argument
    - Enables file operations and project analysis
  - **Enhanced Prompt System**: Sophisticated prompt enhancement for m1f setup
    - Deep thinking task list approach for systematic m1f configuration
    - Detects when users want to set up m1f (various phrase patterns)
    - Provides 5-phase task list: Analysis, Documentation Study, Design,
      Implementation, Validation
    - Always references @m1f/m1f.txt documentation (5+ references per prompt)
    - Detects and prioritizes AI context files (CLAUDE.md, .cursorrules,
      .windsurfrules)
    - Project-aware recommendations based on detected frameworks
    - Line-specific documentation references for key sections
  - **Debug Mode**: Added `--debug` flag for detailed output
    - Shows session IDs, costs, and API usage
    - Displays tool invocations and responses
    - Helps troubleshoot issues and monitor usage
  - **Interactive Mode UX**: Improved visual feedback
    - "Claude is thinking..." indicator during processing
    - Tool usage notifications: `[🔧 Using tool: Read]`
    - Response completion indicator: `[✅ Response complete]`
    - Better prompt spacing with newlines before "You:"
    - Clear separation between responses and new prompts
    - Interaction counter: prompts to continue after every 10 exchanges
    - Ctrl-C signal handling for graceful cancellation
    - Tool output preview: shows abbreviated results from Claude's tool usage
    - Emphasis on Standard separator (not Markdown) for AI-optimized bundles
  - **Exit Command**: Added `/e` command support like Claude CLI
    - Works alongside 'quit', 'exit', and 'q' commands
    - Updated help text and keyboard interrupt messages
  - **Initialization Command**: Fixed `--init` command async/await issues
    - Resolved RuntimeError with cancel scope in different task
    - Added graceful handling of missing 'cost_usd' field in Claude SDK
      responses
    - Implemented proper anyio task group management for async operations
    - Enhanced error handling with debug logging for SDK issues
    - Fixed subprocess hanging by displaying prompts for manual use instead of
      programmatic execution

### Changed

- **m1f-claude --init Workflow**: Completely redesigned initialization process

  - Now automatically creates complete.txt and docs.txt bundles without Claude
  - Generates .m1f.config.yml with both bundles pre-configured
  - Uses new --docs-only parameter for documentation bundle creation
  - Claude Code only used for advanced topic-specific segmentation
  - Simplified workflow: git clone → m1f-link → m1f-claude --init → done!

- **Dependencies**: Updated claude-code-sdk to use flexible version constraint

  - Changed from `claude-code-sdk==0.0.10` to `claude-code-sdk>=0.0.10`
  - Ensures automatic updates to latest compatible versions
  - Maintains backward compatibility with current version

- **m1f-claude Architecture**: Switched from SDK to subprocess for better
  control
  - Uses Claude CLI directly with proper session management
  - More reliable than the SDK for interactive sessions
  - Better error handling and fallback mechanisms
  - Removed misleading "subprocess fallback" message (it's the primary method
    now)

### Fixed

- **m1f-claude --init Command**: Fixed Claude Code subprocess execution

  - Resolved parameter ordering issue with `--add-dir` flag
  - Changed from stdin-based prompt delivery to `-p` parameter method
  - Implemented fallback to display manual command when subprocess hangs
  - Now shows clear instructions for manual execution with proper parameters
  - Ensures Claude has directory access permissions for file operations

- **PowerShell Installation**: Fixed missing m1f_aliases.ps1 file

  - Created m1f_aliases.ps1 with all PowerShell functions and aliases
  - Added file existence check in setup_m1f_aliases.ps1 before sourcing
  - Fixed hardcoded path issue that caused PowerShell profile errors
  - Now uses correct relative paths based on actual m1f installation location
  - Added PowerShell profile path to warning message for easier debugging

- **m1f-claude Project Name Extraction**: Fixed regex patterns that were failing
  to extract project names
  - Replaced complex regex patterns with backreferences that were causing
    incorrect matches
  - Added simpler, more specific patterns for different name formats (quoted,
    unquoted, possessive)
  - Fixed issue where project names were always extracted as empty strings
  - Now correctly handles formats like "project called 'awesome-app'", "project
    named MyWebApp", "company's main project"

### Dependencies

- Added required dependencies for m1f-claude:
  - anyio==4.9.0 (async support)
  - claude-code-sdk==0.0.10 (Claude integration)

## [3.2.2] - 2025-07-06

### Changed

- **Documentation**: Updated all command examples to use installed bin commands
  - Replaced `python -m tools.m1f` with `m1f`
  - Replaced `python -m tools.s1f` with `m1f-s1f`
  - Replaced `python -m tools.scrape_tool` and `python -m tools.webscraper` with
    `m1f-scrape`
  - Replaced `python -m tools.html2md` and `python -m tools.html2md_tool` with
    `m1f-html2md`
  - Replaced `python tools/token_counter.py` with `m1f-token-counter`
  - Replaced `m1f auto-bundle` with `m1f-update` where appropriate
  - Updated all documentation, scripts, and examples for consistency

### Fixed

- **Scraper Config Files**: Fixed typo in YAML configs (mf1-html2md →
  m1f-scrape)
- **Documentation**: Improved command consistency across all user-facing
  documentation

## [3.2.1] - 2025-06-07

### Fixed

- **Wrapper Scripts**: Added PYTHONPATH to all wrapper scripts to ensure proper
  module imports
- **Pre-commit Hook**: Updated to use python3 and properly handle virtual
  environments
- **Bin Scripts**: All wrapper scripts now preserve current working directory

## [3.2.0] - 2025-06-06

### Added

- **Git Hooks Integration**: Automatic bundle generation on every commit

  - Pre-commit hook that runs `m1f auto-bundle` before each commit
  - Installation script with remote download support:
    `curl -sSL https://raw.githubusercontent.com/franzundfranz/m1f/main/scripts/install-git-hooks.sh | bash`
  - Auto-detection of m1f development repository vs. installed m1f
  - Automatic staging of generated bundles in `m1f/` directory
  - Comprehensive setup guide at `docs/05_development/56_git_hooks_setup.md`

- **Bundle Directory Migration**: Moved from `.m1f/` to `m1f/` for better AI
  tool compatibility

  - AI tools like Claude Code can now access bundled files directly
  - Generated bundles are included in version control by default
  - Automatic migration of configuration paths
  - Updated `m1f-link` command to create symlinks in `m1f/` directory
  - Added `m1f/README.md` explaining auto-generated files

- **Complete Preset Parameter Support**: ALL m1f parameters can now be
  configured via presets

  - Input/Output settings: source_directory, input_file, output_file,
    input_include_files
  - Output control: add_timestamp, filename_mtime_hash, force, minimal_output,
    skip_output_file
  - Archive settings: create_archive, archive_type
  - Runtime behavior: verbose, quiet
  - CLI arguments always take precedence over preset values
  - Enables simple commands like `m1f --preset production.yml`
  - Updated template-all-settings.m1f-presets.yml with all new parameters
  - Full documentation in docs/01_m1f/12_preset_reference.md

- **Auto-Bundle Subcommand**: Integrated auto-bundle functionality directly into
  m1f

  - New `auto-bundle` subcommand for creating multiple bundles from YAML config
  - Reads `.m1f.config.yml` from project root
  - Supports creating all bundles or specific bundles by name
  - `--list` option to show available bundles with descriptions
  - `--verbose` and `--quiet` options for output control
  - `m1f-update` command provides convenient access from anywhere
  - Full compatibility with existing `.m1f.config.yml` format
  - Supports all m1f options: presets, exclude/include files, conditional
    bundles
  - Updated `watch_and_bundle.sh` to use new auto-bundle functionality

- **Simplified Installation System**: Complete installer scripts for all
  platforms

  - New `install.sh` handles entire setup process (3 commands total!)
  - New `install.ps1` for Windows with full automation
  - Automatic Python 3.10+ version checking
  - Virtual environment creation and dependency installation
  - Initial bundle generation during setup
  - Smart shell detection for immediate PATH activation
  - `uninstall.sh` for clean removal

- **PATH-based Command System**: Replaced aliases with executable wrappers

  - Created `bin/` directory with standalone executable scripts
  - Each wrapper activates venv and runs appropriate tool
  - Works consistently across all shells and platforms
  - Optional symlink creation in ~/.local/bin

- **m1f-claude Command**: Smart prompt enhancement for Claude AI

  - New `m1f-claude` command that enhances prompts with m1f knowledge
  - Automatically injects m1f documentation context into prompts
  - Interactive mode for continued conversations
  - Project structure analysis for better suggestions
  - Contextual hints based on user intent (bundling, config, WordPress, AI
    context)
  - Integration with Claude Code CLI (if installed)
  - Comprehensive workflow guide at docs/01_m1f/30_claude_workflows.md

- **Enhanced Auto-Bundle Functionality**: Improved usability and flexibility

  - Config file search now traverses from current directory up to root
  - New `--group` parameter to create bundles by group (e.g.,
    `m1f auto-bundle --group documentation`)
  - Bundle grouping support in `.m1f.config.yml` with `group: "name"` field
  - Improved error messages when config file is not found
  - Enhanced `--list` output showing bundles organized by groups
  - Comprehensive documentation in `docs/01_m1f/20_auto_bundle_guide.md`
  - Examples for server-wide bundle management and automation

- **Join Paragraphs Feature**: Markdown optimization for LLMs

  - New `JOIN_PARAGRAPHS` processing action to compress markdown
  - Intelligently joins multi-line paragraphs while preserving structure
  - Preserves code blocks, tables, lists, and other markdown elements
  - Helps maximize content in the first 200 lines that LLMs read intensively
  - Available in presets for documentation bundles

- **S1F List Command**: Display archive contents without extraction

  - New `--list` flag to show files in m1f archives
  - Displays file information including size, encoding, and type
  - No longer shows SHA256 hashes for cleaner output
  - Useful for previewing archive contents before extraction

- **Configurable UTF-8 Preference**: Made UTF-8 encoding preference for text
  files configurable

  - Added `prefer_utf8_for_text_files` option to EncodingConfig (defaults to
    True)
  - New CLI flag `--no-prefer-utf8-for-text-files` to disable UTF-8 preference
  - Configurable via preset files through `prefer_utf8_for_text_files` setting
  - Affects only text files (.md, .markdown, .txt, .rst) when encoding detection
    is ambiguous

- **Configurable Content Deduplication**: Made content deduplication optional
  - Added `enable_content_deduplication` option to OutputConfig (defaults to
    True)
  - New CLI flag `--allow-duplicate-files` to include files with identical
    content
  - Configurable via preset files through `enable_content_deduplication` setting
  - Useful when you need to preserve all files regardless of duplicate content

### Fixed

- **Security**: Comprehensive path traversal protection across all tools

  - Added path validation to prevent directory traversal attacks
  - Block paths with `../` or `..\` patterns
  - Reject absolute paths in s1f extraction
  - Validate all user-provided file paths including symlink targets
  - Allow legitimate exceptions: home directory configs (~/.m1f/), output files

- **Markdown Format**: Fixed separator and content formatting issues

  - Content now properly starts on new line after code fence in markdown format
  - Added blank line between separator and content in parallel processing mode
  - Fixed S1F markdown parser to correctly handle language hint and newline
  - Fixed closing ``` for markdown format in parallel processing

- **S1F List Output**: Simplified file information display

  - Removed SHA256 hash display from list output
  - No longer shows "[Unknown]" for missing file sizes
  - Only displays file size when available

- **Standard Separator Format**: Removed checksum from display
  - Standard format now shows only file path without SHA256
  - Simplified output for better readability
  - Parser ignores separators inside code blocks to prevent false positives

### Changed

- **Parallel File Processing**: Enhanced performance for large projects

  - Added optional `--parallel` flag for concurrent file processing
  - Implemented asyncio-based batch handling with proper thread safety
  - Added locks for thread-safe checksum operations
  - Maintained file ordering in output despite parallel processing
  - Automatic fallback to sequential processing for single files

- **Auto-bundle config file** (`.m1f.config.yml`) updated with group
  categorization

  - Documentation bundles grouped under "documentation"
  - Source code bundles grouped under "source"
  - Complete project bundle in "complete" group

- **Command Naming Standardization**: All tools now use m1f- prefix

  - `s1f` → `m1f-s1f`
  - `html2md` → `m1f-html2md`
  - `webscraper` → `m1f-scrape`
  - `token-counter` → `m1f-token-counter`
  - Prevents naming conflicts with system commands

- **Module Execution**: Fixed import errors with proper module syntax

  - All scripts now use `python -m tools.m1f` format
  - Ensures reliable imports across different environments
  - Updated all documentation examples

- **WebScraper Rate Limiting**: Conservative defaults for Cloudflare protection

  - Changed default request delay from 0.5s to 15s
  - Reduced concurrent requests from 5 to 2
  - Added bandwidth limiting (100KB/s) and connection rate limits
  - Created cloudflare.yaml config with ultra-conservative 30s delays

- **Code Quality**: Comprehensive linting and formatting
  - Applied Black formatting to all Python code
  - Applied Prettier formatting to all Markdown files
  - Added/updated license headers across all source files
  - Removed deprecated test files and debug utilities

### Security

- **Path Traversal Protection**: Comprehensive validation across all tools

  - Prevents attackers from using paths like `../../../etc/passwd`
  - Validates resolved paths against project boundaries
  - Allows legitimate exceptions for configs and output files
  - Added extensive security tests

- **Scraper Security**: Enhanced security measures
  - Enforced robots.txt compliance with caching
  - Added URL validation to prevent SSRF attacks
  - Basic JavaScript validation to block dangerous scripts
  - Sanitized command arguments in HTTrack to prevent injection

### Improved

- **HTML2MD Enhancement**: Better file path handling

  - Improved source path logic for file inputs
  - Enhanced relative path resolution for edge cases
  - Consistent output path generation with fallback mechanisms
  - Removed hardcoded Anthropic-specific navigation selectors

- **Encoding Detection**: Enhanced fallback logic

  - Default to UTF-8 if chardet fails or returns empty
  - Prefer UTF-8 over Windows-1252 for markdown files
  - Expanded encoding map for better emoji support
  - Better handling of exotic encodings

- **Async I/O Support**: Performance optimizations

  - S1F now supports optional aiofiles for async file reading
  - Better handling of deprecated asyncio methods
  - Improved concurrent operation handling

- **Testing Infrastructure**: Comprehensive test improvements
  - Reorganized test structure for better clarity
  - Added path traversal security tests
  - Fixed all test failures (100% success rate)
  - Added pytest markers for test categorization
  - Improved test documentation

### Removed

- Obsolete scripts replaced by integrated functionality:
  - `scripts/auto_bundle.py` (now `m1f auto-bundle`)
  - `scripts/auto_bundle.sh` (now `m1f auto-bundle`)
  - `scripts/auto_bundle.ps1` (now `m1f auto-bundle`)
  - `scripts/update_m1f_files.sh` (now `m1f-update`)
  - `setup_m1f_aliases.sh` (replaced by bin/ directory)
  - Deprecated test files and debug utilities (~3000 lines removed)

## [3.1.0] - 2025-06-04

### Added - html2md

- **Custom Extractor System**: Site-specific content extraction
  - Pluggable extractor architecture for optimal HTML parsing
  - Support for function-based and class-based extractors
  - Extract, preprocess, and postprocess hooks
  - Dynamic loading of Python extractor files
  - Default extractor for basic navigation removal
- **Workflow Integration**: Organized .scrapes directory structure
  - Standard directory layout: html/, md/, extractors/
  - .scrapes directory added to .gitignore
  - Supports Claude-assisted extractor development
- **CLI Enhancement**: `--extractor` option for custom extraction logic
- **API Enhancement**: Extractor parameter in Html2mdConverter constructor

### Changed - html2md

- Removed all Anthropic-specific code from core modules
- Cleaned up api.py to remove hardcoded navigation selectors
- Improved modularity with separate extractor system

### Added - m1f

- **Multiple Exclude/Include Files Support**: Enhanced file filtering
  capabilities
  - `exclude_paths_file` and `include_paths_file` now accept multiple files
  - Files are merged in order, non-existent files are gracefully skipped
  - Include files work as whitelists - only matching files are processed
  - Full backward compatibility with single file syntax
  - CLI supports multiple files: `--exclude-paths-file file1 file2 file3`
  - YAML config supports both single file and list syntax

### Changed

- Enhanced file processor to handle pattern merging from multiple sources
- Updated CLI arguments to accept multiple files with `nargs="+"`
- Improved pattern matching for exact path excludes/includes

## [3.0.1] - 2025-06-04

### Fixed

- **Configuration Parsing**: Fixed YAML syntax error in .m1f.config.yml
  - Corrected array item syntax in include_files sections
  - Removed erroneous hyphens within square bracket array notation

## [3.0.0] - 2025-06-03

### Added

- **Python-based auto_bundle.py**: Cross-platform bundling implementation
  - Pure Python alternative to shell scripts
  - Improved include-extensions handling
  - Dynamic watcher ignores based on configuration
  - Global excludes support
  - Better error handling and logging
- **Enhanced Bundling Configuration**: Advanced m1f.config.yml structure
  - Config-based directory setup
  - Refined source rules for s1f-code and all bundles
  - Improved path handling for m1f/s1f separation
- **Depth-based Sorting**: Files and directories now sorted by depth for better
  organization
- **Improved Documentation**: Comprehensive updates to m1f documentation
  - Added CLI reference and troubleshooting guides
  - Enhanced preset system documentation
  - Clarified script invocation methods
  - Added quick reference guides
- **Testing Improvements**: Enhanced asyncio handling across test suites
  - Better pytest configuration for async tests
  - Preset configuration support in scrapers
  - Fixed import and linting issues
- **License Change**: Migrated from MIT to Apache 2.0 License
  - Added NOTICE file with proper attribution
  - Updated all license references throughout codebase

### Changed

- **Refactored Web Scraping Architecture**: Separated webscraper from HTML2MD
  - Cleaner separation of concerns
  - Better modularity for each tool
  - Improved maintainability
- **Build System Enhancements**: Overhauled build configuration
  - Optimized bundling for tool segregation
  - Added quiet flag to suppress unnecessary log file creation
  - Enhanced PowerShell support with auto_bundle.ps1
- **Documentation Structure**: Reorganized docs for better navigation
  - Renamed files for improved sorting
  - Moved changelog to dedicated location
  - Updated all references to new structure

### Fixed

- **Script Issues**: Multiple fixes for auto-bundling scripts
  - Corrected include-extensions parameter handling
  - Fixed config file parsing and argument handling
  - Resolved path resolution issues
- **Test Errors**: All test suite issues resolved
  - Fixed async test handling
  - Corrected import statements
  - Resolved linting issues (Black and Markdown)
- **Configuration Issues**: Fixed various config problems
  - Corrected output paths in m1f.config.yml
  - Fixed switch handling in scripts
  - Updated autobundler configurations

### Dependencies

- Updated aiohttp to 3.10.11 for security and performance improvements
- Added new packages to support enhanced functionality

---

### Original 3.0.0 Features (from earlier development)

- **Pluggable Web Scraper Backends**: HTML2MD now supports multiple scraper
  backends for different use cases
  - **Selectolax** (httpx + selectolax): Blazing fast HTML parsing with minimal
    resource usage
  - **Scrapy**: Industrial-strength web scraping framework with middleware
    support
  - **Playwright**: Browser automation for JavaScript-heavy sites and SPAs
  - Each scraper is optimized for specific scenarios:
    - Selectolax: Maximum performance for simple HTML (20+ concurrent requests)
    - Scrapy: Complex crawling with retry logic, caching, and auto-throttle
    - Playwright: Full JavaScript execution with multiple browser support
  - CLI option `--scraper` to select backend (beautifulsoup, httrack,
    selectolax, scrapy, playwright)
  - Backend-specific configuration files in `scrapers/configs/`
  - Graceful fallback when optional dependencies are not installed

### Changed

- **HTML2MD Version**: Bumped to 3.0.0 for major feature addition
- **Scraper Architecture**: Refactored to plugin-based system with abstract base
  class
- **Documentation**: Comprehensive updates for all scraper backends with
  examples
- **CLI**: Extended to support new scraper options and configuration
- **HTTrack Integration**: Replaced Python HTTrack module with native Linux
  httrack command
  - Now uses real HTTrack command-line tool for professional-grade website
    mirroring
  - Better performance, reliability, and standards compliance
  - Requires system installation: `sudo apt-get install httrack`
  - Enhanced command-line options mapping for HTTrack features

### Documentation

- Added Web Scraper Backends Guide (`docs/html2md_scraper_backends.md`)
- Updated HTML2MD documentation with new scraper examples
- Added configuration examples for each scraper backend

## [2.1.1] - 2025-05-25

### Changed

- Small documentation update
- Improved example consistency across documentation
- Updated file paths in test fixtures
- Cleaned up outdated references

## [2.1.0] - 2025-05-25

### Added

- **Preset System**: Flexible file-specific processing rules

  - Hierarchical preset loading: global (~/.m1f/) → user → project
  - Global settings: encoding, separator style, line endings, includes/excludes
  - Extension-specific processing: HTML minification, CSS compression, comment
    stripping
  - Built-in actions: minify, strip_tags, strip_comments, compress_whitespace,
    remove_empty_lines
  - Custom processors: truncate, redact_secrets, extract_functions
  - CLI options: `--preset`, `--preset-group`, `--disable-presets`
  - Example presets: WordPress, web projects, documentation
  - **Per-file-type overrides**: Different settings for different extensions
    - `security_check`: Enable/disable security scanning per file type
    - `max_file_size`: Different size limits for CSS, JS, PHP, etc.
    - `remove_scraped_metadata`: Clean HTML2MD files selectively
    - `include_dot_paths`, `include_binary_files`: File-type specific filtering
  - **Auto-bundling with presets**: New scripts and VS Code tasks
    - `scripts/auto_bundle_preset.sh` - Preset-based intelligent bundling
    - `tasks/auto_bundle.json` - 11 VS Code tasks for automated bundling
    - Focus areas: WordPress, web projects, documentation
    - Integration with preset system for file-specific processing
  - **Test suite**: Basic preset functionality tests
    - Global settings and file filtering tests
    - File-specific action processing tests
    - Integration verification

- **Auto-bundling System**: Automatic project organization for AI/LLM
  consumption
  - `scripts/auto_bundle.sh` - Basic bundling with predefined categories
  - `scripts/auto_bundle_v2.sh` - Advanced bundling with YAML configuration
  - `.m1f.config.yml` - Customizable bundle definitions and priorities
  - `scripts/watch_and_bundle.sh` - File watcher for automatic updates
  - Bundle types: docs, src, tests, complete, and custom focus areas
- **Claude Code Integration** (optional): AI-powered tool automation

  - `tools/claude_orchestrator.py` - Natural language command processing
  - Integration with Claude Code CLI for workflow automation
  - Project-specific `.claude/settings.json` configuration
  - Example workflows and documentation

- **HTML2MD Preprocessing System**: Configurable HTML cleaning
  - `tools/html2md/analyze_html.py` - Analyze HTML for preprocessing patterns
  - `tools/html2md/preprocessors.py` - Generic preprocessing framework
  - Removed hardcoded project-specific logic
  - Support for custom preprocessing configurations per project

### Changed

- HTML2MD now uses configurable preprocessing instead of hardcoded rules
- Updated documentation structure to include new features

### Fixed

- Preset `strip_tags` action now properly strips all HTML tags when no specific
  tags are specified
- Added missing `get_file_specific_settings` method to PresetManager class

### Documentation

- Added Preset System Guide (`docs/m1f_presets.md`)
- Added Auto Bundle Guide (`docs/AUTO_BUNDLE_GUIDE.md`)
- Added Claude Code Integration Guide (`docs/CLAUDE_CODE_INTEGRATION.md`)
- Added example workflows (`examples/claude_workflows.md`)
- Updated main documentation index with new features

## [2.0.1] - 2025-05-25

### Fixed

- All test suite failures now pass (100% success rate)
  - S1F: Fixed content normalization and timestamp tolerance issues
  - M1F: Fixed encoding test with proper binary file handling
  - HTML2MD: Fixed server tests and API implementation
  - Security: Fixed warning log format detection with ANSI codes
- Documentation formatting and consistency issues

### Changed

- Applied Black formatting to all Python code
- Applied Prettier formatting to all Markdown files
- Updated all documentation to consistently use module execution syntax

### Documentation

- Updated all docs to reflect v2.0.0 architecture changes
- Added architecture sections to all tool documentation
- Modernized API examples with async/await patterns
- Updated token limits for latest LLM models

## [2.0.0] - 2025-05-25

### 🚀 Major Architectural Overhaul

This is a major release featuring complete architectural modernization of the
m1f project, bringing it to Python 3.10+ standards with significant performance
improvements and new features.

### Added

- **HTML2MD Converter**: New tool for converting HTML to Markdown with HTTrack
  integration for website scraping
  - CSS selector-based content extraction
  - Configurable crawl depth and domain restrictions
  - Metadata preservation and frontmatter generation
  - Integration with m1f for bundle creation
- **Content Deduplication**: Automatic detection and removal of duplicate file
  content based on SHA256 checksums
- **Symlink Support**: Smart symlink handling with cycle detection
- **File Size Filtering**: New `--max-file-size` parameter with unit support (B,
  KB, MB, GB, TB)
- **Metadata Removal**: New `--remove-scraped-metadata` option for cleaning
  HTML2MD scraped content
- **Colorized Output**: Beautiful console output with progress indicators
- **Async I/O**: Concurrent file operations for better performance
- **Type Hints**: Comprehensive type annotations using Python 3.10+ features
- **Test Infrastructure**: pytest-timeout for reliable test execution

### Changed

- **Complete Architecture Rewrite**:
  - m1f transformed from monolithic script to modular package
  - s1f transformed from monolithic script to modular package
  - Clean architecture with dependency injection and SOLID principles
- **Python Requirements**: Now requires Python 3.10+ (previously 3.9+)
- **Enhanced Security**: Improved security scanning and validation
- **Better Error Handling**: Custom exception hierarchies with specific error
  types
- **Improved Logging**: Structured logging with configurable levels and colors

### Fixed

- All test suite failures (205 tests now passing)
- S1F content normalization and timestamp tolerance issues
- M1F encoding tests with proper binary file support
- HTML2MD frontmatter generation and CLI integration
- Security warning log format handling
- Path resolution issues in tests
- Memory efficiency for large file handling

### Security

- Removed dangerous placeholder directory creation
- Enhanced input validation
- Better path sanitization
- Improved handling of sensitive data detection

### Breaking Changes

- Internal APIs completely reorganized (CLI remains compatible)
- Module structure changed from single files to packages
- Python 3.10+ now required (was 3.9+)
- Some internal functions renamed or relocated

---

## [1.4.0] - 2025-05-19

### Added

- WordPress content export functionality (`wp_export_md.py`)
- Support for exporting WordPress posts, pages, and custom post types
- Conversion of WordPress HTML content to clean Markdown
- Preservation of WordPress metadata (author, date, categories, tags)
- Flexible filtering options for content export

### Changed

- Improved documentation structure
- Enhanced error handling in export tools

### Fixed

- Various minor bug fixes and improvements

---

## [1.3.0] - 2025-05-18

### Added

- `--max-file-size` parameter for filtering large files
- Size unit support (B, KB, MB, GB, TB)
- Recommended 50KB limit for text file merging

### Changed

- Improved file size handling and validation
- Better error messages for size-related issues

### Fixed

- File size calculation accuracy
- Edge cases in size parsing

---

## [1.2.0] - 2025-05-17

### Added

- Symlink handling with `--include-symlinks` and `--ignore-symlinks` options
- Cycle detection for symlinks to prevent infinite loops
- `--security-check` option with configurable levels (skip, warn, fail)
- Integration with detect-secrets for sensitive data detection

### Changed

- Improved file path resolution
- Better handling of special file types

### Fixed

- Symlink recursion issues
- Security scanning false positives

---

## [1.1.0] - 2025-05-16

### Added

- Content deduplication feature
- `--filename-mtime-hash` option for tracking file changes
- Better support for various text encodings
- Custom argument parser with improved error messages

### Changed

- Optimized file reading for better performance
- Improved separator style formatting
- Enhanced logging output

### Fixed

- Encoding detection issues
- Hash generation consistency
- Memory usage for large projects

---

## [1.0.0] - 2025-05-15

### Added

- Initial release of m1f (Make One File)
- s1f (Split One File) companion tool
- Basic file combination functionality
- Multiple separator styles (XML, Markdown, Plain)
- Gitignore support
- Archive creation (ZIP, TAR)
- Token counting for LLM context estimation

### Features

- Combine multiple files into single output
- Preserve file structure and metadata
- Configurable file filtering
- Multiple output formats
- Cross-platform compatibility

======= docs/SETUP.md ======
# m1f Setup Guide

## Prerequisites

You only need:

- **Python 3.10+** (check with `python --version` or `python3 --version`)
- **Git** (to clone the repository)

That's all! The installer handles everything else.

## Installation

### Linux/macOS

```bash
git clone https://github.com/franz-agency/m1f.git
cd m1f
source ./scripts/install.sh
```

**Important**: Use `source` (not just `./scripts/install.sh`) to activate
commands immediately.

### Windows

```powershell
git clone https://github.com/franz-agency/m1f.git
cd m1f
.\scripts\install.ps1
```

Then either:

- Restart PowerShell (recommended), or
- Reload profile: `. $PROFILE`

## What the Installer Does

The installation script automatically:

- ✅ Checks Python version (3.10+ required)
- ✅ Creates virtual environment
- ✅ Installs all dependencies
- ✅ Adds commands to your PATH
- ✅ Creates global command shortcuts
- ✅ Sets up symlinks

## Test Your Installation

```bash
m1f-help
m1f --help
```

## Available Commands

After installation, these commands are available globally:

- `m1f` - Main tool for combining files
- `m1f-s1f` - Split combined files back to original structure
- `m1f-html2md` - Convert HTML to Markdown
- `m1f-scrape` - Download websites for offline viewing
- `m1f-token-counter` - Count tokens in files
- `m1f-update` - Regenerate all m1f bundles
- `m1f-init` - Initialize m1f for your project (replaces m1f-link)
- `m1f-claude` - A wrapper for Claude AI and send infos about m1f. So claude now
  knows how to work with m1f
- `m1f-help` - Show help for all commands

## Uninstall

### Linux/macOS

```bash
cd /path/to/m1f
./scripts/uninstall.sh
```

### Windows

```powershell
cd C:\path\to\m1f
.\scripts\uninstall.ps1
```

---

## Manual Installation (Advanced)

If you prefer to install manually or the automatic installation fails:

### 1. Prerequisites

- Python 3.10 or higher
- Git
- pip

### 2. Clone and Setup Virtual Environment

```bash
git clone https://github.com/franz-agency/m1f.git
cd m1f

# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
# Linux/macOS:
source .venv/bin/activate
# Windows PowerShell:
.\.venv\Scripts\Activate.ps1
# Windows cmd:
.venv\Scripts\activate.bat

# Install dependencies
pip install -r requirements.txt
```

### 3. Generate Initial Bundles

```bash
m1f-update
```

### 4. Add to PATH

#### Linux/macOS

Add to your shell configuration file (`~/.bashrc` or `~/.zshrc`):

```bash
export PATH="/path/to/m1f/bin:$PATH"  # m1f tools
```

Then reload:

```bash
source ~/.bashrc  # or ~/.zshrc
```

#### Windows

**Option A: PowerShell Functions**

The install script already configures PowerShell functions. To reload them:

```powershell
. $PROFILE
```

**Option B: Add to System PATH**

1. Create batch files in a directory (e.g., `C:\m1f\batch\`)
2. Add that directory to your system PATH:
   - Win + X → System → Advanced system settings
   - Environment Variables → Path → Edit → New
   - Add your batch directory path

Example batch file (`m1f.bat`):

```batch
@echo off
cd /d "C:\path\to\m1f"
call .venv\Scripts\activate.bat
m1f %*
```

Create similar batch files for:

- `m1f-s1f.bat` → `m1f-s1f %*`
- `m1f-html2md.bat` → `m1f-html2md %*`
- `m1f-scrape.bat` → `m1f-scrape %*`
- `m1f-token-counter.bat` → `m1f-token-counter %*`

## Using m1f in Other Projects

### Quick Setup for AI-Assisted Development

When starting a new project with m1f, use the `m1f-init` command for quick
setup:

```bash
cd /your/project
m1f-init
```

This command:

- Creates `m1f/m1f.txt` - a symlink to the complete m1f documentation
- Analyzes your project structure
- Generates initial bundles with auxiliary files:
  - `m1f/<project>_complete.txt` - Full project bundle
  - `m1f/<project>_complete_filelist.txt` - List of all included files
  - `m1f/<project>_complete_dirlist.txt` - List of all directories
  - `m1f/<project>_docs.txt` - Documentation bundle
  - `m1f/<project>_docs_filelist.txt` - List of documentation files
  - `m1f/<project>_docs_dirlist.txt` - Documentation directories
- Creates a basic `.m1f.config.yml`
- Shows platform-specific next steps

#### Working with Generated File Lists

The file lists created by `m1f-init` can be edited to customize future bundles:

```bash
# Edit the complete file list to remove unwanted files
vi m1f/<project>_complete_filelist.txt

# Use the edited list to create a custom bundle
m1f -i m1f/<project>_complete_filelist.txt -o m1f/custom_bundle.txt

# Create a bundle from specific directories (edit dirlist first)
m1f -s . -i m1f/selected_dirs.txt -o m1f/specific_areas.txt
```

For advanced setup with topic-specific bundles (Linux/macOS only):

```bash
m1f-claude --setup
```

#### Example AI Prompts:

```bash
# Ask Claude Code to create a configuration
"Please read @m1f/m1f.txt and create a .m1f.config.yml
for my Python web project"

# Get help with specific use cases
"Based on @m1f/m1f.txt, how do I exclude all test
files but include fixture data?"

# Troubleshoot issues
"I'm getting this error: [error message]. Can you check
@m1f/m1f.txt to help me fix it?"
```

The AI will understand:

- All m1f commands and parameters
- How to create `.m1f.config.yml` files
- Preset system and file processing options
- Best practices for different project types

## Troubleshooting

### Python Version Error

Install Python 3.10+ from [python.org](https://python.org)

### PowerShell Execution Policy (Windows)

```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### Command Not Found

- Linux/macOS: Make sure you've run `source ~/.bashrc` (or `~/.zshrc`)
- Windows: Restart PowerShell or Command Prompt

### Permission Errors

- Linux/macOS: Make sure scripts are executable: `chmod +x scripts/*.sh`
- Windows: Run PowerShell as Administrator if needed

## Next Steps

- Read the
  [M1F Development Workflow](docs/01_m1f/04_m1f_development_workflow.md)
- Check out example presets in `presets/`
- Run `m1f --help` to explore options

======= research-data/README.md ======
# Research Data Directory

This directory contains all data generated by the m1f-research tool, including:

- **Scraped web content** - Raw HTML and converted Markdown files from web
  scraping
- **Research bundles** - Organized collections of research results
- **Metadata** - JSON files with research metadata and statistics
- **Analysis results** - LLM-generated analysis and summaries

## Structure

```
research-data/
├── README.md                 # This file
└── [topic-YYYYMMDD-HHMMSS]/ # Research sessions
    ├── research-bundle.md    # Main research bundle
    ├── metadata.json         # Research metadata
    ├── search_results.json   # Found URLs
    └── scraped/              # Individual scraped content
        └── [domain]/         # Content organized by domain
```

## Usage

When you run `m1f-research`, the output is automatically saved here unless you
specify a different location with `--output`.

Example:

```bash
m1f-research "python async programming"
# Output saved to: ./research-data/python-async-programming-20240120-143022/
```

## Why This Directory?

- **Persistent Storage**: Research results are saved for future reference
- **Organization**: Each research session gets its own timestamped folder
- **Gitignore**: All contents (except this README) are excluded from version
  control
- **Clean Separation**: Keeps research data separate from source code

## Note

This directory is excluded from git (except this README) because:

- Research data can be large
- Content is user-specific
- Data can be regenerated
- May contain scraped content with various licenses

======= tasks/README.md ======
# AI Context File Generator & Auto-Bundling System

## Overview

This directory contains tasks for creating selective file bundles that serve as
context for AI interactions. The system includes:

1. **Manual Selection** - Create bundles from carefully selected files
2. **Auto-Bundling** - Automatically organize project content into topic-based
   bundles
3. **Preset System** - Apply file-specific processing rules
4. **Watch Mode** - Automatically regenerate bundles when files change

Using the `m1f` tool and auto-bundling scripts, you can create optimized context
files for AI assistants.

## VS Code Setup

To use these tasks in VS Code:

1. Create a `.vscode` directory in your project root (if it doesn't exist)
2. Copy the example tasks configuration:
   ```bash
   cp tasks/example.tasks.json .vscode/tasks.json
   ```
3. Now you can access all tasks via the Command Palette (`Ctrl+Shift+P` →
   "Tasks: Run Task")

The `example.tasks.json` file references all available task definitions:

- `m1f.json` - Manual file selection tasks
- `auto_bundle.json` - Automated bundling tasks with preset support
- `linting.json` - Code quality and linting tasks

**Note**: The `.vscode` directory is typically gitignored, so each developer can
customize their tasks.json as needed.

## When to Use This Tool

**Do NOT use this tool if:**

- You only have a few files to work with (just reference them directly)
- You want to include your entire project (this will overwhelm the AI with
  irrelevant information)

**DO use this tool when:**

- You have a large project (hundreds or thousands of files)
- You need to provide context from ~50 key files that are most relevant to your
  current task
- You want to give the AI a focused understanding of specific parts of your
  codebase

## Purpose

When working with AI assistants (like those in Windsurf, Cursor, VS Code, or
other AI-enabled editors), providing selective but sufficient context is
essential. This tool helps you to:

1. Select and combine only the most important files into a single document
2. Include metadata that helps AI systems understand file relationships
3. Create machine-readable formats optimized for Large Language Models
4. Efficiently manage context limitations by focusing on what matters

## Available Task Files

This directory contains several task definition files:

### Task Definition Files

1. **m1f.json** - Core context generation tasks for manual file selection
2. **auto_bundle.json** - Automated bundling tasks with 11 different bundle
   types
3. **linting.json** - Code quality and linting tasks
4. **example.tasks.json** - Example VS Code tasks.json that integrates all task
   files

### Supporting Files

- **ai_context_files.txt** - Example list of files for manual context creation
- **wp\_\*.txt** - WordPress-specific include/exclude patterns

### m1f.json - Core Context Generation Tasks

The `m1f.json` file defines core tasks for manual file selection:

### 1. AI Context: Create Combined File

This task combines files from your project with common exclusions:

- **Source**: Project directory with extensive filtering
- **Output**: `.gen/ai_context.m1f.txt`
- **Excludes**: Non-relevant directories (`node_modules`, `.git`, `.venv`, etc.)
- **Format**: Machine-readable format with clear file separators
- **Optimization**: Uses `--minimal-output` to generate only the combined file
  without extra logs or lists
- **Best for**: Initial exploration when you're unsure which files are important

### 2. AI Context: Create From Input List (Recommended)

This task combines only the specific files you select:

- **Source**: Files explicitly listed in `tasks/ai_context_files.txt`
- **Output**: `.gen/ai_context_custom.m1f.txt`
- **Format**: Same machine-readable format
- **Efficiency**: Uses `--minimal-output --quiet` for silent operation with no
  auxiliary files
- **Best for**: Focused work when you know which ~20-50 files are most relevant

## Practical Usage Guide

### Step 1: Identify Key Files

Start by identifying the most important files for your current task:

- **Core files**: Main entry points, key modules, and configuration files
- **Relevant to your task**: Files you're actively working on or need to
  understand
- **Context providers**: Files that explain project structure or domain concepts
- **Aim for 20-50 files**: This provides enough context without overwhelming the
  AI

### Step 2: Create Your Custom File List

The recommended approach is to create a task-specific file list in
`ai_context_files.txt`:

```
# Core modules for authentication feature
${workspaceFolder}/auth/user.py
${workspaceFolder}/auth/permissions.py
${workspaceFolder}/auth/tokens.py

# Configuration
${workspaceFolder}/config/settings.py

# Related utilities
${workspaceFolder}/utils/crypto.py
```

### Step 3: Generate the Context File

1. Open Windsurf/VS Code Command Palette (`Ctrl+Shift+P`)
2. Type "Tasks: Run Task" and press Enter
3. Select "AI Context: Create From Input List" (recommended)
4. The task will run and create the output file in the `.gen` directory

### Step 4: Use with AI

1. Open the generated `.m1f.txt` file in your editor
2. In your AI-enabled editor (Windsurf, Cursor, VS Code):
   - Include this file in the AI's context using the editor's method
   - In Windsurf: Type `@filename` in chat or use the "Add to Context" option

### auto_bundle.json - Automated Topic-Based Bundling

The `auto_bundle.json` file provides tasks for automatic bundle generation:

#### Available Auto-Bundle Tasks:

1. **Auto Bundle: Docs Bundle** - All documentation, READMEs, and markdown files
2. **Auto Bundle: Source Bundle** - All source code files
3. **Auto Bundle: Tests Bundle** - All test files and fixtures
4. **Auto Bundle: Complete Bundle** - Combined documentation, source, and tests
5. **Auto Bundle: Custom Focus** - Topic-specific bundles (html2md, m1f, s1f,
   etc.)
6. **Auto Bundle: Watch and Update** - Monitor changes and regenerate bundles
7. **Auto Bundle: With Preset** - Apply processing rules during bundling
8. **Auto Bundle: Generate All Bundles** - Creates all standard bundles in one
   go
9. **Auto Bundle: Preset - All Standard** - Creates all standard preset-based
   bundles
10. **Auto Bundle: Preset - Focused** - Creates focused bundles using presets
11. **Auto Bundle: List Presets** - Lists all available presets and their groups

#### Using Auto-Bundle Tasks:

1. Open VS Code Command Palette (`Ctrl+Shift+P`)
2. Type "Tasks: Run Task"
3. Select an auto-bundle task (e.g., "Auto Bundle: Complete Bundle")
4. The bundle will be created in `.ai-context/`

#### Configuration:

Auto-bundling is configured via `.m1f.config.yml`. See the
[Auto Bundle Guide](../docs/01_m1f/06_auto_bundle_guide.md) for details.

#### Preset-Based Auto-Bundling:

The preset-based tasks (9-11) use the `scripts/auto_bundle_preset.sh` script
which leverages the m1f preset system:

- **Intelligent file filtering** - Presets apply smart includes/excludes based
  on file type
- **Per-file-type processing** - Different settings for different file
  extensions
- **Security scanning control** - Enable/disable security checks per file type
- **Size limit management** - Different size limits for CSS vs PHP files
- **Processing actions** - Minify, strip tags, compress whitespace per file type

Example preset usage:

```bash
# Create all standard bundles using presets
m1f-update all

# Create WordPress-specific bundles
m1f-update focus wordpress

# Use specific preset with group
m1f auto-bundle preset web-project frontend
```

Available presets:

- `wordpress` - WordPress themes and plugins with appropriate excludes
- `web-project` - Modern web projects with frontend/backend separation
- `documentation` - Documentation-focused bundles
- `example-globals` - Example with comprehensive global settings

See [m1f Presets Documentation](../docs/01_m1f/02_m1f_presets.md) for detailed
preset information.

## Best Practices for Effective AI Context

### For Manual Selection:

1. **Be selective**: Choose only the most important 20-50 files for your current
   task
2. **Include structure files**: Add README.md, configuration files, and key
   interfaces
3. **Group related files**: When customizing your list, organize files by
   related functionality
4. **Comment your file lists**: Add comments in `ai_context_files.txt` to
   explain why files are included

### For Auto-Bundling:

1. **Use focused bundles**: Start with topic-specific bundles (docs, src) before
   using complete
2. **Configure properly**: Customize `.m1f.config.yml` for your project
   structure
3. **Apply presets**: Use the preset system to optimize file processing
4. **Watch mode**: Use watch tasks during active development
5. **Refresh regularly**: Regenerate bundles after significant changes

## Customizing the Process

You can customize the tasks by editing `m1f.json` for your specific needs:

- Modify output file locations and naming conventions
- Adjust file exclusion patterns for your project structure
- Add task-specific configurations for different project components

## Additional Options

Consider these advanced options from `m1f` for specific needs:

- `--include-dot-paths`: Useful for including WordPress-specific configuration
  files like `.htaccess` or other dot files and directories (e.g., `.config/`,
  `.github/`) if they are relevant to your context. By default, all files and
  directories starting with a dot are excluded.
- `--separator-style`: While `MachineReadable` is generally recommended for AI
  context files, you can explore other styles if needed.
- `--skip-output-file`: Executes all operations (logs, additional files, etc.)
  but skips writing the final .m1f.txt output file. Useful when you're only
  interested in generating the file and directory listings or logs, but not the
  combined content file itself.

For a complete list of all available options and their detailed descriptions,
run:

```
m1f --help
```

## Machine-Readable Format

The default separator style "MachineReadable" optimizes the combined file for AI
understanding:

```
--- PYMK1F_BEGIN_FILE_METADATA_BLOCK_f84a9c25-b8cf-4e6a-a39d-842d7fe3b6e1 ---
METADATA_JSON:
{
    "original_filepath": "relative/path.ext",
    "original_filename": "path.ext",
    "timestamp_utc_iso": "2023-01-01T12:00:00Z",
    "type": ".ext",
    "size_bytes": 1234,
    "checksum_sha256": "abc123..."
}
--- PYMK1F_END_FILE_METADATA_BLOCK_f84a9c25-b8cf-4e6a-a39d-842d7fe3b6e1 ---
--- PYMK1F_BEGIN_FILE_CONTENT_BLOCK_f84a9c25-b8cf-4e6a-a39d-842d7fe3b6e1 ---

[file content]

--- PYMK1F_END_FILE_CONTENT_BLOCK_f84a9c25-b8cf-4e6a-a39d-842d7fe3b6e1 ---
```

This format ensures the AI can clearly identify file boundaries and understand
metadata about each file, making it more effective in processing your selected
files. The JSON metadata includes the original filepath, filename, timestamp in
ISO format, file type, size in bytes, and SHA256 checksum for data integrity
verification. It's particularly suitable for automated processing and splitting
back into individual files.

## Author

Franz und Franz - https://franz.agency

## Use Case: WordPress Theme/Plugin Context File

When developing WordPress themes or plugins, you often need to provide an AI
assistant with the context of your specific theme/plugin files. Here's how you
can create a single context file for this purpose using `m1f.py`:

### 1. Strategically Select WordPress Files

To create an effective AI context for WordPress development, carefully select
files that represent the functionality or problem area you're focusing on.
Consider these categories:

- **Core Theme Files**:
  - `style.css` (for theme identity and metadata)
  - `functions.php` (critical for theme logic, hooks, and filters)
  - `index.php`, `header.php`, `footer.php`, `sidebar.php` (main template
    structure)
  - Specific template files relevant to your task: `single.php`, `page.php`,
    `archive.php`, `category.php`, `tag.php`, `search.php`, `404.php`,
    `front-page.php`, `home.php`.
  - Template parts (e.g., files in `template-parts/` directory like
    `content-page.php`).
  - Customizer settings and controls if relevant (`inc/customizer.php`).
  - Key JavaScript (e.g., `assets/js/custom.js`) and CSS files.

- **Core Plugin Files**:
  - The main plugin file (e.g., `your-plugin-name/your-plugin-name.php`) which
    includes the plugin header.
  - Files containing main classes, action/filter hooks, shortcodes, and admin
    panel logic.
  - AJAX handlers, REST API endpoint definitions.
  - Files related to Custom Post Types (CPTs) or taxonomies defined by the
    plugin.
  - Key JavaScript and CSS files specific to the plugin's functionality.

- **Feature-Specific Files**: If you are working on a particular feature (e.g.,
  WooCommerce integration, a custom contact form, a specific admin page):
  - Include all files directly related to that feature from both your theme and
    any relevant plugins.
  - For example, for WooCommerce: relevant template overrides in
    `your-theme/woocommerce/`, custom functions related to WooCommerce in
    `functions.php` or a plugin.

- **Problem-Specific Files**: If debugging, include files involved in the error
  stack trace or areas where the bug is suspected.

- **Important Note on Parent/Child Themes**:
  - If using a child theme, include relevant files from _both_ the child theme
    and parent theme that interact or are being overridden.

### 2. Structure Your Input File List (`my_wp_context_files.txt`)

Create a plain text file (e.g., `my_wp_context_files.txt`) listing the absolute
or relative paths to your selected files. Organize and comment this list for
clarity, especially if you plan to reuse or modify it.

**Example `my_wp_context_files.txt` for a theme feature and a related plugin:**

```plaintext
# Paths should be relative to your project root, or absolute.
# For VS Code tasks, ${workspaceFolder} can be used.

# =====================================
# My Custom Theme: "AwesomeTheme"
# Working on: Homepage Slider Feature
# =====================================

# Core Theme Files
wp-content/themes/AwesomeTheme/style.css
wp-content/themes/AwesomeTheme/functions.php
wp-content/themes/AwesomeTheme/header.php
wp-content/themes/AwesomeTheme/footer.php
wp-content/themes/AwesomeTheme/front-page.php

# Homepage Slider Specifics
wp-content/themes/AwesomeTheme/template-parts/homepage-slider.php
wp-content/themes/AwesomeTheme/includes/slider-customizer-settings.php
wp-content/themes/AwesomeTheme/assets/js/homepage-slider.js
wp-content/themes/AwesomeTheme/assets/css/homepage-slider.css

# =====================================
# Related Plugin: "UtilityPlugin"
# Used by: Homepage Slider for data
# =====================================
wp-content/plugins/UtilityPlugin/utility-plugin.php
wp-content/plugins/UtilityPlugin/includes/class-data-provider.php
wp-content/plugins/UtilityPlugin/includes/cpt-slides.php

# =====================================
# General WordPress Context (Optional)
# =====================================
# Consider adding if debugging core interactions, but be selective:
# wp-includes/post.php
# wp-includes/query.php
```

**Tips for your list:**

- Use comments (`#`) to organize sections or explain choices.
- Start with a small, focused set of files and expand if the AI needs more
  context.
- Paths are typically relative to where you run the `m1f.py` script, or from the
  `${workspaceFolder}` if using VS Code tasks.

### 3. Generate the Combined Context File

Run `m1f` from your terminal, pointing to your input file list and specifying an
output file. It's recommended to use the `MachineReadable` separator style.

```bash
m1f \
  --input-file my_wp_context_files.txt \
  --output-file .gen/wordpress_context.m1f.txt \
  --separator-style MachineReadable \
  --force \
  --minimal-output
```

**Explanation of options:**

- `--input-file my_wp_context_files.txt`: Specifies the list of files to
  include.
- `--output-file .gen/wordpress_context.m1f.txt`: Defines where the combined
  file will be saved. Using a `.gen` or `.ai-context` subfolder is good
  practice.
- `--separator-style MachineReadable`: Ensures the output is easily parsable by
  AI tools.
- `--force`: Overwrites the output file if it already exists.
- `--minimal-output`: Prevents the script from generating auxiliary files like
  file lists or logs, keeping your project clean.

You can also generate only the auxiliary files (file list and directory list)
without creating the combined file:

```bash
m1f \
  --input-file my_wp_context_files.txt \
  --output-file .gen/wordpress_auxiliary_only.m1f.txt \
  --skip-output-file \
  --verbose
```

This will create `wordpress_auxiliary_only_filelist.txt` and
`wordpress_auxiliary_only_dirlist.txt` files but won't generate the combined
content file.

### 4. Using the Context File with Your AI Assistant

Once `wordpress_context.m1f.txt` is generated:

1.  Open the file in your AI-enabled editor (e.g., Cursor, VS Code with AI
    extensions).
2.  Use your editor's features to add this file to the AI's context. For
    example, in Cursor, you can type `@wordpress_context.m1f.txt` in the chat or
    use the "Add to Context" option.
3.  Now, when you ask the AI questions or request code related to your WordPress
    theme/plugin, it will have the specific context of your selected files.

### Example: Creating a VS Code Task

You can automate this process by creating a VS Code task in your
`.vscode/tasks.json` file:

```json
{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "WordPress: Generate AI Context from List",
      "type": "shell",
      "command": "python",
      "args": [
        "${workspaceFolder}/tools/m1f.py",
        "--input-file",
        "${workspaceFolder}/my_wp_context_files.txt",
        "--output-file",
        "${workspaceFolder}/.gen/wordpress_context.m1f.txt",
        "--separator-style",
        "MachineReadable",
        "--force",
        "--minimal-output",
        "--quiet"
      ],
      "problemMatcher": [],
      "group": {
        "kind": "build",
        "isDefault": true
      },
      "detail": "Combines specified WordPress theme/plugin files into a single context file for AI."
    },
    {
      "label": "WordPress: Generate File Lists Only",
      "type": "shell",
      "command": "python",
      "args": [
        "${workspaceFolder}/tools/m1f.py",
        "--input-file",
        "${workspaceFolder}/my_wp_context_files.txt",
        "--output-file",
        "${workspaceFolder}/.gen/wordpress_auxiliary.m1f.txt",
        "--skip-output-file",
        "--verbose"
      ],
      "problemMatcher": [],
      "group": "build",
      "detail": "Generates file and directory lists without creating the combined file."
    }
  ]
}
```

With this task, you can simply run "WordPress: Generate AI Context from List"
from the VS Code Command Palette to update your context file. Remember to
maintain your `my_wp_context_files.txt` list as your project evolves.

This approach helps you provide targeted and relevant information to your AI
assistant, leading to more accurate and helpful responses for your WordPress
development tasks.

## Example: Organizing a Large Project with `m1f`

When dealing with a project that contains hundreds or thousands of files, start
by generating a complete file and directory listing without creating the merged
context file. Run the **Project Review: Generate Lists** task. It calls `m1f`
with `--skip-output-file` and saves two inventory files to the `m1f` directory:

- `m1f/project_review_filelist.txt`
- `m1f/project_review_dirlist.txt`

Review these lists and decide which areas of the project you want to load into
your AI assistant. Typical numbered context files might include:

- `1_doc.txt` – the full documentation bundle
- `2_template.txt` – template files from your theme
- `3_plugin.txt` – a specific plugin or a group of plugins

Store each generated context file in the `m1f` folder with a number prefix for
quick referencing in Windsurf, Cursor, or Claude (for example `@m1f/1_doc.txt`).

To keep the inventory current during development, launch **Project Review: Watch
for Changes**. This background watcher reruns the list generation whenever files
are modified.

Remember to add `m1f/` (and `.1f/` if used) to your `.gitignore` so these helper
files stay out of version control.

======= tasks/ai_context_files.txt ======
# This is an example file list for AI context bundling
# Group related files by feature/functionality with comments

# Core project documentation
/path/to/project/README.md
/path/to/project/ARCHITECTURE.md
/path/to/project/docs/api_reference.md

# Authentication feature
/path/to/project/auth/models.py           # Data models for users and permissions
/path/to/project/auth/views.py            # Authentication API endpoints
/path/to/project/auth/middleware.py       # Auth verification middleware
/path/to/project/auth/tests/test_auth.py  # Key tests that explain requirements

# Database configuration
/path/to/project/config/database.py       # Database connection settings
/path/to/project/db/migrations/001_init.py # Shows schema structure
/path/to/project/db/models/base.py        # Base model classes

# Frontend components
/path/to/project/frontend/components/AuthForm.jsx
/path/to/project/frontend/components/Dashboard.jsx
/path/to/project/frontend/services/api.js # API integration points

# Utility functions
/path/to/project/utils/logging.py
/path/to/project/utils/validators.py

# Configuration files
/path/to/project/.env.example             # Shows required environment variables
/path/to/project/config/settings.py       # Application settings

# Main application entry points
/path/to/project/app.py                   # Main application initialization
/path/to/project/server.py                # Server startup code

# Add task-specific files here as needed

======= tasks/wp_excludes.txt ======
# WordPress Paths to Exclude

# Core WordPress system files
wp-admin/
wp-includes/

# Uploads directory (usually too large and contains only binary media files)
wp-content/uploads/

# Cache files
wp-content/cache/
wp-content/advanced-cache.php
wp-content/wp-cache-config.php
wp-content/object-cache.php

# Default and inactive themes
wp-content/themes/twentytwenty/
wp-content/themes/twentytwentyone/
wp-content/themes/twentytwentytwo/
wp-content/themes/twentytwentythree/
wp-content/themes/twentytwentyfour/

# Common plugins not relevant for development
wp-content/plugins/akismet/
wp-content/plugins/hello-dolly/
wp-content/plugins/wordpress-seo/
wp-content/plugins/wp-super-cache/
wp-content/plugins/wordfence/
wp-content/plugins/elementor/
wp-content/plugins/woocommerce/

# Language files
wp-content/languages/plugins/
wp-content/languages/themes/
wp-content/languages/continents-cities*.po
wp-content/languages/admin*.po

# Backup files
*.bak
*.backup
*.old
*-backup.*
~*

# Plugin/theme development build artifacts
node_modules/
dist/
build/
vendor/
.git/
.github/
.vscode/

# Logs and temporary files
*.log
*.tmp
.DS_Store
Thumbs.db

# Database dumps
*.sql

# Minified files (keep the source files, exclude minified versions)
*.min.js
*.min.css 

======= tasks/wp_plugin_includes.txt ======
# WordPress Plugin Files to Include

# Main plugin file
wp-content/plugins/myplugin/myplugin.php

# Plugin structure
wp-content/plugins/myplugin/includes/*.php
wp-content/plugins/myplugin/admin/*.php
wp-content/plugins/myplugin/public/*.php
wp-content/plugins/myplugin/includes/class-*.php
wp-content/plugins/myplugin/admin/class-*.php
wp-content/plugins/myplugin/public/class-*.php

# API and REST endpoints
wp-content/plugins/myplugin/includes/api/*.php
wp-content/plugins/myplugin/includes/rest-api/*.php

# Templates and partials
wp-content/plugins/myplugin/templates/*.php
wp-content/plugins/myplugin/partials/*.php

# Assets
wp-content/plugins/myplugin/assets/js/*.js
wp-content/plugins/myplugin/assets/css/*.css
wp-content/plugins/myplugin/admin/js/*.js
wp-content/plugins/myplugin/admin/css/*.css
wp-content/plugins/myplugin/public/js/*.js
wp-content/plugins/myplugin/public/css/*.css

# Blocks (if using Gutenberg blocks)
wp-content/plugins/myplugin/blocks/*.php
wp-content/plugins/myplugin/blocks/*.js
wp-content/plugins/myplugin/blocks/*.json

# Languages and internationalization
wp-content/plugins/myplugin/languages/*.pot
wp-content/plugins/myplugin/languages/*.po
wp-content/plugins/myplugin/languages/*.mo

# Configuration
wp-content/plugins/myplugin/config/*.php
wp-content/plugins/myplugin/uninstall.php 

======= tasks/wp_theme_includes.txt ======
# WordPress Theme Files to Include

# Core theme files
wp-content/themes/mytheme/style.css
wp-content/themes/mytheme/functions.php
wp-content/themes/mytheme/index.php
wp-content/themes/mytheme/header.php
wp-content/themes/mytheme/footer.php
wp-content/themes/mytheme/sidebar.php
wp-content/themes/mytheme/page.php
wp-content/themes/mytheme/single.php
wp-content/themes/mytheme/archive.php
wp-content/themes/mytheme/search.php
wp-content/themes/mytheme/404.php
wp-content/themes/mytheme/comments.php

# Template parts
wp-content/themes/mytheme/template-parts/*.php

# Theme includes and functionality
wp-content/themes/mytheme/inc/*.php
wp-content/themes/mytheme/includes/*.php

# Theme assets
wp-content/themes/mytheme/assets/js/*.js
wp-content/themes/mytheme/assets/css/*.css
wp-content/themes/mytheme/assets/scss/*.scss

# WooCommerce templates (if used)
wp-content/themes/mytheme/woocommerce/*.php

# Block patterns and templates
wp-content/themes/mytheme/patterns/*.php
wp-content/themes/mytheme/block-templates/*.html
wp-content/themes/mytheme/block-template-parts/*.html

# Configuration files
wp-content/themes/mytheme/theme.json 

======= tasks/wp_theme_plugin_includes.txt ======
# WordPress Theme Files to Include

# Core theme files
wp-content/themes/mytheme/style.css
wp-content/themes/mytheme/functions.php
wp-content/themes/mytheme/index.php
wp-content/themes/mytheme/header.php
wp-content/themes/mytheme/footer.php
wp-content/themes/mytheme/sidebar.php
wp-content/themes/mytheme/page.php
wp-content/themes/mytheme/single.php
wp-content/themes/mytheme/archive.php
wp-content/themes/mytheme/search.php
wp-content/themes/mytheme/404.php
wp-content/themes/mytheme/comments.php

# Template parts
wp-content/themes/mytheme/template-parts/*.php

# Theme includes and functionality
wp-content/themes/mytheme/inc/*.php
wp-content/themes/mytheme/includes/*.php

# Theme assets
wp-content/themes/mytheme/assets/js/*.js
wp-content/themes/mytheme/assets/css/*.css
wp-content/themes/mytheme/assets/scss/*.scss

# WooCommerce templates (if used)
wp-content/themes/mytheme/woocommerce/*.php

# Block patterns and templates
wp-content/themes/mytheme/patterns/*.php
wp-content/themes/mytheme/block-templates/*.html
wp-content/themes/mytheme/block-template-parts/*.html

# Configuration files
wp-content/themes/mytheme/theme.json
# WordPress Plugin Files to Include

# Main plugin file
wp-content/plugins/myplugin/myplugin.php

# Plugin structure
wp-content/plugins/myplugin/includes/*.php
wp-content/plugins/myplugin/admin/*.php
wp-content/plugins/myplugin/public/*.php
wp-content/plugins/myplugin/includes/class-*.php
wp-content/plugins/myplugin/admin/class-*.php
wp-content/plugins/myplugin/public/class-*.php

# API and REST endpoints
wp-content/plugins/myplugin/includes/api/*.php
wp-content/plugins/myplugin/includes/rest-api/*.php

# Templates and partials
wp-content/plugins/myplugin/templates/*.php
wp-content/plugins/myplugin/partials/*.php

# Assets
wp-content/plugins/myplugin/assets/js/*.js
wp-content/plugins/myplugin/assets/css/*.css
wp-content/plugins/myplugin/admin/js/*.js
wp-content/plugins/myplugin/admin/css/*.css
wp-content/plugins/myplugin/public/js/*.js
wp-content/plugins/myplugin/public/css/*.css

# Blocks (if using Gutenberg blocks)
wp-content/plugins/myplugin/blocks/*.php
wp-content/plugins/myplugin/blocks/*.js
wp-content/plugins/myplugin/blocks/*.json

# Languages and internationalization
wp-content/plugins/myplugin/languages/*.pot
wp-content/plugins/myplugin/languages/*.po
wp-content/plugins/myplugin/languages/*.mo

# Configuration
wp-content/plugins/myplugin/config/*.php
wp-content/plugins/myplugin/uninstall.php

======= tests/README.md ======
# M1F Test Suite Documentation

This directory contains the comprehensive test suite for the m1f tool suite, including m1f, s1f, html2md, m1f-scrape, and m1f-research tools. Built with Python 3.10+ features and modern testing practices.

## Overview

- **43 test files** with ~290 test methods
- **Comprehensive fixture system** with module-specific extensions
- **Multi-platform support** with Windows-specific handling
- **Security testing** with path traversal and secret detection
- **Performance testing** for large files and parallel processing
- **Real-world test data** including international filenames

## Test Structure

```
tests/
├── conftest.py                    # Global fixtures and test configuration
├── base_test.py                   # Base test classes with common utilities
├── test_html2md_server.py         # HTML2MD server tests
├── test_html2md_server_fixed.py   # Fixed server tests
├── test_m1f_claude_improvements.py # Claude-suggested improvements
├── test_simple_server.py          # Simple server tests
│
├── m1f/                           # m1f tests (23 test files, ~180 methods)
│   ├── conftest.py               # m1f-specific fixtures
│   ├── test_m1f_basic.py         # Core functionality
│   ├── test_m1f_advanced.py      # Advanced features
│   ├── test_m1f_encoding.py      # Character encoding
│   ├── test_m1f_integration.py   # End-to-end tests
│   ├── test_m1f_presets_*.py     # Preset system (basic, integration, v3.2)
│   ├── test_security_check.py    # Secret detection
│   ├── test_path_traversal_security.py # Security vulnerabilities
│   ├── test_content_deduplication.py   # File deduplication
│   ├── test_parallel_processing.py     # Async operations
│   ├── test_symlinks*.py         # Symbolic link handling
│   ├── test_large_file.py        # Performance testing
│   ├── test_cross_platform_paths.py # Windows/Linux compatibility
│   └── source/                   # Test data
│       ├── glob_*/               # Pattern matching tests
│       ├── exotic_encodings/     # Non-UTF8 encodings
│       └── advanced_glob_test/   # International filenames
│
├── s1f/                          # s1f tests (6 test files, ~40 methods)
│   ├── conftest.py              # s1f-specific fixtures
│   ├── test_s1f_basic.py        # Core extraction
│   ├── test_s1f_async.py        # Async operations
│   ├── test_s1f_encoding.py     # Encoding preservation
│   ├── test_s1f_target_encoding.py # Encoding conversion
│   ├── test_s1f.py              # General functionality
│   └── test_path_traversal_security.py # Security tests
│
├── html2md/                      # html2md tests (5 test files, ~30 methods)
│   ├── test_html2md.py          # Core conversion
│   ├── test_integration.py      # End-to-end tests
│   ├── test_claude_integration.py # AI optimization
│   ├── test_scrapers.py         # Scraping backends
│   ├── test_local_scraping.py   # Local file processing
│   ├── source/html/             # Test HTML files
│   ├── expected/                # Expected outputs
│   └── scraped_examples/        # Real-world examples
│
├── html2md_server/               # HTML2MD test infrastructure
│   ├── server.py                # Flask test server
│   ├── manage_server.py         # Server management
│   ├── test_pages/              # 8+ complex HTML test pages
│   ├── static/                  # CSS/JS resources
│   └── README.md                # Server documentation
│
└── research/                     # m1f-research tests (5 test files, ~25 methods)
    ├── test_research_workflow.py # End-to-end workflows
    ├── test_llm_providers.py    # LLM integrations
    ├── test_content_analysis.py # Content analysis
    ├── test_analysis_templates.py # Template system
    └── test_scraping_integration.py # Scraping integration
```

## Key Features

### Global Test Infrastructure (conftest.py)

**Core Fixtures:**
- `tools_dir` - Path to tools directory
- `test_data_dir` - Path to test data
- `temp_dir` - Temporary directory with auto-cleanup
- `isolated_filesystem` - Isolated filesystem environment
- `create_test_file` - Factory for creating test files
- `create_test_directory_structure` - Complex directory creation
- `capture_logs` - Log output capture and examination
- `anyio_backend` - Async testing support

**Platform Support:**
- Windows-specific cleanup handling
- Cross-platform path separator handling
- File locking issue mitigation

**Test Markers:**
```python
@pytest.mark.unit         # Fast, isolated unit tests
@pytest.mark.integration  # End-to-end integration tests
@pytest.mark.slow        # Long-running tests
@pytest.mark.requires_git # Tests requiring git
@pytest.mark.encoding    # Encoding-related tests
```

## Running Tests

### Basic Commands

```bash
# Run all tests
pytest

# Run with verbose output
pytest -vv

# Run specific tool tests
pytest tests/m1f/
pytest tests/s1f/
pytest tests/html2md/
pytest tests/research/

# Run by marker
pytest -m unit              # Fast unit tests only
pytest -m integration       # Integration tests only
pytest -m "not slow"       # Skip slow tests
pytest -m encoding         # Encoding tests only
```

### Advanced Testing

```bash
# Run with coverage
pytest --cov=tools --cov-report=html --cov-report=term

# Run specific test patterns
pytest -k "test_encoding"   # All encoding tests
pytest -k "test_security"   # Security tests

# Debug options
pytest -x                   # Stop on first failure
pytest --pdb               # Drop into debugger on failure
pytest -s                  # Show print statements

# Parallel execution
pytest -n auto             # Use all CPU cores
```

### Test Categories by Tool

#### M1F Tests
- **Basic**: Core file bundling functionality
- **Advanced**: Complex scenarios, edge cases
- **Encoding**: UTF-8, UTF-16, exotic encodings
- **Security**: Path traversal, secret detection
- **Presets**: YAML preset system, file-specific rules
- **Performance**: Large files, parallel processing
- **Cross-platform**: Windows/Linux compatibility

#### S1F Tests
- **Extraction**: All M1F format variations
- **Async**: Asynchronous file operations
- **Encoding**: Preservation and conversion
- **Security**: Malicious path protection

#### HTML2MD Tests
- **Conversion**: HTML to Markdown accuracy
- **Scrapers**: BeautifulSoup, Playwright
- **AI Integration**: Claude-powered optimization
- **Local Processing**: File system operations

#### Research Tests
- **Workflows**: End-to-end research automation
- **LLM Providers**: Provider abstraction testing
- **Content Analysis**: Scoring and analysis
- **Templates**: Analysis template system

## Writing New Tests

### Test Structure Template

```python
from __future__ import annotations

import pytest
from pathlib import Path
from ..base_test import BaseM1FTest  # or BaseS1FTest, etc.

class TestFeatureName(BaseM1FTest):
    """Tests for specific feature area."""
    
    @pytest.mark.unit
    async def test_specific_behavior(self, temp_dir: Path, create_test_file):
        """Test description explaining what and why."""
        # Arrange
        test_file = create_test_file("test.txt", "content")
        
        # Act
        result = await some_function(test_file)
        
        # Assert
        assert result.success
        assert "expected" in result.output
```

### Best Practices

1. **Use Type Hints**: All functions should have complete type annotations
2. **Clear Naming**: Test names should describe the behavior being tested
3. **Docstrings**: Explain what the test validates and why
4. **AAA Pattern**: Arrange-Act-Assert structure
5. **Isolation**: Tests should not depend on each other
6. **Fixtures**: Use fixtures for common setup/teardown
7. **Markers**: Apply appropriate test markers
8. **Cleanup**: Ensure proper resource cleanup

## Test Servers

### HTML2MD Test Server

```bash
# Start the test server
cd tests/html2md_server
python server.py

# Or use management script
python manage_server.py start

# Access test pages
http://localhost:8080/
```

Provides:
- Complex HTML test pages (CSS Grid, Flexbox, nested structures)
- Modern web features (HTML5, semantic markup)
- Real documentation examples
- Edge cases and malformed HTML

## Troubleshooting

### Common Issues

1. **Import Errors**: Ensure tools directory is in PYTHONPATH
2. **Fixture Not Found**: Check conftest.py placement
3. **Encoding Failures**: Some tests require specific system encodings
4. **Permission Errors**: Temporary file cleanup issues
5. **Port Conflicts**: Test server requires port 8080
6. **Async Errors**: Ensure anyio is installed

### Platform-Specific Issues

**Windows:**
- File locking during cleanup
- Path separator differences
- Encoding defaults

**Linux/macOS:**
- Symbolic link tests require permissions
- Case-sensitive filesystem assumptions

## Test Data Organization

### M1F Test Data (`m1f/source/`)
- Pattern matching test cases
- International filenames
- Various encodings (UTF-8, UTF-16, Latin-1, etc.)
- Nested directory structures
- Binary and text files

### S1F Test Data
- Pre-generated M1F bundles
- Various separator styles
- Corrupted/malformed inputs

### HTML2MD Test Data
- Complex HTML structures
- Real website snapshots
- Various content types
- Edge cases

## Contributing

When adding new tests:

1. **Follow existing patterns** - Consistency is key
2. **Add to appropriate directory** - Keep tests organized
3. **Update fixtures** - Add reusable components to conftest.py
4. **Document special requirements** - Note any dependencies
5. **Run full test suite** - Ensure no regressions
6. **Update this README** - Document new test categories

## Performance Considerations

- Tests use async I/O where possible
- Large file tests are marked as `@pytest.mark.slow`
- Parallel test execution is supported
- Resource cleanup is automatic

## Security Testing

The test suite includes comprehensive security testing:
- Path traversal attempts
- Secret detection validation
- Input sanitization
- Malformed data handling

======= docs/01_m1f/README.md ======
# m1f Documentation

Welcome to the m1f (Make One File) documentation. This tool combines multiple
text files into a single output file, perfect for providing context to Large
Language Models (LLMs) and creating bundled documentation.

## Table of Contents

### Getting Started

- [**00_m1f.md**](00_m1f.md) - Main documentation with features, usage examples,
  and architecture
- [**01_quick_reference.md**](./01_quick_reference.md) - Quick command reference
  and common patterns
- [**02_cli_reference.md**](./02_cli_reference.md) - Complete command-line
  parameter reference
- [**03_troubleshooting.md**](./03_troubleshooting.md) - Common issues and
  solutions

### Preset System

- [**10_m1f_presets.md**](./10_m1f_presets.md) - Comprehensive preset system
  guide
- [**11_preset_per_file_settings.md**](./11_preset_per_file_settings.md) -
  Advanced per-file processing configuration
- [**12_preset_reference.md**](./12_preset_reference.md) - Complete preset
  reference with all settings, features, and clarifications

### Features & Tools

- [**20_auto_bundle_guide.md**](./20_auto_bundle_guide.md) - Automated bundling
  with configuration files
- [**21_development_workflow.md**](./21_development_workflow.md) - Best
  practices for development workflows
- [**25_m1f_config_examples.md**](./25_m1f_config_examples.md) - Comprehensive
  configuration examples for different project types

### AI Integration

- [**30_claude_workflows.md**](./30_claude_workflows.md) - Working with Claude
  and LLMs
- [**31_claude_code_integration.md**](./31_claude_code_integration.md) -
  Integration with Claude Code for AI-assisted development

### Advanced Topics

- [**40_security_best_practices.md**](./40_security_best_practices.md) -
  Security guidelines and protective measures
- [**41_version_3_2_features.md**](./41_version_3_2_features.md) - Comprehensive
  v3.2 feature documentation and migration guide

## Quick Start

```bash
# Basic usage
m1f -s ./your_project -o ./combined.txt

# With file type filtering
m1f -s ./src -o code.txt --include-extensions .py .js

# Using presets
m1f -s . -o bundle.txt --preset wordpress.m1f-presets.yml

# v3.2 features: Allow duplicate files + custom encoding
m1f -s ./legacy -o output.txt --allow-duplicate-files --no-prefer-utf8-for-text-files

# Security scanning with warning mode
m1f -s ./src -o bundle.txt --security-check warn
```

For detailed information, start with the [main documentation](00_m1f.md) or jump
to the [quick reference](./01_quick_reference.md) for common commands.

======= docs/01_m1f/00_m1f.md ======
# m1f (Make One File)

A modern, high-performance tool that combines multiple files into a single file
with rich metadata, content deduplication, and async I/O support.

## Overview

The m1f tool solves a common challenge when working with LLMs: providing
sufficient context without exceeding token limits. It creates optimized
reference files from multiple sources while automatically handling duplicates
and providing comprehensive metadata.

## Key Features

- **Content Deduplication**: Automatically detects and skips duplicate files
  based on SHA256 checksums
- **Async I/O**: High-performance file operations with concurrent processing
- **Type Safety**: Full type annotations throughout the codebase
- **Smart Filtering**: Advanced file filtering with size limits, extensions, and
  patterns
- **Symlink Support**: Intelligent symlink handling with cycle detection
- **Professional Security**: Integration with detect-secrets for sensitive data
  detection

## Quick Start

### Initialize m1f in Your Project

```bash
# Quick setup for any project
cd /your/project
m1f-init

# This creates in the m1f/ directory:
# The place for your bundled files of the current project
```

### Basic m1f Commands

```bash
# Basic usage with a source directory
m1f -s ./your_project -o ./combined.txt

# Include only specific file types
m1f -s ./your_project -o ./combined.txt --include-extensions .py .js .md

# Include only documentation files (62 extensions)
m1f -s ./your_project -o ./docs_bundle.txt --docs-only

# Exclude specific directories
m1f -s ./your_project -o ./combined.txt --excludes "node_modules/" "build/" "dist/"

# Filter by file size (new in v2.0.0)
m1f -s ./your_project -o ./combined.txt --max-file-size 50KB
```

> **Note**: For a complete reference of all available options, see the
> [CLI Reference](./07_cli_reference.md). For troubleshooting, see the
> [Troubleshooting Guide](./08_troubleshooting.md).

## Command Line Options

| Option                      | Description                                                                                                                                                                                                                                                      |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `-s, --source-directory`    | Path to the directory containing files to process. Can be specified multiple times to include files from multiple directories (e.g., `-s dir1 -s dir2`)                                                                                                          |
| `-i, --input-file`          | Path to a file containing a list of files/directories to process. Can be used together with --source-directory to resolve relative paths in the input file against the source directory                                                                          |
| `-o, --output-file`         | Path for the combined output file                                                                                                                                                                                                                                |
| `-f, --force`               | Force overwrite of existing output file without prompting                                                                                                                                                                                                        |
| `-t, --add-timestamp`       | Add a timestamp (\_YYYYMMDD_HHMMSS) to the output filename. Useful for versioning and preventing accidental overwrite of previous output files                                                                                                                   |
| `--filename-mtime-hash`     | Append a hash of file modification timestamps to the filename. The hash is created using all filenames and their modification dates, enabling caching mechanisms. Hash only changes when files are added/removed or their content changes                        |
| `--include-extensions`      | Space-separated list of file extensions to include (e.g., `--include-extensions .py .js .html` will only process files with these extensions)                                                                                                                    |
| `--exclude-extensions`      | Space-separated list of file extensions to exclude (e.g., `--exclude-extensions .log .tmp .bak` will skip these file types)                                                                                                                                      |
| `--includes`                | Space-separated list of gitignore-style patterns to include (e.g., `--includes "*.py" "src/**" "!test.py"`). When combined with `--include-extensions`, files must match both criteria                                                                           |
| `--docs-only`               | Include only documentation files (62 extensions including .md, .txt, .rst, .org, .tex, .info, etc.). Overrides include-extensions.                                                                                                                               |
| `--max-file-size`           | Skip files larger than the specified size (e.g., `--max-file-size 50KB` will exclude files over 50 kilobytes). Supports units: B, KB, MB, GB, TB. Useful for filtering out large generated files, logs, or binary data when merging text files for LLM context   |
| `--exclude-paths-file`      | Path to file containing paths or patterns to exclude. Supports both exact path lists and gitignore-style pattern formats. Can use a .gitignore file directly                                                                                                     |
| `--no-default-excludes`     | Disable default directory exclusions. By default, the following directories are excluded: vendor, node_modules, build, dist, cache, .git, .svn, .hg, \***\*pycache\*\*** (see [Default Excludes Guide](./26_default_excludes_guide.md) for complete list)        |
| `--excludes`                | Space-separated list of paths to exclude. Supports directory names, exact file paths, and gitignore-style patterns (e.g., `--excludes logs "config/settings.json" "*.log" "build/" "!important.log"`)                                                            |
| `--include-dot-paths`       | Include files and directories that start with a dot (e.g., .gitignore, .hidden/). By default, all dot files and directories are excluded.                                                                                                                        |
| `--include-binary-files`    | Attempt to include files with binary extensions                                                                                                                                                                                                                  |
| `--remove-scraped-metadata` | Remove scraped metadata (URL, timestamp) from HTML2MD files during processing. Automatically detects and removes metadata blocks at the end of markdown files created by HTML scraping tools                                                                     |
| `--separator-style`         | Style of separators between files (`Standard`, `Detailed`, `Markdown`, `MachineReadable`, `None`)                                                                                                                                                                |
| `--line-ending`             | Line ending for script-generated separators (`lf` or `crlf`)                                                                                                                                                                                                     |
| `--convert-to-charset`      | Convert all files to the specified character encoding (`utf-8` [default], `utf-16`, `utf-16-le`, `utf-16-be`, `ascii`, `latin-1`, `cp1252`). The original encoding is automatically detected and included in the metadata when using compatible separator styles |
| `--abort-on-encoding-error` | Abort processing if encoding conversion errors occur. Without this flag, characters that cannot be represented will be replaced                                                                                                                                  |
| `-v, --verbose`             | Enable verbose logging. Without this flag, only summary information is shown, and detailed file-by-file logs are written to the log file instead of the console                                                                                                  |
| `--minimal-output`          | Generate only the combined output file (no auxiliary files)                                                                                                                                                                                                      |
| `--skip-output-file`        | Execute operations but skip writing the final output file                                                                                                                                                                                                        |
| `-q, --quiet`               | Suppress all console output                                                                                                                                                                                                                                      |
| `--create-archive`          | Create a backup archive of all processed files                                                                                                                                                                                                                   |
| `--archive-type`            | Type of archive to create (`zip` or `tar.gz`)                                                                                                                                                                                                                    |
| `--security-check`          | Scan files for secrets before merging (`abort`, `skip`, `warn`)                                                                                                                                                                                                  |
| `--preset`                  | One or more preset configuration files for file-specific processing. Files are loaded in order with later files overriding earlier ones                                                                                                                          |
| `--preset-group`            | Specific preset group to use from the configuration. If not specified, all matching presets from all groups are considered                                                                                                                                       |
| `--disable-presets`         | Disable all preset processing even if preset files are loaded                                                                                                                                                                                                    |

## Preset System

The preset system allows you to define file-specific processing rules for
different file types within the same bundle. This is particularly useful for
projects with mixed content types.

### Preset Hierarchy

Presets are loaded in the following order (highest priority wins):

1. **Global Presets** (~/.m1f/global-presets.yml) - Lowest priority
2. **User Presets** (~/.m1f/presets/\*.yml) - Medium priority
3. **Project Presets** (via --preset parameter) - Highest priority

### Quick Preset Examples

```bash
# Use built-in WordPress preset
m1f -s ./wp-site -o bundle.txt --preset presets/wordpress.m1f-presets.yml

# Use specific preset group
m1f -s ./project -o bundle.txt --preset my-presets.yml --preset-group production

# Load multiple preset files (merged in order)
m1f -s . -o out.txt --preset defaults.yml project.yml overrides.yml
```

### Available Processing Actions

- **minify** - Remove unnecessary whitespace (HTML, CSS, JS)
- **strip_tags** - Remove specified HTML tags
- **strip_comments** - Remove comments based on file type
- **compress_whitespace** - Normalize whitespace
- **remove_empty_lines** - Remove all empty lines
- **custom** - Apply custom processors

For detailed preset documentation, see:

- [Preset System Guide](02_m1f_presets.md) - Complete preset documentation
- [Per-File-Type Settings](03_m1f_preset_per_file_settings.md) - File-specific
  overrides

## Usage Examples

### Basic Operations

```bash
# Basic command using a source directory
m1f --source-directory /path/to/your/code \
  --output-file /path/to/combined_output.txt

# Using multiple source directories (new in v3.4.0)
m1f -s ./src -s ./docs -s ./tests -o combined_output.txt

# Using an input file containing paths to process (one per line)
m1f -i filelist.txt -o combined_output.txt

# Using both source directory and input file together
m1f -s ./source_code -i ./file_list.txt -o ./combined.txt

# Using include patterns to filter files (new in v3.4.0)
m1f -s ./project -o output.txt --includes "src/**" "*.py" "!*_test.py"

# Combining includes with extensions for precise filtering
m1f -s ./project -o docs.txt --include-extensions .md .rst \
  --includes "docs/**" "README.md"

# Remove scraped metadata from HTML2MD files (new in v2.0.0)
m1f -s ./scraped_docs -o ./clean_docs.txt \
  --include-extensions .md --remove-scraped-metadata
```

### Advanced Operations

```bash
# Using MachineReadable style with verbose logging
m1f -s ./my_project -o ./output/bundle.m1f.txt \
  --separator-style MachineReadable --force --verbose

# Creating a combined file and a backup zip archive
m1f -s ./source_code -o ./dist/combined.txt \
  --create-archive --archive-type zip

# Only include text files under 50KB to avoid large generated files
m1f -s ./project -o ./text_only.txt \
  --max-file-size 50KB --include-extensions .py .js .md .txt .json

# Handle symlinks with cycle detection (new in v2.0.0)
m1f -s ./project -o ./output.txt \
  --include-symlinks --verbose
```

## Security Check

The `--security-check` option scans files for potential secrets using
`detect-secrets` if the library is installed. When secrets are detected you can
decide how the script proceeds:

- `abort` – stop processing immediately and do not create the output file.
- `skip` – omit files that contain secrets from the final output.
- `warn` – include all files but print a summary warning at the end.

If `detect-secrets` is not available, a simplified pattern-based scan is used as
a fallback.

## Output Files

By default, `m1f.py` creates several output files to provide comprehensive
information about the processed files:

1. **Primary output file** - The combined file specified by `--output-file`
   containing all processed files with separators
2. **Log file** - A `.log` file with the same base name as the output file,
   containing detailed processing information
3. **File list** - A `_filelist.txt` file containing the paths of all included
   files
4. **Directory list** - A `_dirlist.txt` file containing all unique directories
   from the included files
5. **Archive file** - An optional backup archive (zip or tar.gz) if
   `--create-archive` is specified

To create only the primary output file and skip the auxiliary files, use the
`--minimal-output` option:

```bash
# Create only the combined output file without any auxiliary files
m1f -s ./src -o ./combined.txt --minimal-output
```

## Common Use Cases

### Documentation Compilation

```bash
# Create a complete documentation bundle from all markdown files
m1f -s ./docs -o ./doc_bundle.m1f.txt --include-extensions .md
```

### Code Review Preparation

```bash
# Bundle specific components for code review
m1f -i code_review_files.txt -o ./review_bundle.m1f.txt
```

### WordPress Development

```bash
# Combine theme or plugin files for AI analysis
m1f -s ./wp-content/themes/my-theme -o ./theme_context.m1f.txt \
  --include-extensions .php .js .css --exclude-paths-file ./exclude_build_files.txt
```

### Project Knowledge Base

```bash
# Create a searchable knowledge base from project documentation
m1f -s ./project -o ./knowledge_base.m1f.txt \
  --include-extensions .md .txt .rst --minimal-output
```

### Documentation Bundles

```bash
# Create a documentation-only bundle using --docs-only
m1f -s ./project -o ./docs_bundle.txt --docs-only

# Equivalent using include-extensions (more verbose)
m1f -s ./project -o ./docs_bundle.txt --include-extensions \
  .1 .1st .2 .3 .4 .5 .6 .7 .8 .adoc .asciidoc .changelog .changes \
  .creole .faq .feature .help .history .info .lhs .litcoffee .ltx \
  .man .markdown .markdown2 .md .mdown .mdtxt .mdtext .mdwn .mdx \
  .me .mkd .mkdn .mkdown .ms .news .nfo .notes .org .pod .pod6 \
  .qmd .rd .rdoc .readme .release .rmd .roff .rst .rtf .story \
  .t .tex .texi .texinfo .text .textile .todo .tr .txt .wiki
```

### HTML2MD Integration

```bash
# Combine scraped markdown files and remove metadata
m1f -s ./scraped_content -o ./clean_content.m1f.txt \
  --include-extensions .md --remove-scraped-metadata

# Merge multiple scraped websites into a clean documentation bundle
m1f -s ./web_content -o ./web_docs.m1f.txt \
  --include-extensions .md --remove-scraped-metadata --separator-style Markdown
```

### Project Analysis and Overview

```bash
# Generate complete project file and directory lists for analysis
m1f -s . -o m1f/project_analysis.txt --skip-output-file \
  --exclude-paths-file .gitignore --excludes m1f/

# This creates (without the main output file):
# - m1f/project_analysis_filelist.txt  # All project files
# - m1f/project_analysis_dirlist.txt   # All directories
# - m1f/project_analysis.log           # Processing log
```

Use this when you need:

- A complete overview of your project structure
- To understand what files m1f will process
- To verify your exclusion patterns are working correctly
- To analyze project composition before creating bundles
- Input for m1f-claude --init to create optimal configurations

The file lists respect all m1f defaults (excluding .git, node_modules, etc.)
plus your .gitignore patterns.

## Output Files

### Main Output File

The primary output specified with `-o` contains the combined content of all
processed files.

### Auxiliary Files (Automatically Generated)

For each m1f operation, auxiliary files are automatically created alongside the
main output file:

1. **File List** (`<output>_filelist.txt`)
   - Complete list of all files included in the bundle
   - One file path per line
   - Useful for:
     - Understanding what's in your bundle
     - Creating custom file lists for specific m1f operations
     - Input for other tools or scripts
     - Selective inclusion/exclusion in future bundles

2. **Directory List** (`<output>_dirlist.txt`)
   - Complete list of all directories containing processed files
   - One directory path per line
   - Useful for:
     - Understanding project structure
     - Identifying which directories to include/exclude
     - Creating directory-specific bundles

3. **Processing Log** (`<output>.log`)
   - Detailed processing information
   - Includes timing, errors, and statistics

### Working with File Lists

The generated file lists can be edited and used as input for subsequent m1f
operations:

```bash
# Initial project analysis
m1f-init
# Creates: m1f/<project>_complete_filelist.txt and m1f/<project>_docs_filelist.txt

# Edit the file list to remove unwanted files
vi m1f/myproject_complete_filelist.txt

# Use the edited list for a custom bundle
m1f -i m1f/myproject_complete_filelist.txt -o m1f/custom_bundle.txt

# Combine multiple file lists
cat m1f/*_filelist.txt | sort -u > m1f/all_files.txt
m1f -i m1f/all_files.txt -o m1f/combined.txt
```

### Disabling Auxiliary Files

Use `--minimal-output` to create only the main output file without auxiliary
files:

```bash
m1f -s . -o output.txt --minimal-output
```

## Separator Styles

The `--separator-style` option allows you to choose how files are separated in
the combined output file. Each style is designed for specific use cases, from
human readability to automated parsing.

### Standard Style

A simple, concise separator that shows only the file path:

```
======= path/to/file.py ======
```

### Detailed Style (Default)

A more comprehensive separator that includes file metadata:

```
========================================================================================
== FILE: path/to/file.py
== DATE: 2025-05-15 14:30:21 | SIZE: 2.50 KB | TYPE: .py
== CHECKSUM_SHA256: abcdef1234567890...
========================================================================================
```

### Markdown Style

Formats the metadata as Markdown with proper code blocks, using the file
extension to set syntax highlighting:

````markdown
## path/to/file.py

**Date Modified:** 2025-05-15 14:30:21 | **Size:** 2.50 KB | **Type:** .py |
**Checksum (SHA256):** abcdef1234567890...

```python
# File content starts here
def example():
    return "Hello, world!"
```
````

### MachineReadable Style

A robust format designed for reliable automated parsing and processing:

```text
--- PYMK1F_BEGIN_FILE_METADATA_BLOCK_12345678-1234-1234-1234-123456789abc ---
METADATA_JSON:
{
    "original_filepath": "path/to/file.py",
    "original_filename": "file.py",
    "timestamp_utc_iso": "2025-05-15T14:30:21Z",
    "type": ".py",
    "size_bytes": 2560,
    "checksum_sha256": "abcdef1234567890..."
}
--- PYMK1F_END_FILE_METADATA_BLOCK_12345678-1234-1234-1234-123456789abc ---
--- PYMK1F_BEGIN_FILE_CONTENT_BLOCK_12345678-1234-1234-1234-123456789abc ---

# File content here

--- PYMK1F_END_FILE_CONTENT_BLOCK_12345678-1234-1234-1234-123456789abc ---
```

### None Style

Files are concatenated directly without any separators between them.

## Additional Notes

### Binary File Handling

While the script can include binary files using the `--include-binary-files`
option, these are read as text (UTF-8 with error ignoring). This can result in
garbled/unreadable content in the output and significantly increase file size.

### Encoding Behavior

The script uses UTF-8 as the default encoding for reading and writing files.
When using `--convert-to-charset`, the original encoding of each file is
automatically detected and recorded in the file metadata.

### Documentation File Extensions

m1f recognizes the following extensions as documentation files:

- Man pages: .1, .1st, .2, .3, .4, .5, .6, .7, .8
- Markup formats: .adoc, .asciidoc, .md, .markdown, .mdx, .rst, .org, .textile,
  .wiki
- Text formats: .txt, .text, .readme, .changelog, .changes, .todo, .notes
- Developer docs: .pod, .rdoc, .yard, .lhs, .litcoffee
- LaTeX/TeX: .tex, .ltx, .texi, .texinfo
- Other: .rtf, .nfo, .faq, .help, .history, .info, .news, .release, .story

When `--prefer-utf8-for-text-files` is enabled (default), m1f prefers UTF-8
encoding for:

- All Markdown variants (.md, .markdown, .mdx, .rmd, .qmd, etc.)
- Plain text files (.txt, .text, .readme, .changelog, .todo, etc.)
- Structured text formats (.rst, .org, .textile, .wiki, etc.)
- Developer documentation (.pod, .rdoc, .lhs, .litcoffee, etc.)

### Line Ending Behavior

The `--line-ending` option only affects the line endings generated by the script
(in separators and blank lines), not those in the original files. The line
endings of original files remain unchanged.

### Archive Creation

When `--create-archive` is used, the archive will contain all files selected for
inclusion in the main output file, using their relative paths within the
archive.

### Architecture

The m1f tool has been completely rewritten as a modular Python package:

```
tools/m1f/
├── __init__.py          # Package initialization
├── cli.py               # Command-line interface
├── core.py              # Main orchestration logic
├── config.py            # Configuration management
├── constants.py         # Constants and enums
├── exceptions.py        # Custom exceptions
├── file_processor.py    # File handling with async I/O
├── encoding_handler.py  # Smart encoding detection
├── security_scanner.py  # Secret detection integration
├── output_writer.py     # Output generation
├── archive_creator.py   # Archive functionality
├── separator_generator.py # Separator formatting
├── logging.py           # Structured logging
└── utils.py             # Utility functions
```

### Performance Considerations

With the new async I/O architecture, m1f can handle large projects more
efficiently:

- Concurrent file reading and processing
- Memory-efficient streaming for large files
- Smart caching to avoid redundant operations
- Content deduplication saves space and processing time

For extremely large directories with tens of thousands of files or very large
individual files, the script might take some time to process.

## Preset System

The preset system provides powerful file-specific processing capabilities:

### Key Features

- **Hierarchical Configuration**: Settings cascade from global → project → CLI
- **File-Type Processing**: Apply different rules to different file extensions
- **Processing Actions**:
  - `minify` - Reduce file size by removing unnecessary characters
  - `strip_tags` - Remove HTML tags
  - `strip_comments` - Remove code comments
  - `compress_whitespace` - Reduce multiple spaces/newlines
  - `remove_empty_lines` - Clean up empty lines
- **Per-File Settings**: Override security, size limits, and filters per file
  type
- **Custom Processors**: Extend with your own processing functions

### Quick Start

1. Create a preset file in your project (`.m1f-presets.yml`):

```yaml
globals:
  global_settings:
    include_extensions: [.js, .css, .html, .php]
    security_check: warn
    max_file_size: 1MB

  presets:
    frontend:
      extensions: [.js, .css, .html]
      actions: [minify]

    backend:
      extensions: [.php]
      security_check: fail
      max_file_size: 500KB
```

2. Use the preset:

```bash
m1f -s ./src -o output.txt --preset .m1f-presets.yml
```

### Documentation

**Core Documentation:**

- [Quick Reference](./09_quick_reference.md) - Common commands and patterns
- [CLI Reference](./07_cli_reference.md) - Complete command-line reference
- [Default Excludes Guide](./26_default_excludes_guide.md) - What's excluded
  automatically
- [Troubleshooting Guide](./08_troubleshooting.md) - Common issues and solutions

**Preset System:**

- [Complete Preset Guide](02_m1f_presets.md) - Full preset system documentation
- [Per-File Settings](03_m1f_preset_per_file_settings.md) - Advanced file-type
  overrides
- [Example Presets](../presets/) - Ready-to-use preset templates

**Workflows and Integration:**

- [Development Workflow](./21_development_workflow.md) - Best practices
- [Claude Code Integration](./31_claude_code_integration.md) - AI-assisted
  development
- [Auto Bundle Guide](./20_auto_bundle_guide.md) - Automated bundling

======= docs/01_m1f/01_quick_reference.md ======
# m1f Quick Reference

## Most Common Commands

### Basic File Combination

```bash
# Combine all files in current directory
m1f -s . -o output.txt

# Combine specific directory
m1f -s ./src -o bundle.txt

# Force overwrite existing output
m1f -s . -o output.txt -f
```

### Using Presets (v3.2.0+)

```bash
# Use a preset file (can define ALL parameters)
m1f --preset production.yml -o output.txt

# Preset can even define source and output
m1f --preset full-config.yml

# Override preset values with CLI
m1f --preset prod.yml -o custom-output.txt -v
```

### File Type Filtering

```bash
# Only Python files
m1f -s . -o code.txt --include-extensions .py

# Multiple file types
m1f -s . -o docs.txt --include-extensions .md .txt .rst

# Exclude certain types
m1f -s . -o output.txt --exclude-extensions .pyc .log
```

### Directory and Pattern Exclusions

```bash
# Exclude specific directories
m1f -s . -o output.txt --excludes "tests/" "docs/"

# Exclude patterns
m1f -s . -o output.txt --excludes "*.test.js" "*/tmp/*"

# Use gitignore file
m1f -s . -o output.txt --exclude-paths-file .gitignore
```

### Output Formatting

```bash
# Markdown format
m1f -s . -o output.md --separator-style Markdown

# Machine-readable JSON metadata
m1f -s . -o output.txt --separator-style MachineReadable

# No separators
m1f -s . -o output.txt --separator-style None
```

### Size Management

```bash
# Skip large files
m1f -s . -o output.txt --max-file-size 100KB

# Include only small text files
m1f -s . -o small.txt --max-file-size 50KB --include-extensions .txt .md
```

### Archive Creation

```bash
# Create zip backup
m1f -s . -o output.txt --create-archive

# Create tar.gz backup
m1f -s . -o output.txt --create-archive --archive-type tar.gz
```

### Using Presets

```bash
# Use single preset
m1f -s . -o output.txt --preset wordpress.m1f-presets.yml

# Use preset group
m1f -s . -o output.txt --preset web.yml --preset-group frontend

# Multiple presets (merged in order)
m1f -s . -o output.txt --preset base.yml project.yml
```

## Common Patterns

### Documentation Bundle

```bash
m1f -s ./docs -o documentation.txt \
    --include-extensions .md .rst .txt \
    --separator-style Markdown
```

### Source Code Bundle

```bash
m1f -s ./src -o source-code.txt \
    --include-extensions .py .js .ts .jsx .tsx \
    --excludes "*.test.*" "*.spec.*" \
    --max-file-size 500KB
```

### WordPress Theme/Plugin

```bash
m1f -s ./wp-content/themes/mytheme -o theme.txt \
    --include-extensions .php .js .css \
    --excludes "node_modules/" "vendor/" \
    --preset presets/wordpress.m1f-presets.yml
```

### Clean Documentation Export

```bash
m1f -s ./scraped_docs -o clean-docs.txt \
    --include-extensions .md \
    --remove-scraped-metadata \
    --separator-style Markdown
```

### Multiple Exclude/Include Files

```bash
# Multiple exclude files (merged)
m1f -s . -o output.txt \
    --exclude-paths-file .gitignore .dockerignore custom-excludes.txt

# Whitelist mode with include files
m1f -s . -o api-bundle.txt \
    --include-paths-file api-files.txt core-files.txt \
    --exclude-paths-file .gitignore
```

### Working with File Lists (-i)

```bash
# Single input file
m1f -s . -i files.txt -o output.txt

# Merge multiple file lists (Bash)
m1f -s . -i <(cat critical.txt important.txt nice-to-have.txt) -o output.txt

# Combine with filters (input files bypass filters)
m1f -s . -i must-include.txt -o output.txt \
    --exclude-paths-file .gitignore
```

### CI/CD Integration

```bash
# Create timestamped output
m1f -s . -o build.txt -t

# Minimal output for automation
m1f -s . -o output.txt --minimal-output --quiet

# With security check
m1f -s . -o output.txt --security-check abort
```

## Quick Option Reference

| Short | Long                 | Purpose                   |
| ----- | -------------------- | ------------------------- |
| `-s`  | `--source-directory` | Source directory          |
| `-i`  | `--input-file`       | File list input           |
| `-o`  | `--output-file`      | Output file (required)    |
| `-f`  | `--force`            | Overwrite existing        |
| `-t`  | `--add-timestamp`    | Add timestamp to filename |
| `-v`  | `--verbose`          | Detailed output           |
| `-q`  | `--quiet`            | Suppress output           |

## Separator Styles

- **Standard**: Simple filename separator
- **Detailed**: Full metadata (default)
- **Markdown**: Markdown formatting
- **MachineReadable**: JSON metadata
- **None**: No separators

## Size Units

- `B`: Bytes
- `KB`: Kilobytes (1024 bytes)
- `MB`: Megabytes
- `GB`: Gigabytes

Example: `--max-file-size 1.5MB`

## Exit on Success

```bash
m1f -s . -o output.txt && echo "Success!"
```

## Aliases Setup

Add to your shell profile:

```bash
alias m1f='python /path/to/m1f/tools/m1f.py'
alias m1f-docs='m1f -s . -o docs.txt --include-extensions .md .txt'
alias m1f-code='m1f -s . -o code.txt --include-extensions .py .js'
```

## Need Help?

- Full options: `m1f --help`
- [Complete CLI Reference](./02_cli_reference.md)
- [Troubleshooting Guide](./03_troubleshooting.md)
- [Preset Documentation](./10_m1f_presets.md)

======= docs/01_m1f/02_cli_reference.md ======
# m1f CLI Reference

This is a comprehensive reference for all command-line parameters and flags
available in m1f v3.4.0.

## Synopsis

```bash
m1f [-h] [--version] [-s DIR] [-i FILE] -o FILE
    [--input-include-files [FILE ...]]
    [--separator-style {Standard,Detailed,Markdown,MachineReadable,None}]
    [--line-ending {lf,crlf}] [-t] [--filename-mtime-hash]
    [--excludes [PATTERN ...]] [--exclude-paths-file FILE ...]
    [--include-paths-file FILE ...]
    [--include-extensions [EXT ...]] [--exclude-extensions [EXT ...]]
    [--include-dot-paths] [--include-binary-files] [--include-symlinks]
    [--max-file-size SIZE] [--no-default-excludes]
    [--remove-scraped-metadata]
    [--convert-to-charset {utf-8,utf-16,utf-16-le,utf-16-be,ascii,latin-1,cp1252}]
    [--abort-on-encoding-error] [--no-prefer-utf8-for-text-files]
    [--security-check {error,warn,skip}]
    [--create-archive] [--archive-type {zip,tar.gz}] [-f]
    [--minimal-output] [--skip-output-file] [--allow-duplicate-files]
    [-v] [-q]
    [--preset FILE [FILE ...]] [--preset-group GROUP]
    [--disable-presets]
```

## General Options

### `--help`, `-h`

Show help message and exit.

### `--version`

Show program version and exit. Current version: v3.4.0

## Input/Output Options

### `--source-directory DIR`, `-s DIR`

Path to the directory containing files to combine. Can be used multiple times to
process multiple directories.

### `--input-file FILE`, `-i FILE`

Path to a text file containing a list of files/directories to process, one per
line. These files are explicitly included and bypass all filter rules.

**Note**: At least one of `-s` (source directory) or `-i` (input file) must be
specified. When using `-i` alone, relative paths in the input file are resolved
relative to the current working directory. When both `-s` and `-i` are used,
relative paths in the input file are resolved relative to the source directory.

Example input file:

```
# Comments are supported
src/main.py          # Relative to source directory
/absolute/path.txt   # Absolute path
docs/**/*.md         # Glob patterns supported
```

**Merging multiple file lists with Bash**:

```bash
# Create temporary merged file
cat files1.txt files2.txt files3.txt > merged_files.txt
m1f -s . -i merged_files.txt -o output.txt

# Or use process substitution (Linux/Mac)
m1f -s . -i <(cat files1.txt files2.txt files3.txt) -o output.txt

# Remove duplicates while merging
m1f -s . -i <(cat files1.txt files2.txt | sort -u) -o output.txt
```

### `--output-file FILE`, `-o FILE` (REQUIRED)

Path where the combined output file will be created. This is the only required
parameter.

### `--input-include-files [FILE ...]`

Files to include at the beginning of the output. The first file is treated as an
introduction/header.

## Output Formatting

### `--separator-style {Standard,Detailed,Markdown,MachineReadable,None}`

Format of the separator between files. Default: `Detailed`

- **Standard**: Simple separator with filename
- **Detailed**: Includes file metadata (date, size, type, checksum)
- **Markdown**: Markdown-formatted headers and metadata
- **MachineReadable**: JSON metadata blocks for programmatic parsing
- **None**: No separators (files concatenated directly)

### `--line-ending {lf,crlf}`

Line ending style for generated content. Default: `lf`

- **lf**: Unix/Linux/Mac style (\n)
- **crlf**: Windows style (\r\n)

### `--add-timestamp`, `-t`

Add timestamp to output filename in format `_YYYYMMDD_HHMMSS`.

### `--filename-mtime-hash`

Add hash of file modification times to output filename. Useful for
cache-busting.

## File Filtering

### `--excludes [PATTERN ...]`

Paths, directories, or glob patterns to exclude. Supports wildcards.

Example: `--excludes "*/tests/*" "*.pyc" "node_modules/"`

### `--exclude-paths-file FILE ...`

File(s) containing paths to exclude (supports gitignore format). Each pattern on
a new line. Multiple files can be specified and will be merged. Non-existent
files are skipped gracefully.

Examples:

```bash
# Single file
m1f -s . -o output.txt --exclude-paths-file .gitignore

# Multiple files
m1f -s . -o output.txt --exclude-paths-file .gitignore .m1fignore custom-excludes.txt
```

### `--include-paths-file FILE ...`

File(s) containing patterns to include (supports gitignore format). When
specified, only files matching these patterns will be included (whitelist mode).
Multiple files can be specified and will be merged. Non-existent files are
skipped gracefully.

**Processing Order**:

1. Files from `-i` (input-file) are always included, bypassing all filters
2. Files from `-s` (source directory) are filtered by include patterns first
3. Then exclude patterns are applied

**Path Resolution**: Same as `-i` - relative paths are resolved relative to the
source directory (`-s`).

Example include file:

```
# Include all Python files
*.py
# Include specific directories
src/**/*
api/**/*
# Exclude tests even if they match above
!test_*.py
```

Examples:

```bash
# Single file
m1f -s . -o output.txt --include-paths-file important-files.txt

# Multiple files
m1f -s . -o output.txt --include-paths-file core-files.txt api-files.txt

# Combined with input file (input file takes precedence)
m1f -s . -i explicit-files.txt -o output.txt --include-paths-file patterns.txt
```

### `--include-extensions [EXT ...]`

Only include files with these extensions. Extensions should include the dot.

Example: `--include-extensions .py .js .md`

### `--exclude-extensions [EXT ...]`

Exclude files with these extensions.

Example: `--exclude-extensions .pyc .pyo`

### `--include-dot-paths`

Include files and directories starting with a dot (hidden files). By default,
these are excluded.

### `--include-binary-files`

Attempt to include binary files. Use with caution as this may produce unreadable
output.

### `--include-symlinks`

Follow symbolic links. Be careful of infinite loops!

**Deduplication behavior**:

- By default (without `--allow-duplicate-files`), m1f intelligently handles
  symlinks:
  - Internal symlinks (pointing to files within source directories) are excluded
    to avoid duplicates
  - External symlinks (pointing outside source directories) are included
- With `--allow-duplicate-files`, all symlinks are included regardless of their
  target

### `--max-file-size SIZE`

Skip files larger than specified size. Supports KB, MB, GB suffixes.

Examples: `10KB`, `1.5MB`, `2GB`

### `--no-default-excludes`

Disable default exclusions. By default, m1f excludes:

- `.git/`, `.svn/`, `.hg/`
- `node_modules/`, `venv/`, `.venv/`
- `__pycache__/`, `*.pyc`
- `.DS_Store`, `Thumbs.db`

### `--remove-scraped-metadata`

Remove scraped metadata (URL, timestamp) from HTML2MD files during processing.
Useful when processing scraped content.

## Character Encoding

### `--convert-to-charset {utf-8,utf-16,utf-16-le,utf-16-be,ascii,latin-1,cp1252}`

Convert all files to specified encoding. Default behavior is to detect and
preserve original encoding.

### `--abort-on-encoding-error`

Abort if encoding conversion fails. By default, files with encoding errors are
skipped with a warning.

### `--no-prefer-utf8-for-text-files`

Disable UTF-8 preference for text files (.md, .txt, .rst) when encoding is
ambiguous. By default, m1f prefers UTF-8 encoding for these file types when
chardet detects windows-1252 with less than 95% confidence, as these files often
contain UTF-8 emojis or special characters.

## Security Options

### `--security-check {error,warn,skip}`

Check for sensitive information in files using detect-secrets.

- **error**: Stop processing if secrets are found (default in v3.2)
- **warn**: Include files but show warnings
- **skip**: Disable security scanning (not recommended)

## Archive Options

### `--create-archive`

Create backup archive of processed files in addition to the combined output.

### `--archive-type {zip,tar.gz}`

Type of archive to create. Default: `zip`

## Output Control

### `--force`, `-f`

Force overwrite of existing output file without prompting.

### `--minimal-output`

Only create the combined file (no auxiliary files like file lists or directory
structure).

### `--skip-output-file`

Skip creating the main output file. Useful when only creating an archive.

### `--allow-duplicate-files`

Allow files with identical content to be included in the output. By default, m1f
deduplicates files based on their content checksum to save space and tokens.
With this flag, all files are included even if they have identical content.

**Special behavior with symlinks** (when used with `--include-symlinks`):

- **Without** `--allow-duplicate-files`:
  - Symlinks pointing to files **inside** the source directories are excluded
    (the original file is already included)
  - Symlinks pointing to files **outside** the source directories are included
- **With** `--allow-duplicate-files`:
  - All symlinks are included, regardless of where they point
  - Both the original file and symlinks pointing to it can appear in the output

### `--verbose`, `-v`

Enable verbose output with detailed processing information.

### `--quiet`, `-q`

Suppress all console output except errors.

## Preset Configuration

### `--preset FILE [FILE ...]`

Load preset configuration file(s) for file-specific processing. Multiple files
are merged in order.

### `--preset-group GROUP`

Use a specific preset group from the configuration file.

### `--disable-presets`

Disable all preset processing, even if preset files are specified.

## Exit Codes

- **0**: Success
- **1**: General error (M1FError base)
- **2**: File not found (FileNotFoundError)
- **3**: Permission denied (PermissionError)
- **4**: Encoding error (EncodingError)
- **5**: Configuration error (ConfigurationError)
- **6**: Validation error (ValidationError)
- **7**: Security check failed (SecurityError)
- **8**: Archive creation failed (ArchiveError)
- **130**: Operation cancelled by user (Ctrl+C)

## Environment Variables

**Note**: The following environment variables are documented for future
implementation but are not currently supported in v3.4.0:

- `M1F_DEFAULT_PRESET` - Path to default preset file (not implemented)
- `M1F_SECURITY_CHECK` - Default security check mode (not implemented)
- `M1F_MAX_FILE_SIZE` - Default maximum file size limit (not implemented)

## Subcommands

### `auto-bundle`

Create multiple m1f bundles based on a YAML configuration file
(`.m1f.config.yml`).

```bash
# Create all bundles
m1f auto-bundle

# Create specific bundle
m1f auto-bundle BUNDLE_NAME

# List available bundles
m1f auto-bundle --list

# With options
m1f auto-bundle --verbose
m1f auto-bundle --quiet
```

**Note**: The `m1f-update` command is a convenient alias for `m1f auto-bundle`
that can be used interchangeably:

```bash
# These are equivalent:
m1f auto-bundle
m1f-update

# With specific bundle:
m1f auto-bundle code
m1f-update code
```

**Options:**

- `BUNDLE_NAME`: Name of specific bundle to create (optional)
- `--list`: List available bundles from configuration
- `--verbose`, `-v`: Enable verbose output
- `--quiet`, `-q`: Suppress all console output

See the [Auto Bundle Guide](20_auto_bundle_guide.md) for detailed configuration
instructions.

## Notes

1. **Module Invocation**: You can use either `m1f` or `python -m tools.m1f`, or
   set up the `m1f` alias as described in the development workflow.

2. **Input Requirements**: At least one of `-s` (source directory) or `-i`
   (input file) must be specified. If neither is provided, m1f will show an
   error message.

3. **Gitignore**: m1f respects .gitignore files by default unless
   `--no-default-excludes` is used.

4. **Performance**: For large projects, use `--include-extensions` to limit
   processing to specific file types.

======= docs/01_m1f/03_troubleshooting.md ======
# Troubleshooting Guide

This guide covers common issues and error messages you might encounter when
using m1f.

## Common Issues

### Module Import Error

**Problem**: Running `m1f` results in:

```
ModuleNotFoundError: No module named 'm1f'
```

**Solution**: Use the direct script invocation instead:

```bash
m1f [options]
```

Or set up the alias as described in the
[Development Workflow](./21_development_workflow.md).

### Permission Denied

**Problem**: Error when trying to write output file:

```
PermissionError: [Errno 13] Permission denied: '/path/to/output.txt'
```

**Solutions**:

1. Check write permissions in the output directory
2. Use a different output location
3. Run with appropriate permissions (avoid using sudo unless necessary)

### File Not Found

**Problem**: Source directory or input file not found.

**Solutions**:

1. Verify the path exists: `ls -la /path/to/source`
2. Use absolute paths to avoid confusion
3. Check for typos in the path

### Encoding Errors

**Problem**: `UnicodeDecodeError` when processing files.

**Solutions**:

1. Use `--convert-to-charset utf-8` to force UTF-8 encoding
2. Skip problematic files with proper exclusion patterns
3. Use `--abort-on-encoding-error` to identify problematic files

Example:

```bash
m1f -s . -o output.txt --convert-to-charset utf-8
```

### Memory Issues with Large Projects

**Problem**: Memory usage is too high or process is killed.

**Solutions**:

1. Use `--max-file-size` to limit individual file sizes
2. Process specific directories instead of entire project
3. Use `--include-extensions` to limit file types
4. Enable minimal output mode: `--minimal-output`

Example:

```bash
m1f -s . -o output.txt --max-file-size 1MB --include-extensions .py .md
```

### Symlink Cycles

**Problem**: Infinite loop when following symlinks.

**Solutions**:

1. Don't use `--include-symlinks` unless necessary
2. Exclude directories with circular symlinks
3. m1f has built-in cycle detection, but it's better to avoid the issue

### Security Check Failures

**Problem**: Files contain sensitive information.

**Solutions**:

1. Review the detected secrets
2. Use `--security-check skip` to skip files with secrets
3. Use `--security-check warn` to include but get warnings
4. Add sensitive files to exclusions

Example:

```bash
m1f -s . -o output.txt --security-check warn --excludes ".env" "config/secrets.yml"
```

## Error Messages

### "Output file already exists"

**Meaning**: The specified output file exists and would be overwritten.

**Solution**: Use `-f` or `--force` to overwrite, or choose a different output
filename.

### "No files found to process"

**Meaning**: No files matched the inclusion criteria.

**Solutions**:

1. Check your source directory contains files
2. Verify extension filters aren't too restrictive
3. Check exclusion patterns aren't excluding everything
4. Use `--verbose` to see what's being processed

### "File size exceeds maximum allowed"

**Meaning**: A file is larger than the specified `--max-file-size`.

**Solution**: The file is automatically skipped. Adjust `--max-file-size` if
needed.

### "Failed to create archive"

**Meaning**: Archive creation failed (disk space, permissions, etc.).

**Solutions**:

1. Check available disk space
2. Verify write permissions
3. Try a different archive format
4. Skip archive creation and create output file only

### "Preset file not found"

**Meaning**: The specified preset configuration file doesn't exist.

**Solutions**:

1. Check the preset file path
2. Use absolute paths for preset files
3. Verify preset file exists: `ls -la presets/`

## Performance Optimization

### Slow Processing

**Solutions**:

1. Use `--include-extensions` to limit file types
2. Exclude large directories like `node_modules`
3. Use `--max-file-size` to skip large files
4. Enable minimal output: `--minimal-output`
5. Disable security checks if not needed

### High Memory Usage

**Solutions**:

1. Process smaller directory trees
2. Use file size limits
3. Exclude binary files
4. Process in batches using input file lists

## Debug Mode

For detailed debugging information:

```bash
m1f -s . -o output.txt --verbose
```

This will show:

- Files being processed
- Files being skipped and why
- Processing times
- Detailed error messages

## Getting Help

1. Check the [CLI Reference](./02_cli_reference.md) for parameter details
2. Review [examples in the main documentation](00_m1f.md#common-use-cases)
3. Check the [preset documentation](./10_m1f_presets.md) for configuration
   issues
4. Report issues at the project repository

## Exit Codes

Understanding exit codes can help in scripting:

- `0`: Success
- `1`: General error
- `2`: Invalid arguments
- `3`: File not found
- `4`: Permission denied
- `5`: Security check failed

Use in scripts:

```bash
if m1f -s . -o output.txt; then
    echo "Success"
else
    echo "Failed with exit code: $?"
fi
```

======= docs/01_m1f/05_getting_started.md ======
# Getting Started with m1f

This guide will walk you through installing m1f and creating your first bundles
using a real-world example.

## Installation (3 Simple Steps)

### For Users

```bash
# Step 1: Clone the repository
git clone https://github.com/franz-agency/m1f.git

# Step 2: Navigate to the directory
cd m1f

# Step 3: Run the installer
source ./scripts/install.sh    # Linux/macOS
.\scripts\install.ps1          # Windows (restart your shell after)
```

That's it! The installer automatically:

- ✅ Checks for Python 3.10+
- ✅ Creates a virtual environment
- ✅ Installs all dependencies
- ✅ Sets up global command aliases
- ✅ Generates initial m1f bundles

### For Developers

If you want to contribute or modify m1f:

```bash
# Clone and enter directory
git clone https://github.com/franz-agency/m1f.git
cd m1f

# Create virtual environment
python3 -m venv .venv

# Activate it
source .venv/bin/activate    # Linux/macOS
.venv\Scripts\activate       # Windows

# Install in development mode
pip install -e .
pip install -r requirements.txt
```

## Real Example: Bundling TailwindCSS Documentation

Let's walk through a complete example of bundling the TailwindCSS documentation
for use with AI assistants.

### Step 1: Get the Repository

```bash
git clone https://github.com/tailwindlabs/tailwindcss.com
cd tailwindcss.com
```

### Step 2: Initialize m1f

```bash
m1f-init
```

This command:

- Scans the entire repository
- Creates a `.m1f.config.yml` configuration file
- Generates two default bundles in the `m1f/` directory:
  - `tailwind_complete.txt` - All text files in the repository
  - `tailwind_docs.txt` - Documentation files only

### Step 3: Optional - Create Claude-Optimized Bundles

```bash
m1f-claude --setup
```

This creates additional bundles specifically optimized for Claude AI, with
proper formatting and structure.

### Using Your Bundles

Now you can:

1. **In Claude Desktop**: Reference files with `@m1f/tailwind_complete.txt`
2. **Copy & Paste**: Open the bundle file and paste into any LLM
3. **Check Token Count**: Run `m1f-token-counter m1f/tailwind_docs.txt`

## Understanding m1f-init

When you run `m1f-init` in any project directory:

1. **Scans the repository** - Analyzes file types and structure
2. **Creates `.m1f.config.yml`** - A configuration file with:
   - Default bundle definitions
   - Smart file patterns based on your project
   - Sensible exclusions (node_modules, .git, etc.)
3. **Generates bundles** - Creates initial bundles in the `m1f/` directory

## Customizing Your Bundles

After initialization, you can edit `.m1f.config.yml` to create custom bundles:

```yaml
bundles:
  # Existing bundles...

  # Add your custom bundle
  api-docs:
    description: "API documentation only"
    patterns:
      - "docs/api/**/*.md"
      - "src/**/README.md"
    exclude_patterns:
      - "**/*test*"
    output: "m1f/api_documentation.txt"
```

Then regenerate bundles:

```bash
m1f-update  # Updates all bundles
# or
m1f auto-bundle api-docs  # Update specific bundle
```

## Common Workflows

### 1. Documentation Sites

```bash
# Clone documentation
git clone https://github.com/vuejs/docs vuejs-docs
cd vuejs-docs

# Initialize and create bundles
m1f-init

# Feed to your AI
#  m1f/vuejs-docs_complete.txt
#  m1f/vuejs-docs_docs.txt
```

### 2. Your Own Projects

```bash
# In your project directory
# This creates a .m1f.config.yml with default bundles
m1f-init

# Let claude check your project to create smaller bundles sorted by topics
m1f-claude --setup

# Edit .m1f.config.yml to customize
# Then update bundles after code or config changes
m1f-update
```

### 3. Web Documentation

```bash
# Scrape online docs
m1f-scrape https://docs.python.org/3/ -o python-docs-html

# Convert to markdown
m1f-html2md convert python-docs-html -o python-docs-md

# Bundle for AI
cd python-docs-md
m1f-init
```

## Next Steps

- Learn about [configuration options](./25_m1f_config_examples.md)
- Explore [preset systems](./10_m1f_presets.md) for specialized file handling
- Set up [auto-bundling](./20_auto_bundle_guide.md) with git hooks
- Read the [complete m1f documentation](./00_m1f.md)

## Tips

- **Start Simple**: Use `m1f-init` first, customize later
- **Check Token Counts**: Always verify with `m1f-token-counter`
- **Use Presets**: For WordPress, documentation sites, etc.
- **Security**: m1f automatically scans for secrets before bundling

## Getting Help

- Run `m1f --help` for command options
- Check [troubleshooting guide](./03_troubleshooting.md)
- Visit [m1f.dev](https://m1f.dev) for updates

======= docs/01_m1f/10_m1f_presets.md ======
# m1f Preset System Documentation

The m1f preset system allows you to define file-specific processing rules,
enabling different handling for different file types within the same bundle.

## Overview

Instead of applying the same settings to all files, presets let you:

- Minify HTML files while preserving source code formatting
- Strip comments from production code but keep them in documentation
- Apply different separator styles for different file types
- Truncate large data files while keeping full source code
- Override security checks and size limits per file type
- Integrate with auto-bundling for intelligent project organization

## Quick Start

1. **Use a built-in preset**:

   ```bash
   m1f -s ./my-project -o bundle.txt --preset presets/wordpress.m1f-presets.yml
   ```

2. **Specify a preset group**:

   ```bash
   m1f -s ./site -o bundle.txt --preset presets/web-project.m1f-presets.yml --preset-group frontend
   ```

3. **Use multiple preset files**:
   ```bash
   m1f -s . -o bundle.txt --preset company-presets.yml project-presets.yml
   ```

## Preset Configuration File

Preset files are YAML documents that define processing rules:

```yaml
# Group name
my_project:
  description: "Processing rules for my project"
  enabled: true
  priority: 10 # Higher priority groups are checked first

  presets:
    # Preset for Python files
    python:
      extensions: [".py"]
      patterns:
        - "*.py"
        - "src/**/*.py" # Must include full path
        - "lib/**/*.py"
      actions:
        - strip_comments
        - remove_empty_lines
      separator_style: "Detailed"
      include_metadata: true

    # Preset for HTML files - remove specific tags
    html:
      extensions: [".html", ".htm"]
      actions:
        - minify
        - strip_tags
      strip_tags: ["script", "style", "meta", "link"]
      max_lines: 500 # Truncate after 500 lines

    # Preset for HTML to text conversion - strip all but content tags
    html_to_text:
      extensions: [".html"]
      actions:
        - strip_tags
      # Empty strip_tags means remove ALL tags
      strip_tags: []
      # But preserve content-relevant tags
      preserve_tags: ["p", "h1", "h2", "h3", "pre", "code", "blockquote"]

    # Default preset for unmatched files
    default:
      actions: []
      include_metadata: true
```

## Available Actions

### Built-in Actions

1. **`minify`** - Reduces file size by removing unnecessary whitespace. Keep in
   mind that removing comments may remove valuable context for AI models.

   - HTML: Removes comments, compresses whitespace
   - CSS: Removes comments, compresses rules
   - JS: Basic minification (removes comments and newlines)

2. **`strip_tags`** - Removes HTML tags

   - Use `strip_tags` to list tags to remove
   - Use `preserve_tags` to protect specific tags

3. **`strip_comments`** - Removes comments based on file type

   - **WARNING**: Removing comments removes valuable context for AI models.
     Comments often explain the "why" behind code, making it harder for AI to
     understand intent. Only use this when file size reduction is critical.
   - Python: Removes # comments (preserves docstrings)
   - JS/Java/C/C++: Removes // and /\* \*/ comments
   - CSS: Removes /\* \*/ comments
   - HTML: Removes <!-- --> comments

4. **`compress_whitespace`** - Normalizes whitespace

   - Replaces multiple spaces with single space
   - Reduces multiple newlines to double newline

5. **`remove_empty_lines`** - Removes all empty lines

6. **`join_paragraphs`** - Joins multi-line paragraphs into single lines
   (Markdown files)

   - Intelligently preserves code blocks, lists, tables, and other markdown
     structures
   - Helps maximize content density for LLMs that focus on first 200 lines
   - Only affects regular paragraph text

7. **`custom`** - Apply custom processor
   - Specify processor with `custom_processor`
   - Pass arguments with `processor_args`

### Built-in Custom Processors

m1f includes three built-in custom processors:

1. **`truncate`** - Limit content length

   - Truncates content to specified number of characters
   - Adds "[... truncated ...]" marker at the end
   - Useful for large log files or data files

   ```yaml
   actions:
     - custom
   custom_processor: "truncate"
   processor_args:
     max_chars: 1000 # Default: 1000
   ```

2. **`redact_secrets`** - Remove sensitive data

   - Uses regex patterns to find and replace secrets
   - Default patterns include: API keys, secrets, passwords, tokens, bearer
     tokens
   - Replaces matches with "[REDACTED]"

   ```yaml
   actions:
     - custom
   custom_processor: "redact_secrets"
   processor_args:
     patterns:  # Optional custom patterns
       - '(?i)api[_-]?key\s*[:=]\s*["\']?[\w-]+["\']?'
       - '(?i)bearer\s+[\w-]+'
   ```

3. **`extract_functions`** - Extract only function definitions (Python only)

   - Uses Python's AST parser to extract function definitions
   - Includes function names, signatures, and docstrings
   - Only works with `.py` files

   ```yaml
   actions:
     - custom
   custom_processor: "extract_functions"
   # No processor_args needed
   ```

## Important Notes on Binary Files

**m1f is designed for text files only.** Binary files (images, videos,
executables, etc.) are:

- Excluded by default
- Cannot be meaningfully processed even with `include_binary_files: true`
- Would need base64 encoding for proper inclusion (not implemented)

For binary file references, consider:

- Including just the filenames in a text list
- Using external tools to convert binary to text formats first
- Focusing on text-based assets for AI context

## Preset Options

### File Matching

- **`extensions`**: List of file extensions (e.g., `[".py", ".js"]`)
- **`patterns`**: Glob patterns for matching files (e.g., `["src/**/*.py"]`)

### Processing Options

- **`actions`**: List of processing actions to apply
- **`strip_tags`**: HTML tags to remove
- **`preserve_tags`**: HTML tags to keep when stripping
- **`separator_style`**: Override separator style
  - `"Standard"` (default) - Best for AI consumption: `--- FILE: path ---`
  - `"Detailed"` - Includes metadata: `===== FILE: path | ENCODING: utf-8 =====`
  - `"Markdown"` - Uses markdown code blocks
  - `"MachineReadable"` - Structured format for parsing
  - `"None"` - No separators
- **`max_lines`**: Truncate file after N lines

### Custom Processing

- **`custom_processor`**: Name of custom processor
- **`processor_args`**: Arguments for custom processor

## Examples

### WordPress Project

```yaml
wordpress:
  description: "WordPress project processing"

  presets:
    php:
      extensions: [".php"]
      actions:
        - remove_empty_lines # Keep comments for context

    config:
      patterns: ["wp-config*.php", ".env*"]
      actions:
        - custom
      custom_processor: "redact_secrets"

    sql:
      extensions: [".sql"]
      actions:
        - remove_empty_lines # Keep SQL comments
      max_lines: 1000 # Truncate large dumps
```

### Frontend Project

```yaml
frontend:
  description: "React/Vue/Angular project"

  presets:
    components:
      extensions: [".jsx", ".tsx", ".vue"]
      actions:
        - compress_whitespace
        - remove_empty_lines

    styles:
      extensions: [".css", ".scss"]
      actions:
        - minify
      # Note: exclude_patterns is available in global_settings, not in presets

    # Large log files - show only beginning
    logs:
      extensions: [".log"]
      actions:
        - custom
      custom_processor: "truncate"
      processor_args:
        max_chars: 5000 # Show first 5KB
```

### Documentation Project

```yaml
documentation:
  description: "Documentation processing"

  presets:
    markdown:
      extensions: [".md", ".mdx"]
      actions:
        - remove_empty_lines
      separator_style: "Markdown"

    code_examples:
      patterns: ["examples/**/*"]
      actions:
        - remove_empty_lines # Keep comments in examples
      max_lines: 50 # Keep examples concise
```

## Priority and Selection

When multiple preset groups are loaded:

1. Groups are checked by priority (highest first)
2. Within a group, presets are checked in order:
   - Extension matches
   - Pattern matches
   - Default preset
3. First matching preset is used
4. If no preset matches, standard m1f processing applies

## Command Line Usage

```bash
# Use single preset file
m1f -s . -o out.txt --preset my-presets.yml

# Use specific group
m1f -s . -o out.txt --preset presets.yml --preset-group backend

# Multiple preset files (merged in order)
m1f -s . -o out.txt --preset base.yml project.yml

# Disable all presets
m1f -s . -o out.txt --preset presets.yml --disable-presets
```

## Complete List of Supported Settings

### Global Settings

These apply to all files unless overridden:

```yaml
global_settings:
  # Encoding and formatting
  # encoding: "utf-8"  # Default encoding - supports: utf-8, utf-16, latin-1, cp1252, ascii, etc.
  # separator_style: "Standard"  # Default - best for AI consumption
  # line_ending: "lf"  # Default - Unix style (use "crlf" for Windows)

  # Include/exclude patterns
  include_patterns: ["src/**/*", "lib/**/*"]
  exclude_patterns: ["*.min.js", "*.map"]
  include_extensions: [".py", ".js", ".md"]
  exclude_extensions: [".log", ".tmp"]

  # File filtering
  include_dot_paths: false
  include_binary_files: false
  include_symlinks: false
  no_default_excludes: false
  max_file_size: "10MB"

  # Exclude/include file(s) - can be single file or list
  exclude_paths_file: ".gitignore"
  # Or multiple files:
  # exclude_paths_file:
  #   - ".gitignore"
  #   - ".m1fignore"
  #   - "custom-excludes.txt"

  # Include file(s) for whitelist mode
  # include_paths_file: "important-files.txt"
  # Or multiple files:
  # include_paths_file:
  #   - "core-files.txt"
  #   - "api-files.txt"

  # Processing options
  remove_scraped_metadata: true
  abort_on_encoding_error: false

  # Security
  security_check: "warn" # abort, skip, warn
```

### Encoding Options

m1f provides comprehensive encoding support:

**Supported Encodings**:

- `utf-8` (default) - Unicode UTF-8
- `utf-16` - Unicode UTF-16 with BOM detection
- `utf-16-le` - UTF-16 Little Endian
- `utf-16-be` - UTF-16 Big Endian
- `ascii` - Basic ASCII (7-bit)
- `latin-1` / `iso-8859-1` - Western European
- `cp1252` / `windows-1252` - Windows Western European
- Many more via Python's codecs module

**Encoding Configuration**:

```yaml
global_settings:
  encoding: "utf-8" # Target encoding for output (default)
  abort_on_encoding_error: false # Continue on errors (default)
  prefer_utf8_for_text_files: true # Auto UTF-8 for .md, .txt (default)
```

### Extension-Specific Settings

All file-specific settings can now be overridden per extension in
global_settings or in individual presets:

```yaml
global_settings:
  extensions:
    .md:
      actions: [remove_empty_lines]
      security_check: null # Disable security checks for markdown
      remove_scraped_metadata: true
    .php:
      actions: [strip_comments]
      security_check: "abort" # Strict security for PHP
      max_file_size: "5MB"
    .css:
      actions: [minify]
      max_file_size: "50KB" # Stricter size limit for CSS
    .log:
      include_dot_paths: true # Include hidden log files
      max_file_size: "100KB"

presets:
  sensitive_code:
    extensions: [".env", ".key", ".pem"]
    security_check: "abort"
    include_binary_files: false

  documentation:
    extensions: [".md", ".txt", ".rst"]
    security_check: null # No security check for docs
    remove_scraped_metadata: true
```

## Advanced Examples

### Security Check per File Type

Disable security checks for documentation but keep them for code:

```yaml
security_example:
  global_settings:
    security_check: "abort" # Default: strict

    extensions:
      .md:
        security_check: null # Disable for markdown
      .txt:
        security_check: null # Disable for text
      .rst:
        security_check: null # Disable for reStructuredText
      .php:
        security_check: "abort" # Keep strict for PHP
      .js:
        security_check: "warn" # Warn only for JS
      .env:
        security_check: "abort" # Very strict for env files
```

### Size Limits per File Type

Different size limits for different file types:

```yaml
size_limits:
  global_settings:
    max_file_size: "1MB" # Default limit

    extensions:
      .css:
        max_file_size: "50KB" # Stricter for CSS
      .js:
        max_file_size: "100KB" # JavaScript limit
      .php:
        max_file_size: "5MB" # More lenient for PHP
      .sql:
        max_file_size: "10MB" # Large SQL dumps allowed
      .log:
        max_file_size: "500KB" # Log file limit

  presets:
    # Override for specific patterns
    config_files:
      patterns: ["config/**/*.json", "*.config.js"]
      max_file_size: "10KB" # Keep config files small in bundle
```

### Different Processing by Location

Process files differently based on their location:

```yaml
conditional:
  presets:
    # Source files - keep readable
    source:
      patterns: ["src/**/*", "lib/**/*"]
      actions: [remove_empty_lines]

    # Test files - minimal processing
    tests:
      patterns: ["test/**/*", "tests/**/*", "*.test.*"]
      actions: [] # No processing needed

    # Example/demo files - compress
    examples:
      patterns: ["examples/**/*", "demo/**/*"]
      actions: [compress_whitespace]
      max_lines: 100 # Keep examples concise
```

### Combining Multiple Presets

You can load multiple preset files that build on each other:

```bash
m1f -s . -o bundle.txt \
  --preset base-rules.yml \
  --preset project-specific.yml \
  --preset production-overrides.yml
```

## Creating Custom Presets

1. **Start with a template**:

   ```bash
   # Use the comprehensive template with all available settings
   cp presets/template-all-settings.m1f-presets.yml my-project.m1f-presets.yml

   # Or start from a simpler example
   cp presets/web-project.m1f-presets.yml my-project.m1f-presets.yml
   ```

2. **Customize for your project**:

   - Identify file types needing special handling
   - Choose appropriate actions
   - Test with a small subset first

3. **Tips**:
   - Use `max_lines` for generated or data files
   - Apply `minify` only to production builds
   - Keep `preserve_tags` for code examples in HTML
   - Use high priority for project-specific rules

## Integration with CI/CD

```yaml
# GitHub Actions example
- name: Create bundle with presets
  run: |
    m1f \
      -s . \
      -o release-bundle.txt \
      --preset .github/release-presets.yml \
      --preset-group production
```

## Troubleshooting

### Preset not applying

- Check file extension includes the dot (`.py` not `py`)
- Verify pattern matches with `--verbose` flag
- Ensure preset group is enabled

### Wrong preset selected

- Check priority values (higher = checked first)
- Use specific patterns over broad extensions
- Use `--preset-group` to target specific group

### Processing errors

- Some actions may not work on all file types
- Binary files skip most processing
- Use `--verbose` to see which presets are applied

## Auto-Bundling Integration

The preset system integrates seamlessly with the auto-bundling scripts:

### Using Presets with Auto-Bundle

1. **With VS Code Tasks**:

   - Use the "Auto Bundle: With Preset" task
   - Select your preset file and optional group
   - The bundle will apply file-specific processing

2. **With m1f-update Command**:

   ```bash
   # Create all bundles with auto-bundle
   m1f-update

   # Create specific bundle
   m1f-update wordpress

   # List available bundles
   m1f-update --list
   ```

3. **Available Preset Bundles**:
   - `wordpress` - Theme and plugin development
   - `web-project` - Frontend/backend web projects
   - `documentation` - Documentation-focused bundles
   - Custom presets in `presets/` directory

### Benefits

- **Intelligent Filtering**: Each preset knows which files to include
- **Optimized Processing**: Apply minification only where beneficial
- **Security Control**: Different security levels for different file types
- **Size Management**: Appropriate size limits per file type

See the [Auto Bundle Guide](20_auto_bundle_guide.md) for more details on the
bundling system.

## See Also

- [**Preset System Complete Reference**](./10_preset_reference.md) -
  Comprehensive reference with all settings, undocumented features, and advanced
  patterns
- [**Per-File Settings Guide**](./11_preset_per_file_settings.md) - Deep dive
  into per-file processing
- [**Auto Bundle Guide**](./20_auto_bundle_guide.md) - Automated bundling with
  presets

======= docs/01_m1f/11_preset_per_file_settings.md ======
# Per-File-Type Settings in m1f Presets

The m1f preset system supports fine-grained control over processing settings on
a per-file-type basis. This allows you to apply different rules to different
file types within the same bundle.

## Overview

You can override almost any m1f setting for specific file extensions or
patterns. This is particularly useful for:

- Disabling security checks for documentation while keeping them for code
- Setting different size limits for CSS vs PHP files
- Applying different processing rules based on file type
- Handling sensitive files differently from public files

## Supported Per-File Settings

The following settings can be overridden on a per-file basis:

### Processing Settings

- `actions` - List of processing actions (minify, strip_comments, etc.)
- `strip_tags` - HTML tags to remove
- `preserve_tags` - HTML tags to preserve
- `separator_style` - Override separator style for specific files
- `include_metadata` - Whether to include file metadata
- `max_lines` - Truncate after N lines

### Security & Filtering

- `security_check` - Override security scanning (`"abort"`, `"skip"`, `"warn"`,
  `null`)
- `max_file_size` - File-specific size limit (e.g., `"50KB"`, `"5MB"`)
- `remove_scraped_metadata` - Remove HTML2MD metadata for specific files
- `include_dot_paths` - Include hidden files for this type
- `include_binary_files` - Include binary files for this type

### Custom Processing

- `custom_processor` - Name of custom processor to use
- `processor_args` - Arguments for the custom processor

## Configuration Methods

### Method 1: Global Extension Settings

Define defaults for all files of a specific extension:

```yaml
my_project:
  global_settings:
    # Default settings for all files
    security_check: "abort"
    max_file_size: "1MB"

    # Extension-specific overrides
    extensions:
      .md:
        security_check: null # Disable for markdown
        remove_scraped_metadata: true
        max_file_size: "500KB"

      .php:
        security_check: "abort" # Keep strict for PHP
        max_file_size: "5MB"
        actions: [strip_comments]

      .css:
        max_file_size: "50KB" # Strict limit for CSS
        actions: [minify, strip_comments]

      .env:
        security_check: "abort"
        include_dot_paths: true # Include .env files
        max_file_size: "10KB"
```

### Method 2: Preset-Specific Settings

Define settings for files matching specific patterns:

```yaml
my_project:
  presets:
    documentation:
      extensions: [".md", ".rst", ".txt"]
      patterns: ["docs/**/*", "README*"]
      security_check: null # No security check
      remove_scraped_metadata: true
      max_file_size: "1MB"

    sensitive_files:
      extensions: [".env", ".key", ".pem"]
      patterns: ["config/**/*", "secrets/**/*"]
      security_check: "abort"
      max_file_size: "50KB"
      include_dot_paths: true

    documentation:
      patterns: ["docs/**/*", "*.md"]
      security_check: null # Don't check documentation
      max_file_size: "100KB" # Keep docs concise
      actions: [remove_empty_lines]
```

## Real-World Examples

### Example 1: Web Project with Mixed Content

```yaml
web_project:
  global_settings:
    # Defaults
    security_check: "warn"
    max_file_size: "2MB"

    extensions:
      # Documentation - relaxed rules
      .md:
        security_check: null
        remove_scraped_metadata: true
        actions: [remove_empty_lines]

      # Frontend - strict size limits
      .css:
        max_file_size: "50KB"
        security_check: "skip"
        actions: [minify]

      .js:
        max_file_size: "100KB"
        security_check: "warn"
        actions: [strip_comments, compress_whitespace]

      # Backend - larger files, strict security
      .php:
        max_file_size: "5MB"
        security_check: "abort"
        actions: [strip_comments]

      # Data files - very different handling
      .sql:
        max_file_size: "10MB"
        security_check: null
        max_lines: 1000 # Truncate large dumps
```

### Example 2: Documentation Project

```yaml
documentation:
  global_settings:
    # Default: include everything for docs
    security_check: null
    remove_scraped_metadata: true

    extensions:
      # Markdown files
      .md:
        actions: [remove_empty_lines]
        separator_style: "Markdown"

      # Code examples in docs
      .py:
        max_lines: 50 # Keep examples short
        actions: [strip_comments]

      # Config examples
      .json:
        actions: [compress_whitespace]
        max_lines: 30

      # Log file examples
      .log:
        max_file_size: "100KB"
        max_lines: 100
```

### Example 3: Security-Focused Configuration

```yaml
secure_project:
  global_settings:
    # Very strict by default
    security_check: "abort"
    abort_on_encoding_error: true

    extensions:
      # Public documentation - can be relaxed
      .md:
        security_check: null

      # Code files - different levels
      .js:
        security_check: "warn" # Client-side code

      .php:
        security_check: "abort" # Server-side code

      .env:
        security_check: "abort"
        max_file_size: "10KB" # Env files should be small

      # Config files - careful handling
      .json:
        security_check: "warn"
        actions: [custom]
        custom_processor: "redact_secrets"
```

## Priority and Precedence

When multiple settings could apply to a file, they are resolved in this order:

1. **File-specific preset settings** (highest priority)
   - Settings in a preset that matches the file
2. **Global extension settings**
   - Settings in `global_settings.extensions`
3. **Global defaults** (lowest priority)
   - Settings in `global_settings`

Example:

```yaml
my_project:
  global_settings:
    max_file_size: "1MB" # Default for all

    extensions:
      .js:
        max_file_size: "500KB" # Override for JS files

  presets:
    vendor_js:
      patterns: ["vendor/**/*.js"]
      max_file_size: "2MB" # Override for vendor JS (highest priority)
```

## Best Practices

1. **Start with sensible defaults** in `global_settings`
2. **Use extension settings** for broad file-type rules
3. **Use presets** for location or context-specific overrides
4. **Document your choices** with comments
5. **Test incrementally** with `--verbose` to see which rules apply

## Limitations

- Settings cascade down but don't merge collections (e.g., `actions` lists
  replace, not extend)
- Some settings only make sense for certain file types
- Binary file detection happens before preset processing

## See Also

- [Preset System Guide](10_m1f_presets.md) - General preset documentation
- [Preset Template](../../presets/template-all-settings.m1f-presets.yml) -
  Complete example with all settings
- [Use Case Examples](../../presets/example-use-cases.m1f-presets.yml) -
  Real-world scenarios

======= docs/01_m1f/12_preset_reference.md ======
# m1f Preset System Complete Reference

This document provides a comprehensive reference for the m1f preset system,
including all available settings, clarifications, and advanced usage patterns.

## Table of Contents

- [Quick Start](#quick-start)
- [Preset File Format](#preset-file-format)
- [All Available Settings](#all-available-settings)
- [Available Actions](#available-actions)
- [Pattern Matching](#pattern-matching)
- [Processing Order](#processing-order)
- [Important Clarifications](#important-clarifications)
- [Advanced Features](#advanced-features)
- [Examples](#examples)
- [Debugging and Best Practices](#debugging-and-best-practices)

## Quick Start

The m1f preset system allows you to define file-specific processing rules and
configurations. Here's a minimal example:

```yaml
# my-preset.yml
web_assets:
  description: "Process web assets"
  presets:
    javascript:
      extensions: [".js", ".jsx"]
      actions: ["minify", "strip_comments"]
```

Use it with:

```bash
# Module invocation (recommended)
m1f -s ./src -o bundle.txt --preset my-preset.yml

# Direct command invocation (if installed)
m1f -s ./src -o bundle.txt --preset my-preset.yml
```

## Preset File Format

### Modern Format (Recommended)

```yaml
# Group name - can be selected with --preset-group
group_name:
  description: "Optional description of this preset group"
  enabled: true # Can disable entire group
  priority: 10 # Higher numbers are processed first (default: 0)

  presets:
    # Preset name (for internal reference)
    preset_name:
      patterns: ["*.js", "*.jsx"] # Glob patterns
      extensions: [".js", ".jsx"] # Extension matching (with or without dot)
      actions:
        - minify
        - strip_comments
        - compress_whitespace

      # Per-file overrides
      security_check: "warn" # error, skip, warn
      max_file_size: "500KB"
      include_dot_paths: true
      include_binary_files: false
      remove_scraped_metadata: true

      # Custom processor with arguments
      custom_processor: "truncate"
      processor_args:
        max_lines: 100
        add_marker: true

# Global settings (apply to all groups)
globals:
  global_settings:
    # Input/Output settings (NEW in v3.2.0)
    source_directory: "./src"
    input_file: "files_to_process.txt"
    output_file: "bundle.txt"
    input_include_files:
      - "README.md"
      - "INTRO.txt"

    # Output control (NEW in v3.2.0)
    add_timestamp: true
    filename_mtime_hash: false
    force: false
    minimal_output: false
    skip_output_file: false

    # Archive settings (NEW in v3.2.0)
    create_archive: false
    archive_type: "zip" # zip or tar.gz

    # Runtime behavior (NEW in v3.2.0)
    verbose: false
    quiet: false

    # Default file processing
    security_check: "warn"
    max_file_size: "1MB"

    # Per-extension settings
    extensions:
      .py:
        security_check: "error"
        max_file_size: "2MB"
      .env:
        security_check: "skip"
        actions: ["redact_secrets"]
```

## All Available Settings

### Group-Level Settings

| Setting       | Type    | Default | Description                     |
| ------------- | ------- | ------- | ------------------------------- |
| `description` | string  | none    | Human-readable description      |
| `enabled`     | boolean | true    | Enable/disable this group       |
| `priority`    | integer | 0       | Processing order (higher first) |

### Global Settings (NEW in v3.2.0)

These settings can be specified in the `global_settings` section and override
CLI defaults:

#### Input/Output Settings

| Setting               | Type        | Default | Description                                 |
| --------------------- | ----------- | ------- | ------------------------------------------- |
| `source_directory`    | string      | none    | Source directory path                       |
| `input_file`          | string      | none    | Input file listing paths to process         |
| `output_file`         | string      | none    | Output file path                            |
| `input_include_files` | string/list | []      | Files to include at beginning (intro files) |

#### Output Control Settings

| Setting                 | Type    | Default | Description                          |
| ----------------------- | ------- | ------- | ------------------------------------ |
| `add_timestamp`         | boolean | false   | Add timestamp to output filename     |
| `filename_mtime_hash`   | boolean | false   | Add hash of file mtimes to filename  |
| `force`                 | boolean | false   | Force overwrite existing output file |
| `minimal_output`        | boolean | false   | Only create main output file         |
| `skip_output_file`      | boolean | false   | Skip creating main output file       |
| `allow_duplicate_files` | boolean | false   | Allow duplicate content (v3.2)       |

#### Archive Settings

| Setting          | Type    | Default | Description                       |
| ---------------- | ------- | ------- | --------------------------------- |
| `create_archive` | boolean | false   | Create backup archive of files    |
| `archive_type`   | string  | "zip"   | Archive format: "zip" or "tar.gz" |

#### Runtime Settings

| Setting   | Type    | Default | Description                 |
| --------- | ------- | ------- | --------------------------- |
| `verbose` | boolean | false   | Enable verbose output       |
| `quiet`   | boolean | false   | Suppress all console output |

#### File Processing Settings

| Setting                        | Type    | Default | Description                         |
| ------------------------------ | ------- | ------- | ----------------------------------- |
| `encoding`                     | string  | "utf-8" | Target encoding for all files       |
| `separator_style`              | string  | none    | File separator style                |
| `line_ending`                  | string  | "lf"    | Line ending style (lf/crlf)         |
| `security_check`               | string  | "warn"  | How to handle secrets               |
| `max_file_size`                | string  | none    | Maximum file size to process        |
| `enable_content_deduplication` | boolean | true    | Enable content deduplication (v3.2) |
| `prefer_utf8_for_text_files`   | boolean | true    | Prefer UTF-8 for text files (v3.2)  |

### Preset-Level Settings

| Setting                   | Type    | Default | Description                                 |
| ------------------------- | ------- | ------- | ------------------------------------------- |
| `patterns`                | list    | []      | Glob patterns to match files                |
| `extensions`              | list    | []      | File extensions to match                    |
| `actions`                 | list    | []      | Processing actions to apply                 |
| `security_check`          | string  | "warn"  | How to handle secrets                       |
| `max_file_size`           | string  | none    | Maximum file size to process                |
| `include_dot_paths`       | boolean | false   | Include hidden files                        |
| `include_binary_files`    | boolean | false   | Process binary files                        |
| `remove_scraped_metadata` | boolean | false   | Remove HTML2MD metadata                     |
| `custom_processor`        | string  | none    | Name of custom processor                    |
| `processor_args`          | dict    | {}      | Arguments for custom processor              |
| `line_ending`             | string  | "lf"    | Convert line endings (lf, crlf)             |
| `separator_style`         | string  | none    | Override default separator style            |
| `include_metadata`        | boolean | true    | Include file metadata in output             |
| `max_lines`               | integer | none    | Truncate file after N lines                 |
| `strip_tags`              | list    | []      | HTML tags to remove (for strip_tags action) |
| `preserve_tags`           | list    | []      | HTML tags to preserve when stripping        |

## Available Actions

### Built-in Actions

1. **`minify`** - Remove unnecessary whitespace and formatting

   - Reduces file size
   - Maintains functionality
   - Best for: JS, CSS, HTML

2. **`strip_tags`** - Remove HTML/XML tags

   - Extracts text content only
   - Preserves text between tags
   - Best for: HTML, XML, Markdown with HTML

3. **`strip_comments`** - Remove code comments

   - Removes single and multi-line comments
   - Language-aware (JS, Python, CSS, etc.)
   - Best for: Production code bundles

4. **`compress_whitespace`** - Reduce multiple spaces/newlines

   - Converts multiple spaces to single space
   - Reduces multiple newlines to double newline
   - Best for: Documentation, logs

5. **`remove_empty_lines`** - Remove blank lines
   - Removes lines with only whitespace
   - Keeps single blank lines between sections
   - Best for: Clean documentation

### Custom Processors

Currently implemented:

1. **`truncate`** - Limit file length

   ```yaml
   custom_processor: "truncate"
   processor_args:
     max_lines: 100
     max_chars: 10000
     add_marker: true # Add "... truncated ..." marker
   ```

2. **`redact_secrets`** - Remove sensitive data

   ```yaml
   custom_processor: "redact_secrets"
   processor_args:
     patterns:
       - '(?i)(api[_-]?key|secret|password|token)\\s*[:=]\\s*["\\']?[\\w-]+["\\']?'
       - '(?i)bearer\\s+[\\w-]+'
     replacement: "[REDACTED]"
   ```

3. **`extract_functions`** - Extract function definitions
   ```yaml
   custom_processor: "extract_functions"
   processor_args:
     languages: ["python", "javascript"]
     include_docstrings: true
   ```

Note: Other processors mentioned in examples (like `extract_code_cells`) are
illustrative and would need to be implemented.

## Pattern Matching

### Pattern Types

1. **Extension Matching**

   ```yaml
   extensions: [".py", ".pyx", "py"] # All are equivalent
   ```

2. **Glob Patterns**

   ```yaml
   patterns:
     - "*.test.js" # All test files
     - "src/**/*.js" # All JS in src/
   ```

3. **Combined Matching**
   ```yaml
   # File must match BOTH extension AND pattern
   extensions: [".js"]
   patterns: ["src/**/*"]
   ```

## Processing Order

1. **Group Priority** - Higher priority groups are checked first
2. **Preset Order** - Within a group, presets are checked in definition order
3. **First Match Wins** - First matching preset is applied
4. **Action Order** - Actions are applied in the order listed

### Setting Precedence

1. CLI arguments (highest priority)
2. Preset-specific settings
3. Global per-extension settings
4. Global default settings
5. m1f defaults (lowest priority)

**Note**: CLI arguments ALWAYS override preset values.

## Important Clarifications

### Pattern Matching Limitations

**Exclude patterns with `!` prefix are not supported in preset patterns**. To
exclude files:

1. **Use Global Settings** (Recommended):

   ```yaml
   globals:
     global_settings:
       exclude_patterns: ["*.min.js", "*.map", "dist/**/*"]
   ```

2. **Use CLI Arguments**:
   ```bash
   m1f -s . -o out.txt --exclude-patterns "*.min.js" "*.map"
   ```

### Settings Hierarchy

Understanding where settings can be applied:

1. **Global Settings Level** (`globals.global_settings`):

   - `include_patterns` / `exclude_patterns`
   - `include_extensions` / `exclude_extensions`
   - All general m1f settings

2. **Preset Level** (individual presets):

   - `patterns` and `extensions` (for matching)
   - `actions` (processing actions)
   - Override settings like `security_check`

3. **Extension-Specific Global Settings**
   (`globals.global_settings.extensions.{ext}`):
   - All preset-level settings per extension

### Common Misconceptions

1. **Exclude Patterns in Presets**

   ❌ **Incorrect**:

   ```yaml
   presets:
     my_preset:
       exclude_patterns: ["*.min.js"] # Doesn't work here
   ```

   ✅ **Correct**:

   ```yaml
   globals:
     global_settings:
       exclude_patterns: ["*.min.js"] # Works here
   ```

2. **Actions vs Settings**

   **Actions** (go in `actions` list):

   - `minify`, `strip_tags`, `strip_comments`, etc.

   **Settings** (separate fields):

   - `strip_tags: ["script", "style"]` (configuration)
   - `max_lines: 100` (configuration)

## Advanced Features

### Conditional Enabling

To conditionally enable/disable preset groups:

```yaml
production:
  enabled: false # Manually disable this group
  presets:
    minify_all:
      extensions: [".js", ".css", ".html"]
      actions: ["minify"]
```

**Note**: The `enabled_if_exists` feature is only available in auto-bundle
configurations (`.m1f.config.yml`), not in preset files.

### Multiple Preset Files

```bash
# Files are merged in order (later files override earlier ones)
m1f -s . -o out.txt \
  --preset base.yml \
  --preset project.yml \
  --preset overrides.yml
```

### Preset Locations

1. **Project presets**: `./presets/*.m1f-presets.yml`
2. **Local preset**: `./.m1f-presets.yml`
3. **User presets**: `~/m1f/*.m1f-presets.yml`
4. **Specified presets**: Via `--preset` flag

### Complete Parameter Control (v3.2.0+)

Starting with v3.2.0, ALL m1f parameters can be controlled via presets:

```yaml
# production.m1f-presets.yml
production:
  description: "Production build configuration"

  global_settings:
    # Define all inputs/outputs
    source_directory: "./src"
    output_file: "dist/bundle.txt"
    input_include_files: ["README.md", "LICENSE"]

    # Enable production features
    add_timestamp: true
    create_archive: true
    archive_type: "tar.gz"
    force: true

    # Production optimizations
    minimal_output: true
    quiet: true

    # File processing
    separator_style: "MachineReadable"
    encoding: "utf-8"
    security_check: "error"
```

Usage comparison:

**Before v3.2.0** (long command):

```bash
m1f -s ./src -o dist/bundle.txt \
  --input-include-files README.md LICENSE \
  --add-timestamp --create-archive --archive-type tar.gz \
  --force --minimal-output --quiet \
  --separator-style MachineReadable \
  --security-check error
```

**After v3.2.0** (simple command):

```bash
m1f --preset production.m1f-presets.yml -o output.txt
```

## Examples

### Web Development Preset

```yaml
web_development:
  description: "Modern web development bundle"

  presets:
    # Minify production assets
    production_assets:
      patterns: ["dist/**/*", "build/**/*"]
      extensions: [".js", ".css"]
      actions: ["minify", "strip_comments"]

    # Source code - keep readable
    source_code:
      patterns: ["src/**/*"]
      extensions: [".js", ".jsx", ".ts", ".tsx"]
      actions: ["strip_comments"]
      security_check: "error"

    # Documentation
    docs:
      extensions: [".md", ".mdx"]
      actions: ["compress_whitespace", "remove_empty_lines"]

    # Configuration files
    config:
      patterns: ["*.json", "*.yml", "*.yaml"]
      security_check: "error"
      custom_processor: "redact_secrets"
```

### Data Science Preset

```yaml
data_science:
  presets:
    # Large data files - truncate
    data_files:
      extensions: [".csv", ".json", ".parquet"]
      max_file_size: "100KB"
      custom_processor: "truncate"
      processor_args:
        max_lines: 1000

    # Scripts - full content
    scripts:
      extensions: [".py", ".r", ".jl"]
      actions: ["strip_comments"]
```

### Multiple Environment Presets

```yaml
# environments.m1f-presets.yml
development:
  priority: 10
  global_settings:
    source_directory: "./src"
    output_file: "dev-bundle.txt"
    verbose: true
    include_dot_paths: true
    security_check: "warn"

staging:
  priority: 20
  global_settings:
    source_directory: "./src"
    output_file: "stage-bundle.txt"
    create_archive: true
    security_check: "error"

production:
  priority: 30
  global_settings:
    source_directory: "./dist"
    output_file: "prod-bundle.txt"
    minimal_output: true
    quiet: true
    create_archive: true
    archive_type: "tar.gz"
```

Use with `--preset-group`:

```bash
# Development build
m1f --preset environments.yml --preset-group development

# Production build
m1f --preset environments.yml --preset-group production
```

## Debugging and Best Practices

### Debugging Tips

1. **Verbose Mode**

   ```bash
   m1f -s . -o out.txt --preset my.yml --verbose
   ```

   Shows which preset is applied to each file and processing details.

2. **Check What's Applied**

   ```bash
   m1f -s . -o out.txt --preset my.yml --verbose 2>&1 | grep "Applying preset"
   ```

3. **Validate YAML**

   ```bash
   python -c "import yaml; yaml.safe_load(open('my-preset.yml'))"
   ```

4. **Test Small First** Create a test directory with a few files to verify
   preset behavior before running on large codebases.

### Best Practices

1. **Start Simple** - Begin with basic actions, add complexity as needed
2. **Test Thoroughly** - Use verbose mode to verify behavior
3. **Layer Presets** - Use multiple files for base + overrides
4. **Document Presets** - Add descriptions to groups and complex presets
5. **Version Control** - Keep presets in your repository
6. **Performance First** - Apply expensive actions only where needed
7. **Use Priority Wisely** - Higher priority groups are checked first

### Common Issues

1. **Preset not applied**

   - Check pattern matching
   - Verify preset group is enabled
   - Use verbose mode to debug

2. **Wrong action order**

   - Actions are applied sequentially
   - Order matters (e.g., minify before strip_comments)

3. **Performance issues**
   - Limit expensive actions to necessary files
   - Use `max_file_size` to skip large files
   - Consider `minimal_output` mode

## Version Information

This documentation is accurate as of m1f version 3.2.0.

======= docs/01_m1f/20_auto_bundle_guide.md ======
# Auto-Bundle Guide

The m1f auto-bundle feature allows you to automatically generate predefined
bundles of files based on configuration. This is especially useful for
maintaining consistent documentation bundles, creating project snapshots, and
managing multiple projects on a server.

## Configuration File

Auto-bundle looks for a `.m1f.config.yml` file in your project. The tool
searches from the current directory upward to the root, allowing flexible
project organization.

### Basic Configuration Structure

```yaml
# .m1f.config.yml

# Global settings that apply to all bundles
global:
  global_excludes:
    - "**/*.pyc"
    - "**/*.log"
    - "**/tmp/**"

# Bundle definitions
bundles:
  docs:
    description: "Project documentation"
    output: "m1f/docs/manual.txt"
    sources:
      - path: "docs"
        include_extensions: [".md", ".txt"]

  code:
    description: "Source code bundle"
    output: "m1f/src/code.txt"
    sources:
      - path: "src"
        include_extensions: [".py", ".js", ".ts"]
```

## Command Usage

### Create All Bundles

```bash
m1f auto-bundle
# Or use the convenient alias:
m1f-update
```

### Create Specific Bundle

```bash
m1f auto-bundle docs
# Or use the convenient alias:
m1f-update docs
```

### List Available Bundles

```bash
m1f auto-bundle --list
```

### Create Bundles by Group

```bash
m1f auto-bundle --group documentation
# Or use the convenient alias:
m1f-update --group documentation
```

**Note**: The `m1f-update` command is a convenient alias for `m1f auto-bundle`
that provides a simpler way to regenerate bundles.

## Bundle Groups

You can organize bundles into groups for easier management:

```yaml
bundles:
  user-docs:
    description: "User documentation"
    group: "documentation"
    output: "m1f/docs/user.txt"
    sources:
      - path: "docs/user"

  api-docs:
    description: "API documentation"
    group: "documentation"
    output: "m1f/docs/api.txt"
    sources:
      - path: "docs/api"

  frontend-code:
    description: "Frontend source code"
    group: "source"
    output: "m1f/src/frontend.txt"
    sources:
      - path: "frontend"
```

Then create all documentation bundles:

```bash
m1f auto-bundle --group documentation
```

## Server-Wide Usage

### Managing Multiple Projects

For server environments with multiple projects, you can create a management
script:

```bash
#!/bin/bash
# update-all-bundles.sh

# Find all projects with .m1f.config.yml
for config in $(find /home/projects -name ".m1f.config.yml" -type f); do
    project_dir=$(dirname "$config")
    echo "Updating bundles in: $project_dir"

    cd "$project_dir"
    m1f-update --quiet
done
```

### Project-Specific Bundles

Create project-specific configurations by using groups:

```yaml
# Project A - .m1f.config.yml
bundles:
  all:
    description: "Complete project bundle"
    group: "project-a"
    output: "m1f/project-a-complete.txt"
    sources:
      - path: "."
```

Then update only specific projects:

```bash
cd /path/to/project-a
m1f-update --group project-a
```

### Automated Bundle Updates

Set up a cron job for automatic updates:

```bash
# Update all project bundles daily at 2 AM
0 2 * * * /usr/local/bin/update-all-bundles.sh
```

### Organized Bundle Output

Keep bundles organized within your project:

```yaml
bundles:
  project-bundle:
    description: "Main project bundle"
    output: "bundles/latest/project.txt" # Relative to project root
    sources:
      - path: "src"

  archived-bundle:
    description: "Archived version with timestamp"
    output: "bundles/archive/project-{timestamp}.txt"
    add_timestamp: true
    sources:
      - path: "."
```

**Note**: For security reasons, m1f only allows output paths within the project
directory. Use relative paths for portability.

## Advanced Features

### Conditional Bundles

Enable bundles only when specific files exist:

```yaml
bundles:
  python-docs:
    description: "Python documentation"
    enabled_if_exists: "setup.py"
    output: "m1f/python-docs.txt"
    sources:
      - path: "."
        include_extensions: [".py"]
```

### Multiple Source Configurations

Combine files from different locations with different settings:

```yaml
bundles:
  complete:
    description: "Complete project documentation"
    output: "m1f/complete.txt"
    sources:
      - path: "docs"
        include_extensions: [".md"]
      - path: "src"
        include_extensions: [".py"]
        excludes: ["**/test_*.py"]
      - path: "."
        include_files: ["README.md", "CHANGELOG.md"]

  # New in v3.4.0: Using includes patterns
  tool-specific:
    description: "Specific tool code only"
    output: "m1f/tool-code.txt"
    sources:
      - path: "tools/"
        include_extensions: [".py"]
        includes: ["m1f/**", "s1f/**", "!**/test_*.py"]
```

### Using Presets

Apply presets for advanced file processing:

```yaml
bundles:
  web-bundle:
    description: "Web project bundle"
    output: "m1f/web.txt"
    preset: "presets/web-project.m1f-presets.yml"
    preset_group: "production"
    sources:
      - path: "."
```

## Automatic Bundle Generation with Git Hooks

m1f provides a Git pre-commit hook that automatically runs auto-bundle before
each commit. This ensures your bundles are always in sync with your source code.

### Installing the Git Hook

```bash
# Run from your project root (where .m1f.config.yml is located)
bash /path/to/m1f/scripts/install-git-hooks.sh
```

The hook will:

- Run `m1f-update` before each commit
- Add generated bundles to the commit automatically
- Block commits if bundle generation fails

For detailed setup instructions, see the
[Git Hooks Setup Guide](../05_development/56_git_hooks_setup.md).

## Best Practices

1. **Organize with Groups**: Use groups to categorize bundles logically
2. **Version Control**: Include `.m1f.config.yml` in version control
3. **Include m1f/ Directory**: Keep generated bundles in version control for AI
   tool access
4. **Use Descriptive Names**: Make bundle names self-explanatory
5. **Regular Updates**: Use Git hooks or schedule automatic updates for
   frequently changing projects
6. **Review Bundle Changes**: Check generated bundle diffs before committing

## Troubleshooting

### Config Not Found

If you see "No .m1f.config.yml configuration found!", the tool couldn't find a
config file searching from the current directory up to the root. Create a
`.m1f.config.yml` in your project root.

### Bundle Not Created

Check the verbose output:

```bash
m1f-update --verbose
```

Common issues:

- Incorrect file paths
- Missing source directories
- Invalid YAML syntax
- Disabled bundles

### Group Not Found

If using `--group` and no bundles are found:

1. Check that bundles have the `group` field
2. Verify the group name matches exactly
3. Use `--list` to see available groups

## Examples

### Documentation Site Bundle

```yaml
bundles:
  docs-site:
    description: "Documentation site content"
    group: "documentation"
    output: "m1f/docs-site.txt"
    sources:
      - path: "content"
        include_extensions: [".md", ".mdx"]
      - path: "src/components"
        include_extensions: [".jsx", ".tsx"]
    excludes:
      - "**/node_modules/**"
      - "**/.next/**"
```

### Multi-Language Project

```yaml
bundles:
  python-code:
    description: "Python backend code"
    group: "backend"
    output: "m1f/backend/python.txt"
    sources:
      - path: "backend"
        include_extensions: [".py"]

  javascript-code:
    description: "JavaScript frontend code"
    group: "frontend"
    output: "m1f/frontend/javascript.txt"
    sources:
      - path: "frontend"
        include_extensions: [".js", ".jsx", ".ts", ".tsx"]

  all-code:
    description: "All source code"
    output: "m1f/all-code.txt"
    sources:
      - path: "."
        include_extensions: [".py", ".js", ".jsx", ".ts", ".tsx"]
```

### Combining Multiple Directories (v3.4.0+)

When you need to combine files from completely different directories:

```yaml
bundles:
  # Combine documentation from multiple locations
  all-docs:
    description: "All project documentation"
    output: "m1f/all-docs.txt"
    sources:
      - path: "docs"
      - path: "src"
        include_extensions: [".md"]
      - path: "../shared-docs"
      - path: "/absolute/path/to/external/docs"
        includes: ["api/**", "guides/**"]
```

### WordPress Plugin Bundle

```yaml
bundles:
  wp-plugin:
    description: "WordPress plugin files"
    group: "wordpress"
    output: "m1f/wp-plugin.txt"
    preset: "presets/wordpress.m1f-presets.yml"
    sources:
      - path: "."
        include_extensions: [".php", ".js", ".css"]
    excludes:
      - "**/vendor/**"
      - "**/node_modules/**"
```

======= docs/01_m1f/21_development_workflow.md ======
# m1f Development Workflow

This document describes the recommended workflow for developing with m1f and
using it in other projects.

## Overview

The m1f project provides a self-contained development environment with:

- Pre-generated m1f bundles of its own source code
- Shell aliases for convenient access from anywhere
- Symlink system for using m1f documentation in other projects

## Prerequisites

For initial setup instructions, see the [SETUP.md](../../SETUP.md) guide.

## Using m1f in Other Projects

### Method 1: Using Aliases (Recommended)

From any directory, you can use m1f directly:

```bash
cd /path/to/your/project
m1f -s . -o combined.txt
```

### Method 2: Quick Project Setup with m1f-init

When starting a new project with m1f, use `m1f-init` for quick setup:

```bash
cd /path/to/your/project
m1f-init
```

#### What m1f-init does:

1. **Links m1f documentation** (creates `m1f/m1f.txt`)
   - Makes m1f docs available to AI tools
   - Creates symlink on Linux/macOS, copies on Windows
   - Use `--no-symlink` to skip this step if not needed

2. **Analyzes your project**
   - Detects project type and programming languages
   - Supports Python, JavaScript, TypeScript, PHP, Java, C#, Go, Rust, Ruby
   - Creates file and directory listings
   - Shows clean output with created files listed at the end
   - Automatically cleans up temporary analysis files

3. **Generates initial bundles with auxiliary files**
   - `m1f/<project>_complete.txt` - Full project bundle
   - `m1f/<project>_complete_filelist.txt` - List of all included files
   - `m1f/<project>_complete_dirlist.txt` - List of all directories
   - `m1f/<project>_docs.txt` - Documentation only bundle
   - `m1f/<project>_docs_filelist.txt` - List of documentation files
   - `m1f/<project>_docs_dirlist.txt` - Documentation directories

4. **Creates basic configuration**
   - Generates `.m1f.config.yml` if not present
   - Sets up sensible defaults
   - Handles .gitignore correctly (only uses from current directory)
   - Smart Git detection (clean messages for subdirectories)

#### Using with AI Tools:

After running `m1f-init`, reference the documentation in your AI tool:

```bash
# For Claude Code, Cursor, or similar AI assistants:
@m1f/m1f.txt

# Example prompts:
"Please read @m1f/m1f.txt and help me create custom bundles
for my Python web application"

"Based on @m1f/m1f.txt, how can I exclude test files
while keeping fixture data?"

"Using @m1f/m1f.txt as reference, help me optimize
my .m1f.config.yml for a React project"
```

#### Advanced Setup (Linux/macOS only):

For topic-specific bundles and Claude-assisted configuration:

```bash
m1f-claude --setup
```

#### Working with File Lists:

The generated file lists are valuable for customizing bundles:

```bash
# View what files are included
cat m1f/*_filelist.txt | wc -l  # Count total files

# Edit file lists to customize bundles
vi m1f/myproject_complete_filelist.txt
# Remove lines for files you don't want
# Add paths for files you do want

# Create a custom bundle from edited list
m1f -i m1f/myproject_complete_filelist.txt -o m1f/custom.txt

# Combine multiple file lists
cat m1f/*_docs_filelist.txt m1f/api_filelist.txt | sort -u > m1f/combined_list.txt
m1f -i m1f/combined_list.txt -o m1f/docs_and_api.txt
```

This single documentation file contains:

- Complete m1f usage guide and all parameters
- Examples and best practices
- Preset system documentation
- Auto-bundle configuration guide
- All tool documentation (m1f, s1f, html2md, webscraper)

The AI can then:

- Understand all m1f parameters and options
- Help create custom `.m1f.config.yml` configurations
- Suggest appropriate presets for your project type
- Generate complex m1f commands with correct syntax
- Troubleshoot issues based on error messages

## Development Workflow

### When Developing m1f

1. Always work in the development environment:

   ```bash
   cd /path/to/m1f
   source .venv/bin/activate
   ```

2. Test changes directly:

   ```bash
   python -m tools.m1f -s test_dir -o output.txt
   ```

3. Run tests:

   ```bash
   pytest tests/
   ```

4. Update bundle files after significant changes:
   ```bash
   m1f-update
   ```

### When Using m1f in Projects

1. Use the global aliases:

   ```bash
   m1f -s src -o bundle.txt --preset documentation
   ```

2. Or create project-specific configuration:

   ```bash
   # Create .m1f directory in your project
   mkdir .m1f

   # Create m1f preset
   cat > .m1f/project.m1f-presets.yml << 'EOF'
   presets:
     my-bundle:
       source_directory: "."
       include_extensions: [".py", ".md", ".txt"]
       excludes: ["*/node_modules/*", "*/__pycache__/*"]
   EOF

   # Use preset
   m1f --preset .m1f/project.m1f-presets.yml --preset-group my-bundle -o bundle.txt
   ```

## Directory Structure

```
m1f/
├── .m1f/                      # Pre-generated m1f bundles
│   ├── m1f/                   # Tool bundles
│   └── m1f-doc/
│       └── 99_m1fdocs.txt    # Complete documentation
├── bin/                       # Executable commands
│   ├── m1f
│   ├── m1f-s1f
│   ├── m1f-html2md
│   ├── scrape_tool
│   └── ...
├── scripts/
│   ├── install.sh            # Installation script
│   └── watch_and_bundle.sh   # File watcher for auto-bundling
└── tools/                    # m1f source code
    ├── m1f/
    ├── s1f/
    └── html2md/

your-project/
└── .m1f/
    └── m1f -> /path/to/m1f/.m1f/  # Symlink to m1f bundles
```

## Best Practices

1. **Keep Bundles Updated**: Run `m1f-update` after significant changes to m1f
2. **Use Aliases**: The shell aliases handle virtual environment activation
   automatically
3. **Project Organization**: Keep project-specific m1f configurations in `.m1f/`
   directory
4. **Version Control**: The `.m1f/` directory is already in `.gitignore`

## Troubleshooting

### Aliases Not Working

If aliases don't work after setup:

1. Make sure you've reloaded your shell configuration
2. Check that the aliases were added to your shell config file
3. Verify the m1f project path is correct in the aliases

### Virtual Environment Issues

The aliases automatically activate the virtual environment. If you encounter
issues:

1. Ensure the virtual environment exists at `/path/to/m1f/.venv`
2. Check that all dependencies are installed

### Symlink Issues

If `m1f-link` fails:

1. Ensure you have write permissions in the current directory
2. Check that the m1f project path is accessible
3. Remove any existing `.m1f/m1f` symlink and try again

## Advanced Usage

### Custom Bundle Generation

Create custom bundles for specific use cases:

```bash
# Bundle only specific file types
m1f -s /path/to/project -o api-docs.txt \
    --include-extensions .py .yaml \
    --excludes "*/tests/*" \
    --separator-style Markdown

# Create compressed archive
m1f -s . -o project.txt --create-archive --archive-type tar.gz
```

### Integration with CI/CD

Add m1f to your CI pipeline:

```yaml
# Example GitHub Actions
- name: Generate Documentation Bundle
  run: |
    python -m tools.m1f -s docs -o docs-bundle.txt

- name: Upload Bundle
  uses: actions/upload-artifact@v2
  with:
    name: documentation
    path: docs-bundle.txt
```

======= docs/01_m1f/25_m1f_config_examples.md ======
# m1f Configuration Examples

This guide provides comprehensive examples of `.m1f.config.yml` files for
different project types. Each example includes detailed comments explaining the
configuration choices.

> **⚠️ IMPORTANT**: m1f automatically excludes many common directories
> (node_modules, .git, **pycache**, etc.). See the
> [Default Excludes Guide](./26_default_excludes_guide.md) for the complete
> list. **Only add project-specific excludes to keep your configs minimal!**

## 🚨 IMPORTANT: Use Standard Separator for AI Bundles!

**The primary purpose of m1f bundles is to provide context to AI assistants like
Claude, NOT for human reading in Markdown!**

- ✅ **ALWAYS use**: `separator_style: Standard` (or omit it - Standard is the
  default)
- ❌ **AVOID**: `separator_style: Markdown` (this adds unnecessary ```language
  blocks)
- 🎯 **Why**: Standard format is clean and optimal for AI consumption

```yaml
# CORRECT - For AI consumption:
bundles:
  - name: my-bundle
    separator_style: Standard  # ← This is optimal (or just omit it)

# AVOID - Adds unnecessary markdown formatting:
bundles:
  - name: my-bundle
    separator_style: Markdown  # ← Don't use for AI bundles!
```

**Note**: `MachineReadable` is only needed when you plan to use `s1f` to split
the bundle back into individual files.

## Minimal vs Verbose Configurations

### ❌ BAD Example - Overly Verbose (Don't Do This!)

```yaml
global:
  global_excludes:
    # ❌ ALL of these are already excluded by default!
    - "**/node_modules/**" # Auto-excluded
    - "**/vendor/**" # Auto-excluded
    - "**/__pycache__/**" # Auto-excluded
    - "**/build/**" # Auto-excluded
    - "**/dist/**" # Auto-excluded
    - "**/.git/**" # Auto-excluded
    - "**/cache/**" # Auto-excluded
    - "**/.vscode/**" # Auto-excluded
    - "**/.idea/**" # Auto-excluded

    # ✅ Only these are needed (project-specific)
    - "**/logs/**"
    - "**/tmp/**"
    - "/m1f/**"
```

### ✅ GOOD Example - Minimal Configuration

```yaml
global:
  global_excludes:
    # Only project-specific excludes
    - "**/logs/**" # Your log files
    - "**/tmp/**" # Your temp files
    - "/m1f/**" # Output directory

  global_settings:
    # Let .gitignore handle most excludes
    exclude_paths_file: ".gitignore"
```

## Table of Contents

1. [m1f Tool Project (Current)](#m1f-tool-project-current)
2. [Node.js/React Project](#nodejsreact-project)
3. [Python/Django Project](#pythondjango-project)
4. [WordPress Theme](#wordpress-theme)
5. [Documentation Site](#documentation-site)
6. [Mixed Language Project](#mixed-language-project)
7. [Microservices Architecture](#microservices-architecture)
8. [Mobile App Project](#mobile-app-project)

## m1f Tool Project (Current)

This is the actual configuration used by the m1f project itself - a Python-based
tool with comprehensive documentation.

```yaml
# m1f Auto-Bundle Configuration

# Global settings
global:
  # Exclusions that apply to all bundles
  global_excludes:
    - "/m1f/**" # Exclude output directory
    - "**/*.pyc" # Python bytecode
    - "**/*.log" # Log files
    - "**/tmp/**" # Temporary directories
    - "**/dev/**" # Development files
    - "**/tests/**/source/**" # Test input data
    - "**/tests/**/output/**" # Test output data
    - "**/tests/**/expected/**" # Expected test results
    - "**/tests/**/scraped_examples/**" # Scraped test examples

  global_settings:
    # Default security setting for all files
    security_check: "warn" # Strict by default
    # Use .gitignore as exclude file (can be single file or list)
    exclude_paths_file:
      - ".gitignore"
      - ".m1fignore"

    # Per-extension overrides
    extensions:
      .py:
        security_check: "abort" # Strict for Python files

  # Default settings for all bundles
  defaults:
    force_overwrite: true
    max_file_size: "1MB"
    minimal_output: false

  # File watcher settings for auto-update
  watcher:
    enabled: true
    debounce_seconds: 2
    ignored_paths:
      - "/m1f"
      - ".git/"
      - ".venv/"
      - "tmp/"
      - ".scrapes/"

# Bundle definitions
bundles:
  # Documentation bundles - separate by tool
  m1f-docs:
    description: "m1f docs"
    group: "documentation"
    output: "m1f/m1f/87_m1f_only_docs.txt"
    sources:
      - path: "docs/01_m1f"

  html2md-docs:
    description: "html2md docs"
    group: "documentation"
    output: "m1f/m1f/88_html2md_docs.txt"
    sources:
      - path: "docs/03_html2md"

  # Source code bundles - modular approach
  m1f-code:
    description: "m1f complete code"
    group: "source"
    output: "m1f/m1f/94_code.txt"
    sources:
      - path: "."
        includes:
          [
            "README.md",
            "SETUP.md",
            "requirements.txt",
            "tools/**",
            "scripts/**",
          ]
      - path: "tests/"
        excludes:
          [
            "**/tests/**/source/**",
            "**/tests/**/extracted/**",
            "**/tests/**/output/**",
          ]

  # Complete project bundle
  all:
    description: "All 1 One"
    group: "complete"
    output: "m1f/m1f/99_m1f_complete.txt"
    sources:
      - path: "."
```

## Node.js/React Project

Configuration for a modern React application with TypeScript and testing.

```yaml
# React Application m1f Configuration

global:
  global_excludes:
    # ⚠️ MINIMAL CONFIG - Only project-specific excludes!
    # DON'T add node_modules, dist, build - they're auto-excluded!

    # Next.js specific (not in defaults)
    - "**/.next/**" # Next.js build cache
    - "**/coverage/**" # Test coverage reports

    # Log and temp files
    - "**/*.log"
    - "**/*.map" # Source maps
    - "**/.DS_Store"
    - "**/Thumbs.db"

  global_settings:
    security_check: "warn"
    exclude_paths_file: [".gitignore", ".eslintignore"]

    # JavaScript/TypeScript specific processing
    extensions:
      .js:
        minify: true # Minify for AI context
        remove_comments: true # Clean comments
      .jsx:
        minify: true
        remove_comments: true
      .ts:
        minify: true
        remove_comments: true
      .tsx:
        minify: true
        remove_comments: true
      .json:
        minify: true # Compact JSON
      .env:
        security_check: "abort" # Never include env files

  defaults:
    force_overwrite: true
    max_file_size: "500KB" # Smaller for JS files
    minimal_output: true # Compact output

bundles:
  # Application source code
  app-components:
    description: "React components"
    group: "frontend"
    output: "m1f/01_components.txt"
    sources:
      - path: "src/components"
        include_extensions: [".tsx", ".ts", ".css", ".scss"]
      - path: "src/hooks"
        include_extensions: [".ts", ".tsx"]

  app-pages:
    description: "Application pages/routes"
    group: "frontend"
    output: "m1f/02_pages.txt"
    sources:
      - path: "src/pages"
      - path: "src/routes"
      - path: "src/layouts"

  app-state:
    description: "State management (Redux/Context)"
    group: "frontend"
    output: "m1f/03_state.txt"
    sources:
      - path: "src/store"
      - path: "src/redux"
      - path: "src/context"
      - path: "src/reducers"
      - path: "src/actions"

  # API and services
  app-api:
    description: "API integration layer"
    group: "integration"
    output: "m1f/10_api.txt"
    sources:
      - path: "src/api"
      - path: "src/services"
      - path: "src/graphql"
        include_extensions: [".ts", ".graphql", ".gql"]

  # Configuration and setup
  app-config:
    description: "Build configuration"
    group: "config"
    output: "m1f/20_config.txt"
    sources:
      - path: "."
        includes:
          [
            "package.json",
            "tsconfig.json",
            "webpack.config.js",
            "vite.config.js",
            ".eslintrc.*",
            ".prettierrc.*",
            "babel.config.*",
          ]

  # Tests
  app-tests:
    description: "Test suites"
    group: "testing"
    output: "m1f/30_tests.txt"
    sources:
      - path: "src"
        includes:
          ["**/*.test.ts", "**/*.test.tsx", "**/*.spec.ts", "**/*.spec.tsx"]
      - path: "__tests__"
      - path: "cypress/integration"
        include_extensions: [".js", ".ts"]

  # Documentation
  app-docs:
    description: "Project documentation"
    group: "docs"
    output: "m1f/40_docs.txt"
    sources:
      - path: "."
        includes: ["README.md", "CONTRIBUTING.md", "docs/**/*.md"]
      - path: "src"
        includes: ["**/*.md"]

  # Quick reference bundle for AI assistance
  app-quick-reference:
    description: "Key files for quick AI context"
    group: "reference"
    output: "m1f/00_quick_reference.txt"
    max_file_size: "100KB" # Keep small for quick loading
    sources:
      - path: "."
        includes: ["package.json", "README.md", "src/App.tsx", "src/index.tsx"]
      - path: "src/types" # TypeScript types
```

## Python/Django Project

Configuration for a Django web application with REST API.

```yaml
# Django Project m1f Configuration

global:
  global_excludes:
    # ⚠️ MINIMAL CONFIG - __pycache__, .pytest_cache, etc. are auto-excluded!

    # Python bytecode (not in defaults)
    - "**/*.pyc"
    - "**/*.pyo"
    - "**/*.pyd"

    # Virtual environments (common names)
    - "**/venv/**"
    - "**/.venv/**"
    - "**/env/**"

    # Django specific
    - "**/migrations/**" # Database migrations
    - "**/media/**" # User uploads
    - "**/static/**" # Collected static files
    - "**/staticfiles/**"
    - "**/*.sqlite3" # SQLite database
    - "**/celerybeat-schedule"

  global_settings:
    security_check: "abort" # Strict for web apps
    exclude_paths_file: ".gitignore"

    extensions:
      .py:
        remove_docstrings: false # Keep docstrings for API
        remove_comments: true # Remove inline comments
      .html:
        minify: true # Minify templates
      .env:
        security_check: "abort" # Never include
      .yml:
        security_check: "warn" # Check for secrets

  defaults:
    force_overwrite: true
    max_file_size: "1MB"

bundles:
  # Django apps - one bundle per app
  app-accounts:
    description: "User accounts and authentication"
    group: "apps"
    output: "m1f/apps/01_accounts.txt"
    sources:
      - path: "accounts/"
        excludes: ["migrations/", "__pycache__/", "*.pyc"]

  app-api:
    description: "REST API implementation"
    group: "apps"
    output: "m1f/apps/02_api.txt"
    sources:
      - path: "api/"
        excludes: ["migrations/", "__pycache__/"]
      - path: "."
        includes: ["**/serializers.py", "**/viewsets.py"]

  app-core:
    description: "Core business logic"
    group: "apps"
    output: "m1f/apps/03_core.txt"
    sources:
      - path: "core/"
        excludes: ["migrations/", "__pycache__/"]

  # Project configuration
  django-settings:
    description: "Django settings and configuration"
    group: "config"
    output: "m1f/10_settings.txt"
    sources:
      - path: "config/" # Settings module
      - path: "."
        includes:
          ["manage.py", "requirements*.txt", "Dockerfile", "docker-compose.yml"]

  # Models across all apps
  django-models:
    description: "All database models"
    group: "database"
    output: "m1f/20_models.txt"
    sources:
      - path: "."
        includes: ["**/models.py", "**/models/*.py"]

  # Views and URLs
  django-views:
    description: "Views and URL patterns"
    group: "views"
    output: "m1f/21_views.txt"
    sources:
      - path: "."
        includes: ["**/views.py", "**/views/*.py", "**/urls.py"]

  # Templates
  django-templates:
    description: "HTML templates"
    group: "frontend"
    output: "m1f/30_templates.txt"
    sources:
      - path: "templates/"
      - path: "."
        includes: ["**/templates/**/*.html"]

  # Tests
  django-tests:
    description: "Test suites"
    group: "testing"
    output: "m1f/40_tests.txt"
    sources:
      - path: "."
        includes: ["**/tests.py", "**/tests/*.py", "**/test_*.py"]

  # Management commands
  django-commands:
    description: "Custom management commands"
    group: "utilities"
    output: "m1f/50_commands.txt"
    sources:
      - path: "."
        includes: ["**/management/commands/*.py"]

  # Quick AI reference
  django-quick-ref:
    description: "Essential files for AI context"
    group: "reference"
    output: "m1f/00_quick_reference.txt"
    max_file_size: "100KB"
    sources:
      - path: "."
        includes:
          [
            "README.md",
            "requirements.txt",
            "config/settings/base.py",
            "config/urls.py",
          ]
```

## WordPress Theme

Configuration for a custom WordPress theme with modern build tools.

```yaml
# WordPress Theme m1f Configuration

global:
  global_excludes:
    # ⚠️ MINIMAL CONFIG - node_modules, vendor, build, dist are auto-excluded!

    # WordPress specific (not in defaults)
    - "wp-admin/**" # Core files
    - "wp-includes/**" # Core files
    - "wp-content/uploads/**" # User uploads
    - "wp-content/cache/**" # Cache plugins
    - "wp-content/backup/**" # Backup files
    - "wp-content/upgrade/**" # Updates

    # Sass cache (not in defaults)
    - "**/.sass-cache/**"
    - "**/*.map" # Source maps
    - "**/*.log" # Log files

  global_settings:
    security_check: "warn"
    exclude_paths_file: [".gitignore", ".wpignore"]

    # Use WordPress preset for optimal processing
    preset: "wordpress"

    extensions:
      .php:
        remove_comments: true # Clean PHP comments
      .js:
        minify: true
      .css:
        minify: true
      .scss:
        minify: true

  defaults:
    force_overwrite: true
    max_file_size: "500KB"

bundles:
  # Theme core files
  theme-core:
    description: "Theme core functionality"
    group: "theme"
    output: "m1f/01_theme_core.txt"
    sources:
      - path: "."
        includes: [
            "style.css", # Theme header
            "functions.php",
            "index.php",
            "header.php",
            "footer.php",
            "sidebar.php",
            "searchform.php",
            "404.php",
          ]

  # Template files
  theme-templates:
    description: "Page and post templates"
    group: "theme"
    output: "m1f/02_templates.txt"
    sources:
      - path: "."
        includes:
          [
            "single*.php",
            "page*.php",
            "archive*.php",
            "category*.php",
            "tag*.php",
            "taxonomy*.php",
            "front-page.php",
            "home.php",
          ]
      - path: "template-parts/"
      - path: "templates/"

  # Theme includes/components
  theme-includes:
    description: "Theme includes and components"
    group: "theme"
    output: "m1f/03_includes.txt"
    sources:
      - path: "inc/"
      - path: "includes/"
      - path: "lib/"
      - path: "components/"

  # Custom post types and taxonomies
  theme-cpt:
    description: "Custom post types and taxonomies"
    group: "functionality"
    output: "m1f/10_custom_types.txt"
    sources:
      - path: "."
        includes: ["**/post-types/*.php", "**/taxonomies/*.php"]
      - path: "inc/"
        includes: ["*cpt*.php", "*custom-post*.php", "*taxonom*.php"]

  # ACF field groups
  theme-acf:
    description: "Advanced Custom Fields configuration"
    group: "functionality"
    output: "m1f/11_acf_fields.txt"
    sources:
      - path: "acf-json/" # ACF JSON exports
      - path: "."
        includes: ["**/acf-fields/*.php", "**/acf/*.php"]

  # JavaScript and build files
  theme-assets:
    description: "Theme assets and build configuration"
    group: "assets"
    output: "m1f/20_assets.txt"
    sources:
      - path: "src/"
        include_extensions: [".js", ".jsx", ".scss", ".css"]
      - path: "assets/src/"
      - path: "."
        includes:
          [
            "webpack.config.js",
            "gulpfile.js",
            "package.json",
            ".babelrc",
            "postcss.config.js",
          ]

  # WooCommerce integration
  theme-woocommerce:
    description: "WooCommerce customizations"
    group: "integrations"
    output: "m1f/30_woocommerce.txt"
    sources:
      - path: "woocommerce/"
      - path: "inc/"
        includes: ["*woocommerce*.php", "*wc-*.php"]

  # Documentation and setup
  theme-docs:
    description: "Theme documentation"
    group: "docs"
    output: "m1f/40_documentation.txt"
    sources:
      - path: "."
        includes: ["README.md", "CHANGELOG.md", "style.css"]
      - path: "docs/"

  # Quick reference for AI
  theme-quick-ref:
    description: "Essential theme files for AI context"
    group: "reference"
    output: "m1f/00_quick_reference.txt"
    max_file_size: "100KB"
    sources:
      - path: "."
        includes: ["style.css", "functions.php", "README.md", "package.json"]
```

## Documentation Site

Configuration for a documentation website using Markdown and static site
generators.

```yaml
# Documentation Site m1f Configuration

global:
  global_excludes:
    # Build outputs
    - "_site/**"
    - "public/**"
    - "dist/**"
    - ".cache/**"

    # Development
    - "**/node_modules/**"
    - "**/.sass-cache/**"
    - "**/tmp/**"

  global_settings:
    security_check: "skip" # Docs are public
    exclude_paths_file: ".gitignore"

    # Optimize for documentation
    extensions:
      .md:
        preserve_formatting: true # Keep Markdown formatting
        max_file_size: "2MB" # Allow larger docs
      .mdx:
        preserve_formatting: true
      .yml:
        minify: false # Keep YAML readable
      .json:
        minify: true

  defaults:
    force_overwrite: true
    max_file_size: "1MB"
    include_empty_dirs: false

bundles:
  # Documentation by section
  docs-getting-started:
    description: "Getting started guides"
    group: "content"
    output: "m1f/01_getting_started.txt"
    sources:
      - path: "docs/getting-started/"
      - path: "content/getting-started/"
      - path: "src/pages/docs/getting-started/"

  docs-tutorials:
    description: "Tutorial content"
    group: "content"
    output: "m1f/02_tutorials.txt"
    sources:
      - path: "docs/tutorials/"
      - path: "content/tutorials/"
      - path: "examples/"
        include_extensions: [".md", ".mdx"]

  docs-api-reference:
    description: "API documentation"
    group: "content"
    output: "m1f/03_api_reference.txt"
    sources:
      - path: "docs/api/"
      - path: "content/api/"
      - path: "reference/"

  docs-guides:
    description: "How-to guides"
    group: "content"
    output: "m1f/04_guides.txt"
    sources:
      - path: "docs/guides/"
      - path: "content/guides/"
      - path: "content/how-to/"

  # Site configuration and theming
  site-config:
    description: "Site configuration and theme"
    group: "config"
    output: "m1f/10_site_config.txt"
    sources:
      - path: "."
        includes: [
            "config*.yml",
            "config*.yaml",
            "config*.toml",
            "config*.json",
            "_config.yml", # Jekyll
            "docusaurus.config.js", # Docusaurus
            "gatsby-config.js", # Gatsby
            "mkdocs.yml", # MkDocs
            ".vuepress/config.js", # VuePress
          ]
      - path: "data/" # Data files
        include_extensions: [".yml", ".yaml", ".json"]

  # Theme and layouts
  site-theme:
    description: "Theme and layout files"
    group: "theme"
    output: "m1f/11_theme.txt"
    sources:
      - path: "_layouts/" # Jekyll
      - path: "_includes/"
      - path: "layouts/" # Hugo
      - path: "themes/"
      - path: "src/theme/"
      - path: "src/components/"
        include_extensions: [".jsx", ".tsx", ".vue", ".css", ".scss"]

  # Code examples
  docs-examples:
    description: "Code examples and snippets"
    group: "examples"
    output: "m1f/20_examples.txt"
    sources:
      - path: "examples/"
      - path: "snippets/"
      - path: "code-examples/"
      - path: "."
        includes: ["**/*.example.*", "**/examples/**"]

  # Search index and data
  site-search:
    description: "Search configuration and index"
    group: "search"
    output: "m1f/30_search.txt"
    sources:
      - path: "."
        includes: ["**/search-index.json", "**/algolia*.js", "**/lunr*.js"]
      - path: "search/"

  # Complete documentation bundle
  docs-complete:
    description: "All documentation content"
    group: "complete"
    output: "m1f/99_all_docs.txt"
    sources:
      - path: "."
        include_extensions: [".md", ".mdx"]
        excludes: ["node_modules/", "_site/", "public/"]

  # Quick reference
  docs-quick-ref:
    description: "Key documentation for AI context"
    group: "reference"
    output: "m1f/00_quick_reference.txt"
    max_file_size: "100KB"
    sources:
      - path: "."
        includes: ["README.md", "index.md", "docs/index.md"]
      - path: "docs/"
        includes: ["quick-start.md", "overview.md", "introduction.md"]
```

## Mixed Language Project

Configuration for a project with multiple programming languages (e.g., Python
backend, React frontend, Go microservices).

```yaml
# Mixed Language Project m1f Configuration

global:
  global_excludes:
    # Language-specific build artifacts
    - "**/node_modules/**" # JavaScript
    - "**/__pycache__/**" # Python
    - "**/venv/**"
    - "**/vendor/**" # Go/PHP
    - "**/target/**" # Rust/Java
    - "**/bin/**" # Binaries
    - "**/obj/**" # .NET

    # Common excludes
    - "**/dist/**"
    - "**/build/**"
    - "**/*.log"
    - "**/.cache/**"
    - "**/tmp/**"

  global_settings:
    security_check: "warn"
    exclude_paths_file: [".gitignore", ".dockerignore"]

    # Language-specific processing
    extensions:
      # Frontend
      .js:
        minify: true
        remove_comments: true
      .ts:
        minify: true
        remove_comments: true
      .jsx:
        minify: true
      .tsx:
        minify: true

      # Backend
      .py:
        remove_comments: true
        remove_docstrings: false
      .go:
        remove_comments: true
      .java:
        remove_comments: true
      .rs:
        remove_comments: true

      # Config files
      .env:
        security_check: "abort"
      .yml:
        security_check: "warn"

  defaults:
    force_overwrite: true
    max_file_size: "1MB"

bundles:
  # Frontend - React/TypeScript
  frontend-components:
    description: "Frontend React components"
    group: "frontend"
    output: "m1f/frontend/01_components.txt"
    sources:
      - path: "frontend/src/components/"
      - path: "frontend/src/hooks/"
      - path: "frontend/src/utils/"

  frontend-config:
    description: "Frontend configuration"
    group: "frontend"
    output: "m1f/frontend/02_config.txt"
    sources:
      - path: "frontend/"
        includes:
          ["package.json", "tsconfig.json", "webpack.config.js", ".eslintrc.*"]

  # Backend - Python/FastAPI
  backend-api:
    description: "Python API endpoints"
    group: "backend"
    output: "m1f/backend/01_api.txt"
    sources:
      - path: "backend/app/api/"
      - path: "backend/app/routers/"

  backend-models:
    description: "Database models and schemas"
    group: "backend"
    output: "m1f/backend/02_models.txt"
    sources:
      - path: "backend/app/models/"
      - path: "backend/app/schemas/"
      - path: "backend/app/database/"

  backend-services:
    description: "Business logic services"
    group: "backend"
    output: "m1f/backend/03_services.txt"
    sources:
      - path: "backend/app/services/"
      - path: "backend/app/core/"

  # Microservices - Go
  service-auth:
    description: "Authentication service (Go)"
    group: "microservices"
    output: "m1f/services/01_auth.txt"
    sources:
      - path: "services/auth/"
        include_extensions: [".go"]
        excludes: ["vendor/", "*_test.go"]

  service-notifications:
    description: "Notification service (Go)"
    group: "microservices"
    output: "m1f/services/02_notifications.txt"
    sources:
      - path: "services/notifications/"
        include_extensions: [".go"]
        excludes: ["vendor/", "*_test.go"]

  # Shared libraries
  shared-proto:
    description: "Protocol Buffers definitions"
    group: "shared"
    output: "m1f/shared/01_protobuf.txt"
    sources:
      - path: "proto/"
        include_extensions: [".proto"]

  shared-utils:
    description: "Shared utilities across languages"
    group: "shared"
    output: "m1f/shared/02_utils.txt"
    sources:
      - path: "shared/"
      - path: "common/"

  # Infrastructure as Code
  infrastructure:
    description: "Infrastructure configuration"
    group: "infrastructure"
    output: "m1f/infra/01_infrastructure.txt"
    sources:
      - path: "infrastructure/"
        include_extensions: [".tf", ".yml", ".yaml"]
      - path: "."
        includes: ["docker-compose*.yml", "Dockerfile*", ".dockerignore"]

  # Testing
  tests-frontend:
    description: "Frontend tests"
    group: "testing"
    output: "m1f/tests/01_frontend.txt"
    sources:
      - path: "frontend/"
        includes: ["**/*.test.ts", "**/*.test.tsx", "**/*.spec.ts"]

  tests-backend:
    description: "Backend tests"
    group: "testing"
    output: "m1f/tests/02_backend.txt"
    sources:
      - path: "backend/"
        includes: ["**/test_*.py", "**/*_test.py"]

  tests-integration:
    description: "Integration tests"
    group: "testing"
    output: "m1f/tests/03_integration.txt"
    sources:
      - path: "tests/integration/"
      - path: "e2e/"

  # Documentation
  project-docs:
    description: "Project documentation"
    group: "docs"
    output: "m1f/docs/01_documentation.txt"
    sources:
      - path: "."
        includes: ["README.md", "CONTRIBUTING.md", "ARCHITECTURE.md"]
      - path: "docs/"
      - path: "frontend/README.md"
      - path: "backend/README.md"
      - path: "services/*/README.md"

  # Quick reference bundle
  project-overview:
    description: "Project overview for AI context"
    group: "reference"
    output: "m1f/00_overview.txt"
    max_file_size: "100KB"
    sources:
      - path: "."
        includes:
          [
            "README.md",
            "docker-compose.yml",
            "frontend/package.json",
            "backend/requirements.txt",
            "services/auth/go.mod",
          ]
```

## Microservices Architecture

Configuration for a microservices-based application with multiple services.

```yaml
# Microservices Architecture m1f Configuration

global:
  global_excludes:
    # Common excludes across all services
    - "**/node_modules/**"
    - "**/vendor/**"
    - "**/target/**"
    - "**/build/**"
    - "**/dist/**"
    - "**/.cache/**"
    - "**/logs/**"
    - "**/*.log"

  global_settings:
    security_check: "abort" # Strict for microservices
    exclude_paths_file: [".gitignore", ".dockerignore"]

    # Process by file type
    extensions:
      .env:
        security_check: "abort"
      .yml:
        security_check: "warn"
      .json:
        minify: true
      .proto:
        preserve_formatting: true # Keep protobuf readable

  defaults:
    force_overwrite: true
    max_file_size: "500KB" # Smaller for services

  # Watch for changes in all services
  watcher:
    enabled: true
    debounce_seconds: 3
    ignored_paths:
      - "**/node_modules"
      - "**/vendor"
      - "**/logs"

bundles:
  # API Gateway
  gateway-main:
    description: "API Gateway service"
    group: "gateway"
    output: "m1f/gateway/01_main.txt"
    sources:
      - path: "services/gateway/"
        excludes: ["node_modules/", "dist/", "coverage/"]

  # Individual microservices
  service-users:
    description: "User management service"
    group: "services"
    output: "m1f/services/01_users.txt"
    sources:
      - path: "services/users/"
        excludes: ["vendor/", "bin/", "logs/"]

  service-orders:
    description: "Order processing service"
    group: "services"
    output: "m1f/services/02_orders.txt"
    sources:
      - path: "services/orders/"
        excludes: ["vendor/", "bin/", "logs/"]

  service-inventory:
    description: "Inventory management service"
    group: "services"
    output: "m1f/services/03_inventory.txt"
    sources:
      - path: "services/inventory/"
        excludes: ["vendor/", "bin/", "logs/"]

  service-payments:
    description: "Payment processing service"
    group: "services"
    output: "m1f/services/04_payments.txt"
    sources:
      - path: "services/payments/"
        excludes: ["vendor/", "bin/", "logs/"]

  # Shared configurations and contracts
  shared-contracts:
    description: "Service contracts and interfaces"
    group: "shared"
    output: "m1f/shared/01_contracts.txt"
    sources:
      - path: "contracts/"
        include_extensions: [".proto", ".graphql", ".openapi.yml"]
      - path: "schemas/"

  shared-libs:
    description: "Shared libraries and utilities"
    group: "shared"
    output: "m1f/shared/02_libraries.txt"
    sources:
      - path: "libs/"
      - path: "packages/"
      - path: "common/"

  # Infrastructure and deployment
  k8s-configs:
    description: "Kubernetes configurations"
    group: "infrastructure"
    output: "m1f/k8s/01_configs.txt"
    sources:
      - path: "k8s/"
        include_extensions: [".yml", ".yaml"]
      - path: "helm/"

  docker-configs:
    description: "Docker configurations"
    group: "infrastructure"
    output: "m1f/docker/01_configs.txt"
    sources:
      - path: "."
        includes: ["**/Dockerfile*", "**/.dockerignore", "docker-compose*.yml"]

  # Monitoring and observability
  monitoring:
    description: "Monitoring and alerting configs"
    group: "observability"
    output: "m1f/monitoring/01_configs.txt"
    sources:
      - path: "monitoring/"
      - path: "grafana/"
      - path: "prometheus/"

  # CI/CD pipelines
  cicd:
    description: "CI/CD pipeline definitions"
    group: "devops"
    output: "m1f/cicd/01_pipelines.txt"
    sources:
      - path: ".github/workflows/"
      - path: ".gitlab-ci.yml"
      - path: "jenkins/"
      - path: ".circleci/"

  # Service mesh configuration
  service-mesh:
    description: "Service mesh configurations"
    group: "infrastructure"
    output: "m1f/mesh/01_configs.txt"
    sources:
      - path: "istio/"
      - path: "linkerd/"
      - path: "consul/"

  # Quick overview for new developers
  architecture-overview:
    description: "Architecture overview"
    group: "reference"
    output: "m1f/00_architecture.txt"
    max_file_size: "150KB"
    sources:
      - path: "."
        includes:
          [
            "README.md",
            "ARCHITECTURE.md",
            "docker-compose.yml",
            "services/*/README.md",
          ]
```

## Mobile App Project

Configuration for a React Native or Flutter mobile application.

```yaml
# Mobile App m1f Configuration

global:
  global_excludes:
    # Platform-specific builds
    - "**/ios/build/**"
    - "**/ios/Pods/**"
    - "**/android/build/**"
    - "**/android/.gradle/**"
    - "**/android/app/build/**"

    # React Native / Flutter
    - "**/node_modules/**"
    - "**/.dart_tool/**"
    - "**/pubspec.lock"
    - "**/package-lock.json"
    - "**/yarn.lock"

    # IDE and temp files
    - "**/.idea/**"
    - "**/.vscode/**"
    - "**/tmp/**"
    - "**/*.log"

  global_settings:
    security_check: "warn"
    exclude_paths_file: [".gitignore", ".npmignore"]

    extensions:
      # Mobile-specific
      .swift:
        remove_comments: true
      .kt:
        remove_comments: true
      .dart:
        remove_comments: true
      .java:
        remove_comments: true
      # JavaScript/TypeScript
      .js:
        minify: true
      .jsx:
        minify: true
      .ts:
        minify: true
      .tsx:
        minify: true

  defaults:
    force_overwrite: true
    max_file_size: "500KB"

bundles:
  # Core application code
  app-screens:
    description: "App screens and navigation"
    group: "app"
    output: "m1f/app/01_screens.txt"
    sources:
      - path: "src/screens/" # React Native
      - path: "lib/screens/" # Flutter
      - path: "src/pages/"
      - path: "src/navigation/"

  app-components:
    description: "Reusable UI components"
    group: "app"
    output: "m1f/app/02_components.txt"
    sources:
      - path: "src/components/"
      - path: "lib/widgets/" # Flutter
      - path: "src/ui/"

  app-state:
    description: "State management"
    group: "app"
    output: "m1f/app/03_state.txt"
    sources:
      - path: "src/store/" # Redux/MobX
      - path: "src/context/" # React Context
      - path: "lib/providers/" # Flutter Provider
      - path: "lib/blocs/" # Flutter BLoC

  app-services:
    description: "API and service layer"
    group: "app"
    output: "m1f/app/04_services.txt"
    sources:
      - path: "src/services/"
      - path: "src/api/"
      - path: "lib/services/"
      - path: "src/utils/"

  # Platform-specific code
  platform-ios:
    description: "iOS specific code"
    group: "platform"
    output: "m1f/platform/01_ios.txt"
    sources:
      - path: "ios/"
        include_extensions: [".swift", ".m", ".h", ".plist"]
        excludes: ["Pods/", "build/"]

  platform-android:
    description: "Android specific code"
    group: "platform"
    output: "m1f/platform/02_android.txt"
    sources:
      - path: "android/"
        include_extensions: [".java", ".kt", ".xml", ".gradle"]
        excludes: ["build/", ".gradle/"]

  # Assets and resources
  app-assets:
    description: "App assets and resources"
    group: "assets"
    output: "m1f/assets/01_resources.txt"
    sources:
      - path: "assets/"
        includes: ["**/*.json", "**/*.xml", "**/strings.xml"]
      - path: "src/assets/"
      - path: "resources/"

  # Configuration
  app-config:
    description: "App configuration"
    group: "config"
    output: "m1f/config/01_configuration.txt"
    sources:
      - path: "."
        includes: [
            "package.json",
            "app.json", # React Native
            "metro.config.js", # React Native
            "babel.config.js",
            "tsconfig.json",
            "pubspec.yaml", # Flutter
            ".env.example",
          ]

  # Tests
  app-tests:
    description: "Test suites"
    group: "testing"
    output: "m1f/tests/01_tests.txt"
    sources:
      - path: "__tests__/"
      - path: "test/"
      - path: "src/"
        includes: ["**/*.test.js", "**/*.test.ts", "**/*.spec.js"]

  # Native modules
  native-modules:
    description: "Native modules and bridges"
    group: "native"
    output: "m1f/native/01_modules.txt"
    sources:
      - path: "src/native/"
      - path: "native-modules/"
      - path: "."
        includes: ["**/RN*.swift", "**/RN*.java", "**/RN*.kt"]

  # Quick reference
  app-quick-ref:
    description: "Key files for AI context"
    group: "reference"
    output: "m1f/00_quick_reference.txt"
    max_file_size: "100KB"
    sources:
      - path: "."
        includes:
          ["README.md", "package.json", "app.json", "src/App.js", "index.js"]
```

## Best Practices

When creating your `.m1f.config.yml`:

1. **Group Related Files**: Create focused bundles that group related
   functionality
2. **Use Meaningful Names**: Choose descriptive bundle names that indicate
   content
3. **Set Size Limits**: Keep bundles under 100KB for optimal AI performance
4. **Security First**: Always configure proper security checks for sensitive
   files
5. **Leverage Presets**: Use built-in presets for common project types
6. **Exclude Wisely**: Don't bundle generated files, dependencies, or build
   artifacts
7. **Document Purpose**: Add descriptions to help others understand each bundle
8. **Test Configuration**: Run `m1f-update` and check bundle sizes with
   `m1f-token-counter`

## Common Patterns

### Pattern 1: Separate by Layer

```yaml
bundles:
  frontend: # UI components
  backend: # Server logic
  database: # Models and migrations
  api: # API endpoints
  tests: # Test suites
```

### Pattern 2: Separate by Feature

```yaml
bundles:
  feature-auth: # Authentication
  feature-payment: # Payment processing
  feature-search: # Search functionality
  feature-admin: # Admin panel
```

### Pattern 3: Separate by Purpose

```yaml
bundles:
  quick-reference: # Essential files for context
  documentation: # All docs
  source-code: # Implementation
  configuration: # Config files
  deployment: # Deploy scripts
```

### Pattern 4: Progressive Detail

```yaml
bundles:
  overview: # High-level summary (10KB)
  core-logic: # Main functionality (50KB)
  full-source: # Complete code (100KB)
  everything: # All files (500KB)
```

Remember: The best configuration depends on your specific project needs and how
you plan to use the bundles with AI assistants.

======= docs/01_m1f/26_default_excludes_guide.md ======
# m1f Default Excludes Guide

This guide explains the files and directories that m1f excludes by default,
helping you write minimal and efficient `.m1f.config.yml` configurations.

## 🚨 CRITICAL: Correct Bundle Format

**ALWAYS use the `sources:` array format, NOT `source_directory:`!**

```yaml
# ✅ CORRECT FORMAT:
bundles:
  - name: my-bundle
    sources:
      - "./src"
    output_file: "m1f/my-bundle.txt"
    separator_style: Standard  # Or omit - Standard is default

# ❌ WRONG FORMAT (will cause errors):
bundles:
  my-bundle:
    source_directory: "./src"  # This format causes "ERROR: At least one of -s/--source-directory..."
    output_file: "m1f/my-bundle.txt"
    separator_style: Detailed  # Don't use for AI bundles!
```

**ALWAYS test with `m1f-update` immediately after creating/editing
.m1f.config.yml!**

## Understanding Default Excludes

**IMPORTANT**: m1f automatically excludes many common directories and files. You
DON'T need to repeat these in your configuration - only add project-specific
exclusions!

## Default Excluded Directories

The following directories are ALWAYS excluded unless you explicitly use
`--no-default-excludes`:

```yaml
# These are excluded automatically - no need to add them to your config!
- vendor/ # Composer dependencies (PHP)
- node_modules/ # NPM dependencies (JavaScript)
- build/ # Common build output directory
- dist/ # Distribution/compiled files
- cache/ # Cache directories
- .git/ # Git repository data
- .svn/ # Subversion data
- .hg/ # Mercurial data
- __pycache__/ # Python bytecode cache
- .pytest_cache/ # Pytest cache
- .mypy_cache/ # MyPy type checker cache
- .tox/ # Tox testing cache
- .coverage/ # Coverage.py data
- .eggs/ # Python eggs
- htmlcov/ # HTML coverage reports
- .idea/ # IntelliJ IDEA settings
- .vscode/ # Visual Studio Code settings
```

## Default Excluded Files

These specific files are also excluded automatically:

```yaml
# These files are excluded by default:
- LICENSE # License files (usually not needed in bundles)
- package-lock.json # NPM lock file
- composer.lock # Composer lock file
- poetry.lock # Poetry lock file
- Pipfile.lock # Pipenv lock file
- yarn.lock # Yarn lock file
```

## Writing Minimal Configurations

### ❌ BAD - Overly Verbose Configuration

```yaml
# DON'T DO THIS - repeating default excludes unnecessarily!
global:
  global_excludes:
    - "**/node_modules/**" # Already excluded by default!
    - "**/vendor/**" # Already excluded by default!
    - "**/__pycache__/**" # Already excluded by default!
    - "**/build/**" # Already excluded by default!
    - "**/dist/**" # Already excluded by default!
    - "**/.git/**" # Already excluded by default!
    - "**/cache/**" # Already excluded by default!
    - "**/.vscode/**" # Already excluded by default!
    - "**/*.pyc" # Project-specific - OK
    - "**/logs/**" # Project-specific - OK
```

### ✅ GOOD - Minimal Configuration

```yaml
# Only add project-specific exclusions!
global:
  global_excludes:
    - "**/*.pyc" # Python bytecode
    - "**/logs/**" # Your project's log files
    - "**/tmp/**" # Your temporary directories
    - "/m1f/**" # Output directory
    - "**/secrets/**" # Sensitive data
```

## Common Patterns by Project Type

### Python Projects

```yaml
# Only add what's NOT in default excludes
global:
  global_excludes:
    - "**/*.pyc" # Bytecode files
    - "**/*.pyo" # Optimized bytecode
    - "**/*.pyd" # Python DLL files
    - "**/venv/**" # Virtual environments
    - "**/.venv/**" # Alternative venv naming
    - "**/env/**" # Another venv naming
```

### Node.js Projects

```yaml
# node_modules is already excluded!
global:
  global_excludes:
    - "**/.next/**" # Next.js build cache
    - "**/.nuxt/**" # Nuxt.js build cache
    - "**/coverage/**" # Test coverage reports
    - "**/*.log" # Log files
```

### WordPress Projects

```yaml
# Only WordPress-specific excludes needed
global:
  global_excludes:
    - "**/wp-content/uploads/**" # User uploads
    - "**/wp-content/cache/**" # Cache plugins
    - "**/wp-content/backup/**" # Backup files
    - "wp-admin/**" # Core files
    - "wp-includes/**" # Core files
```

## Using .gitignore as Exclude File

Instead of manually listing excludes, use your existing .gitignore:

```yaml
global:
  global_settings:
    # This automatically uses your .gitignore patterns!
    exclude_paths_file: ".gitignore"
```

Or use multiple exclude files:

```yaml
global:
  global_settings:
    exclude_paths_file:
      - ".gitignore" # Version control ignores
      - ".m1fignore" # m1f-specific ignores
```

## Checking What's Excluded

To see all excluded paths (including defaults), use verbose mode:

```bash
m1f -s . -o test.txt --verbose
```

This will show:

- Default excluded directories
- Patterns from your config
- Files matched by your exclude patterns

## Disabling Default Excludes

If you need to include normally excluded directories:

```bash
# Include everything, even node_modules, .git, etc.
m1f -s . -o complete.txt --no-default-excludes
```

⚠️ **WARNING**: This can create HUGE bundles and include sensitive data!

## Best Practices

1. **Start Simple**: Begin with no excludes and add only as needed
2. **Use .gitignore**: Leverage existing ignore patterns
3. **Test First**: Run with `--verbose` to see what's excluded
4. **Document Why**: Add comments explaining non-obvious excludes

```yaml
global:
  global_excludes:
    # Project-specific build artifacts
    - "**/generated/**" # Auto-generated code
    - "**/reports/**" # Test/coverage reports

    # Large data files
    - "**/*.sqlite" # Database files
    - "**/*.csv" # Data exports

    # Sensitive information
    - "**/.env*" # Environment files
    - "**/secrets/**" # API keys, certs
```

## Quick Reference

### Already Excluded (Don't Repeat)

- `node_modules/`, `vendor/`, `build/`, `dist/`
- `.git/`, `.svn/`, `.hg/`
- `__pycache__/`, `.pytest_cache/`, `.mypy_cache/`
- `.idea/`, `.vscode/`
- Lock files: `*.lock`, `package-lock.json`

### Commonly Added (Project-Specific)

- Virtual envs: `venv/`, `.venv/`, `env/`
- Logs: `*.log`, `logs/`
- Temp files: `tmp/`, `temp/`, `*.tmp`
- Database: `*.sqlite`, `*.db`
- Environment: `.env`, `.env.*`
- Output: `/m1f/` (your bundle directory)

## Summary

Keep your `.m1f.config.yml` files clean and minimal by:

1. NOT repeating default excludes
2. Only adding project-specific patterns
3. Using `.gitignore` when possible
4. Documenting non-obvious exclusions

This makes your configurations easier to read, maintain, and share with others!

======= docs/01_m1f/30_claude_workflows.md ======
# Claude + m1f: Your AI-Powered Project Assistant 🤖

Ever wished you had an AI buddy who actually understands your project structure?
That's what happens when you combine Claude with m1f. This guide shows you how
to turn Claude into your personal project assistant who knows exactly how to
bundle, organize, and process your code.

## The Power of m1f v3.2 + Claude ✨

With m1f v3.2's enhanced features, Claude can help you:

- Configure comprehensive security scanning
- Set up parallel processing for faster bundling
- Create sophisticated preset configurations
- Manage content deduplication strategies
- Handle complex encoding scenarios

## Getting Started with Claude

### Step 1: Give Claude the Power

First, let's get Claude up to speed on what m1f can do:

```bash
cd /your/awesome/project
m1f-init  # Quick setup: links docs, analyzes project, creates bundles
```

Boom! 💥 This command:

- Creates m1f/m1f.txt symlink to the complete documentation
- Analyzes your project structure
- Generates initial bundles (complete and docs)
- Creates a basic .m1f.config.yml

For advanced setup with topic-specific bundles (Linux/macOS only):

```bash
# Interactive mode - will prompt for project description and priorities
m1f-claude --setup

# Or provide project info via command line
m1f-claude --setup \
  --project-description "E-commerce platform with React frontend and Django backend" \
  --project-priorities "performance, security, maintainability"
```

### Step 2: Start the Conversation

Here's where it gets fun. Just tell Claude what you need:

```
Hey Claude, I need help setting up m1f for my project.
Check out @m1f/m1f.txt to see what m1f can do.

My project is a Python web app with:
- Backend API in /api
- Frontend React code in /frontend
- Tests scattered around
- Some docs in /docs

Can you create a .m1f.config.yml that bundles these intelligently?
```

Claude will read the docs and create a perfect config for your project
structure. No more guessing at parameters!

## Real-World Workflows That Actually Work 🚀

### The "Security-First Bundle" Workflow

```
Claude, I need to create bundles for external review.
Using m1f v3.2's security features:

1. Create a config that scans for secrets (security_check: error)
2. Exclude any files with sensitive data
3. Set up proper path validation
4. Ensure no internal IPs or credentials leak through

Focus on making it safe to share with contractors.
```

### The "Performance Optimization" Workflow

```
Claude, my project has 5000+ files and bundling is slow.
Help me optimize using m1f v3.2's features:

1. Leverage parallel processing (enabled by default)
2. Set up smart file size limits
3. Use content deduplication to reduce bundle size
4. Create targeted bundles instead of one massive file

The goal is sub-10 second bundle generation.
```

### The "Multi-Environment Setup" Workflow

```
Claude, I need different bundles for dev/staging/prod.
Using m1f v3.2's preset system:

1. Create environment-specific presets
2. Use enabled flag for environment control
3. Set different security levels per environment
4. Configure appropriate output formats

Make it so I can just run: m1f --preset env.yml --preset-group production
```

## Using m1f-claude: Advanced Project Setup 🧠

For advanced project-specific configuration, use m1f-claude (Linux/macOS only):

```bash
# First, run the quick setup
m1f-init

# Then for advanced configuration with Claude's help
m1f-claude --setup
```

### What Makes m1f-claude Special?

When you use `m1f-claude --setup`, it:

- Analyzes your project in detail with Claude's assistance
- Creates topic-specific bundles (components, API, tests, etc.)
- Optimizes configuration for your specific project type
- Provides intelligent suggestions based on your codebase

**Note**: m1f-claude requires Claude Code SDK and is not available on Windows.
Windows users can manually customize their .m1f.config.yml after running
m1f-init.

### Permission System

Control how Claude handles file operations with the `--permission-mode` flag:

```bash
# Auto-accept all file edits
m1f-claude --permission-mode acceptEdits "Help me refactor this code"

# Plan mode - Claude describes changes without executing
m1f-claude --permission-mode plan "What changes would you make?"

# Bypass all permission checks (use with caution)
m1f-claude --permission-mode bypassPermissions "Fix all issues"

# Default mode - prompts for each operation
m1f-claude --permission-mode default "Update the config"
```

### Output Formats

Choose how Claude's responses are formatted:

```bash
# Plain text output (default)
m1f-claude --output-format text "Explain this code"

# JSON output for programmatic processing
m1f-claude --output-format json "Analyze project structure"

# Streaming JSON for real-time processing
m1f-claude --output-format stream-json "Refactor the codebase"
```

### MCP (Model Context Protocol) Support

Extend Claude's capabilities with MCP servers:

```bash
# Load MCP configuration from file
m1f-claude --mcp-config ./mcp-servers.json "Use the database tools"

# Example MCP configuration file:
cat > mcp-servers.json << 'EOF'
{
  "servers": {
    "postgres-tools": {
      "command": "npx",
      "args": ["@modelcontextprotocol/postgres-server"],
      "env": {
        "DATABASE_URL": "postgresql://user:pass@localhost/mydb"
      }
    }
  }
}
EOF
```

### Tool Control

Fine-grained control over which tools Claude can use:

```bash
# Allow specific tools only
m1f-claude --allowed-tools "Read,Write,Edit" "Update the documentation"

# Disallow dangerous tools
m1f-claude --disallowed-tools "Bash,System" "Review the code"

# Combine both for precise control
m1f-claude --allowed-tools "Read,Edit,MultiEdit,Write,Glob,Grep" \
           --disallowed-tools "Bash" \
           "Refactor without running commands"
```

### System Prompt Enhancement

Append custom instructions to Claude's system prompt:

```bash
# Add specific instructions
m1f-claude --append-system-prompt "Focus on security best practices" \
           "Review this authentication code"

# Multiple instructions
m1f-claude --append-system-prompt "Be concise. Explain your reasoning. Focus on performance." \
           "Optimize this algorithm"
```

### Working Directory Control

Set a specific working directory for Claude:

```bash
# Work in a different directory than current
m1f-claude --cwd /path/to/project "List all Python files"

# Useful for monorepos
m1f-claude --cwd ./packages/frontend "Set up the React components"
```

### Enhanced Message Handling

m1f-claude handles all message types from Claude:

- **System Messages**: Session initialization, permission prompts, notifications
- **User Messages**: Tracked for conversation context
- **Assistant Messages**: Handles both flat and nested content structures
- **Tool Messages**: Tool use events with parameters, results with smart
  truncation
- **Result Messages**: Success/error/cancellation states, cost tracking,
  metadata

### Usage Examples

#### Basic Setup with Enhanced Features

```bash
# Initialize with specific permissions and tools
m1f-claude --setup \
  --permission-mode acceptEdits \
  --allowed-tools "Read,Write,Edit,MultiEdit,Glob,Grep" \
  --project-description "E-commerce platform using Django" \
  --project-priorities "Security, scalability, maintainability"
```

#### Interactive Mode with MCP

```bash
# Start interactive mode with database tools
m1f-claude -i \
  --mcp-config ./database-tools.json \
  --append-system-prompt "You have access to PostgreSQL tools"
```

#### Automated Refactoring

```bash
# Refactor with auto-accept and specific output format
m1f-claude --permission-mode acceptEdits \
  --output-format json \
  --max-turns 5 \
  "Refactor all Python files to use type hints"
```

#### Safe Code Review

```bash
# Review without write permissions
m1f-claude --allowed-tools "Read,Grep,Glob" \
  --permission-mode default \
  "Review the codebase for security issues"
```

### 💡 Important: Claude Code Subscription Recommended

**We strongly recommend using Claude Code with a subscription plan** when using
m1f-claude for project setup. Setting up m1f with Claude's assistance can
involve:

- Multiple file reads to analyze your project structure
- Creating and editing configuration files
- Running various commands to test configurations
- Iterative refinement of bundles

Since we don't know exactly how many tokens this process will consume, a
subscription ensures you won't run into usage limits during critical setup
phases. The investment pays off quickly through the time saved in properly
configuring your project.

## Working with Claude Code

If you're using Claude Code (claude.ai/code), you can leverage its file reading
capabilities:

```
# In Claude Code, you can directly reference files
Claude, please read my current .m1f.config.yml and suggest improvements
based on m1f v3.2 features like:
- Better security scanning
- Optimized performance settings
- Advanced preset configurations
```

## Advanced v3.2 Patterns 🎯

### The "Complete Configuration via Presets"

With v3.2, you can control everything through presets:

```yaml
# production.m1f-presets.yml
production:
  description: "Production-ready bundles with full security"

  global_settings:
    # Input/Output
    source_directory: "./src"
    output_file: "dist/prod-bundle.txt"
    input_include_files: ["README.md", "LICENSE"]

    # Security (v3.2)
    security_check: "error" # Stop on any secrets

    # Performance (v3.2)
    enable_content_deduplication: true
    prefer_utf8_for_text_files: true

    # Output control
    add_timestamp: true
    create_archive: true
    archive_type: "tar.gz"
    force: true
    minimal_output: true
    quiet: true

    # Processing
    separator_style: "MachineReadable"
    encoding: "utf-8"
    max_file_size: "1MB"

    # Exclusions
    exclude_patterns:
      - "**/*.test.js"
      - "**/*.spec.ts"
      - "**/node_modules/**"
      - "**/.env*"

  presets:
    minify_production:
      patterns: ["dist/**/*"]
      extensions: [".js", ".css"]
      actions: ["minify", "strip_comments"]
```

### The "AI Context Optimization" Pattern

```yaml
bundles:
  ai-context:
    description: "Optimized for Claude and other LLMs"
    output: "m1f/ai-context.txt"
    sources:
      - path: "src"
        include_extensions: [".py", ".js", ".ts", ".jsx", ".tsx"]
        exclude_patterns:
          - "**/*.test.*"
          - "**/*.spec.*"
          - "**/test/**"

    # v3.2 optimizations
    global_settings:
      # Security first
      security_check: "warn"

      # Performance
      enable_content_deduplication: true # Reduce token usage

      # AI-friendly format
      separator_style: "Markdown"
      max_file_size: "100KB" # Keep context focused

      # Clean output
      remove_scraped_metadata: true
      allow_duplicate_files: false
```

### The "Encoding-Aware Bundle" Pattern

```yaml
bundles:
  legacy-code:
    description: "Handle mixed encoding legacy code"
    output: "m1f/legacy-bundle.txt"

    global_settings:
      # v3.2 encoding features
      prefer_utf8_for_text_files: false # Respect original encoding
      convert_to_charset: "utf-8" # But convert output
      abort_on_encoding_error: false # Continue on errors

      # Include everything
      include_binary_files: false
      include_dot_paths: true
```

## Pro Tips for Claude Interactions 💪

### 1. Let Claude Learn Your Project

First time? Let Claude explore:

```
Claude, analyze my project structure and suggest
how to organize it with m1f bundles. Consider:
- What files change together
- Logical groupings for different use cases
- Size limits for AI context windows

Use @m1f/m1f.txt to understand all available options.
```

### 2. Provide Clear Context

```
Claude, here's my project structure from m1f:
- Total files: 500
- Main languages: Python (60%), JavaScript (30%), Docs (10%)
- Special requirements: HIPAA compliance, no credential exposure
- Target use: Sharing with external auditors

Create a secure bundling strategy using m1f v3.2's security features.
Check @m1f/m1f.txt for security parameters.
```

### 3. Iterative Refinement

```
Claude, the bundle is too large (50MB). Help me:
1. Use content deduplication more aggressively
2. Set up file size limits
3. Create multiple smaller bundles by component
4. Exclude generated files and build artifacts
```

### 4. Preset Composition

```
Claude, I want layered presets:
1. base.yml - Company-wide standards
2. project.yml - Project-specific rules
3. personal.yml - My personal preferences

Show me how to use them together with proper override behavior.
```

## Security-First Workflows 🔒

### Preparing Code for Review

```
Claude, I need to share code with a contractor. Create a config that:
1. Runs strict security scanning (security_check: error)
2. Validates all file paths
3. Excludes .env files and secrets
4. Redacts any hardcoded credentials
5. Creates an audit trail

Use m1f v3.2's security features to make this bulletproof.
```

### Automated Security Checks

```
Claude, write a Git pre-commit hook that:
1. Runs m1f with security scanning
2. Blocks commits if secrets are found
3. Auto-generates safe bundles
4. Updates the m1f/ directory

Make it work with m1f v3.2's git hooks setup.
```

## Performance Optimization Strategies 🚀

### Large Codebase Handling

```
Claude, optimize m1f for our monorepo (10K+ files):

1. Set up smart exclusion patterns
2. Use size-based filtering
3. Create focused bundles per team
4. Leverage parallel processing
5. Implement caching strategies

Goal: Bundle generation under 30 seconds.
```

### Memory-Efficient Processing

```yaml
# Claude might suggest this for large files
large_files:
  description: "Handle massive log files"

  global_settings:
    max_file_size: "10MB" # Skip huge files
    enable_content_deduplication: true

  presets:
    truncate_logs:
      extensions: [".log", ".txt"]
      custom_processor: "truncate"
      processor_args:
        max_lines: 1000
        add_marker: true
```

## Troubleshooting with Claude 🔧

### Common Issues and Solutions

```
Claude, m1f is flagging false positives for secrets. Help me:
1. Configure security_check levels appropriately
2. Create patterns to exclude test fixtures
3. Set up per-file security overrides
4. Document why certain warnings are acceptable
```

### Performance Debugging

```
Claude, bundling takes 5 minutes. Analyze this verbose output
and suggest optimizations:
[paste m1f --verbose output]

Consider:
- File count and sizes
- Duplicate detection overhead
- Encoding detection delays
- Security scanning bottlenecks
```

## Integration Patterns 🔌

### CI/CD Integration

```
Claude, create a GitHub Action that:
1. Triggers on PR creation
2. Generates comparison bundles (before/after)
3. Posts bundle statistics as PR comment
4. Fails if bundle size increases >10%
5. Runs security scanning on changed files

Use m1f v3.2's features for efficiency.
```

### Documentation Automation

```
Claude, automate our documentation workflow:
1. Scrape our docs site weekly
2. Convert HTML to Markdown
3. Bundle by section with m1f
4. Remove outdated metadata
5. Create versioned archives

Leverage m1f's web scraping and processing features.
```

## Quick Reference Commands 🎪

Some powerful one-liners for common tasks:

```bash
# Give Claude m1f superpowers
m1f-link

# Quick m1f setup for your project
m1f-claude "Setup m1f for a typical Python project with tests and docs"

# Interactive Claude session
m1f-claude -i

# With specific permissions and tools
m1f-claude --permission-mode acceptEdits --allowed-tools "Read,Write,Edit" "Update the README"

# JSON output for automation
m1f-claude --output-format json "List all Python files"

# With MCP database tools
m1f-claude --mcp-config ./mcp.json "Query the user database"

# Security audit bundle
m1f -s . -o audit.txt --security-check error --minimal-output

# Fast development bundle (no security checks)
m1f -s ./src -o dev.txt --security-check skip

# Documentation bundle with metadata
m1f -s ./docs -o docs.txt --separator-style Detailed

# Clean bundle for AI consumption
m1f -s . -o ai-context.txt --allow-duplicate-files false

# Help me understand this codebase
m1f-claude "Create bundles to help a new developer understand this project"

# Prep for the AI apocalypse
m1f-claude "Optimize my project for AI assistants with proper context windows"
```

## Your Turn! 🎮

Now you're ready to turn Claude into your personal m1f expert. Remember:

1. Always start with `m1f-link` to give Claude the docs
2. Be specific about what you want to achieve
3. Let Claude suggest optimal configurations based on the documentation
4. Iterate and refine based on results
5. Test security settings thoroughly before sharing

The best part? Claude remembers your conversations, so it gets better at
understanding your project over time.

Happy bundling! 🚀

---

_P.S. - If Claude suggests something that seems off, just ask "Are you sure
about that? Check @m1f/m1f.txt again." Works every time! 😉_

======= docs/01_m1f/31_claude_code_integration.md ======
# Claude Code Integration Guide

This guide explains how to integrate Claude Code as an optional AI assistant for
the m1f tools project.

## Overview

Claude Code can help automate complex workflows by understanding natural
language prompts and executing the appropriate tools with correct parameters.

## Installation

### Prerequisites

- Node.js installed on your system
- An Anthropic API key (get one at https://console.anthropic.com)

### Install Claude Code

```bash
npm install -g @anthropic-ai/claude-code
```

### Initial Setup

1. Start Claude Code:

   ```bash
   claude
   ```

2. Login with your API key:

   ```
   /login
   ```

3. Configure Claude Code for this project:
   ```bash
   cd /path/to/m1f
   claude config
   ```

## Project Configuration

Create `.claude/settings.json` in the project root:

```json
{
  "model": "claude-opus-4",
  "customInstructions": "You are helping with the m1f tools project. Key tools available: m1f.py (file bundler), s1f.py (file splitter), mf1-html2md (HTML to Markdown converter), wp_export_md.py (WordPress exporter).",
  "permissions": {
    "write": true,
    "execute": true
  }
}
```

## m1f Project Setup

### Quick Setup with m1f-init

The `m1f-init` command provides cross-platform project initialization:

```bash
# Run in your project directory
m1f-init

# With verbose output
m1f-init --verbose
```

#### What m1f-init Does:

1. **Links m1f Documentation**
   - Creates m1f/m1f.txt symlink (or copies on Windows)
   - Makes documentation accessible to AI tools

2. **Project Analysis**
   - Detects git repository boundaries
   - Analyzes project structure and languages
   - Creates file and directory lists in `m1f/` directory

3. **Creates Initial Bundles with Auxiliary Files**
   - `<project>_complete.txt` - Full project bundle
   - `<project>_complete_filelist.txt` - List of all included files
   - `<project>_complete_dirlist.txt` - List of all directories
   - `<project>_docs.txt` - Documentation only bundle
   - `<project>_docs_filelist.txt` - List of documentation files
   - `<project>_docs_dirlist.txt` - Documentation directories

4. **Generates Configuration**
   - Creates basic .m1f.config.yml if not present
   - Respects .gitignore patterns
   - Excludes m1f/ directory automatically

### Advanced Setup with m1f-claude (Linux/macOS only)

The `m1f-claude` tool enhances project setup by creating topic-specific bundles
based on your project's needs:

```bash
# Interactive mode - prompts for project details
m1f-claude --setup

# With project information provided
m1f-claude --setup \
  --project-description "SaaS dashboard with React frontend and Express API" \
  --project-priorities "code modularity, API documentation, test coverage"
```

#### Project Information Options:

- **--project-description**: Brief description of what your project does and its
  main technologies
- **--project-priorities**: What's important for this project (e.g.,
  performance, security, documentation, maintainability)

This information helps Claude create better-targeted bundles. For example:

- If "security" is a priority, it will create dedicated auth/security bundles
- If "documentation" is important, it will create more granular doc bundles
- If "performance" matters, it will separate performance-critical code

For topic-specific bundles and advanced configuration:

```bash
# First run m1f-init
m1f-init

# Then run advanced setup
m1f-claude --setup
```

#### What --setup Does:

- Claude analyzes your project structure in detail
- Creates topic-specific bundles (models, views, tests, etc.)
- Customizes configuration for your project type
- Optimizes bundle organization for AI consumption
- Requires Claude Code SDK installation

**Note**: Windows users can achieve similar results by manually editing
.m1f.config.yml after running m1f-init.

### Working with Generated File Lists

The file lists generated by m1f-init are powerful tools for customization:

```bash
# View statistics
wc -l m1f/*_filelist.txt  # Count files in each bundle

# Create a custom bundle by editing file lists
cp m1f/myproject_complete_filelist.txt m1f/api_only_filelist.txt
vi m1f/api_only_filelist.txt  # Keep only API-related files
m1f -i m1f/api_only_filelist.txt -o m1f/api_bundle.txt

# Combine multiple lists
cat m1f/*_docs_filelist.txt m1f/tests_filelist.txt | sort -u > m1f/docs_and_tests.txt
m1f -i m1f/docs_and_tests.txt -o m1f/combined.txt

# Use directory lists to focus on specific areas
grep "src/components" m1f/myproject_complete_dirlist.txt
m1f -s src/components -o m1f/components_only.txt
```

3. **Configuration File**
   - Creates `.m1f.config.yml` with complete and docs bundles
   - Uses `docs_only: true` for documentation bundle
   - No global file size limits
   - Proper meta file exclusions (LICENSE*, CLAUDE.md, *.lock)

4. **Advanced Segmentation (Optional)**
   - If Claude Code is installed and advanced mode selected
   - Analyzes project structure for components, API, styles, etc.
   - Adds topic-specific bundles to existing configuration
   - Uses `--allowedTools Read,Write,Edit,MultiEdit` for file operations

#### Example Output:

```
🚀 Initializing m1f for your project...
==================================================
✅ Git repository detected: /home/user/my-project
✅ m1f documentation already available
⚠️  No m1f configuration found - will help you create one
✅ Claude Code is available

📊 Project Analysis
==============================
Analyzing project structure with m1f...
📄 Created file list: project_analysis_filelist.txt
📁 Created directory list: project_analysis_dirlist.txt
✅ Found 127 files in 59 directories
📁 Project Type: Next.js Application
💻 Languages: JavaScript (37 files), TypeScript (30 files)
📂 Code Dirs: src/app, src/components, src/lib

📦 Creating Initial Bundles
==============================
Creating complete project bundle...
✅ Created: m1f/complete.txt
Creating documentation bundle...
✅ Created: m1f/docs.txt

📝 Creating .m1f.config.yml with basic bundles...
✅ Configuration created with complete and docs bundles

🤖 Claude Code for Advanced Segmentation
──────────────────────────────────────────────────
Basic bundles created! Now Claude can help you create topic-specific bundles.

[Claude analyzes and adds topic-specific bundles]

✅ Advanced segmentation complete!
📝 Claude has analyzed your project and added topic-specific bundles.

🚀 Next steps:
• Your basic bundles are ready in m1f/
  - complete.txt: Full project bundle
  - docs.txt: All documentation files
• Run 'm1f-update' to regenerate bundles after config changes
• Use Claude to create topic-specific bundles as needed
```

#### Troubleshooting:

- **Use --verbose** to see the full prompt and command parameters
- **Check file permissions** if config isn't being modified
- **Ensure Claude Code is installed**:
  `npm install -g @anthropic-ai/claude-code`
- **Analysis files are kept** in m1f/ directory for reference

## Using Claude Code with m1f Tools

### Basic Commands

1. **Bundle files into m1f**:

   ```bash
   claude -p "Bundle all Python files in the tools directory into a single m1f file"
   ```

2. **Convert HTML to Markdown**:

   ```bash
   claude -p "Convert all HTML files in ~/docs to Markdown with preprocessing"
   ```

3. **Analyze and preprocess HTML**:
   ```bash
   claude -p "Analyze the HTML files in the docs folder and create a preprocessing config"
   ```

### Advanced Workflows

1. **Complete documentation conversion workflow**:

   ```bash
   claude -p "I have scraped HTML documentation in ~/docs/html. Please:
   1. Analyze a few sample files to understand the structure
   2. Create a preprocessing configuration
   3. Convert all HTML to Markdown
   4. Create thematic m1f bundles (concepts, reference, installation, etc.)"
   ```

2. **Export WordPress site**:
   ```bash
   claude -p "Export my WordPress site at example.com to Markdown, organizing by categories"
   ```

## Programmatic Usage

### Using Claude Code in Scripts

```python
#!/usr/bin/env python3
import subprocess
import json

def claude_command(prompt):
    """Execute a Claude Code command and return the result."""
    result = subprocess.run(
        ['claude', '-p', prompt, '--output-format', 'json'],
        capture_output=True,
        text=True
    )
    return json.loads(result.stdout)

# Example: Get optimal m1f parameters
response = claude_command(
    "What are the optimal m1f parameters for bundling a Python project with tests?"
)
print(response)
```

### Integration with m1f Tools

Create `tools/claude_orchestrator.py`:

```python
#!/usr/bin/env python3
"""Orchestrate m1f tools using Claude Code."""

import subprocess
import json
from pathlib import Path

class ClaudeOrchestrator:
    def __init__(self):
        self.tools = {
            'm1f': 'tools/m1f.py',
            's1f': 'tools/s1f.py',
            'mf1-html2md': 'tools/mf1-html2md',
            'wp_export': 'tools/wp_export_md.py'
        }

    def analyze_request(self, user_prompt):
        """Use Claude to analyze user request and determine actions."""
        analysis_prompt = f"""
        Analyze this request and return a JSON with:
        1. tool: which tool to use ({', '.join(self.tools.keys())})
        2. parameters: dict of parameters for the tool
        3. steps: list of steps to execute

        Request: {user_prompt}
        """

        result = subprocess.run(
            ['claude', '-p', analysis_prompt, '--output-format', 'json'],
            capture_output=True,
            text=True
        )
        return json.loads(result.stdout)

    def execute_workflow(self, user_prompt):
        """Execute a complete workflow based on user prompt."""
        plan = self.analyze_request(user_prompt)

        for step in plan['steps']:
            print(f"Executing: {step['description']}")
            # Execute the actual command
            subprocess.run(step['command'], shell=True)
```

## Best Practices

1. **Create project-specific instructions** in `.claude/settings.json`
2. **Use Claude for complex workflows** that require multiple steps
3. **Leverage Claude's understanding** of file patterns and project structure
4. **Combine with shell pipes** for powerful automation

## Example Workflows

### 1. Documentation Processing Pipeline

```bash
# Complete pipeline with Claude
claude -p "Process the scraped documentation in ~/scraped-docs:
1. Analyze HTML structure
2. Create preprocessing config
3. Convert to Markdown preserving structure
4. Create m1f bundles by topic
5. Generate a summary report"
```

### 2. Project Analysis

```bash
# Analyze project for bundling
claude -p "Analyze this Python project and suggest:
1. Which files should be bundled together
2. Optimal m1f parameters
3. Any files that should be excluded"
```

### 3. Automated Testing

```bash
# Run tests and fix issues
claude -p "Run the test suite, identify any failures, and fix them"
```

## Environment Variables

Set these in your shell profile for persistent configuration:

```bash
export ANTHROPIC_MODEL="claude-sonnet-4-20250514"
export CLAUDE_CODE_PROJECT_ROOT="/path/to/m1f"
```

## Troubleshooting

1. **Permission errors**: Ensure Claude Code has write permissions in settings
2. **Model selection**: Use Claude Opus 4 for the most complex analysis, Claude
   Sonnet 4 for balanced performance
3. **Rate limits**: Be mindful of API usage limits

## Security Considerations

1. **Never commit API keys** to version control
2. **Use `.claude/settings.local.json`** for personal settings
3. **Review Claude's actions** before executing in production

## Further Resources

- [Claude Code Documentation](https://docs.anthropic.com/en/docs/claude-code)
- [m1f Tools Documentation](00_m1f.md)
- [html2md Documentation](../03_html2md/30_html2md.md)

======= docs/01_m1f/40_security_best_practices.md ======
# Security Best Practices Guide for m1f Toolkit

## Overview

This guide documents security best practices and protective measures implemented
in the m1f toolkit v3.2. Following these practices ensures safe operation and
prevents common security vulnerabilities.

## Path Validation and Traversal Protection

### Why It Matters

Path traversal attacks can allow malicious actors to access files outside
intended directories, potentially exposing sensitive system files or overwriting
critical data.

### Best Practices

1. **Always validate resolved paths**:

   ```python
   # Good practice - validate after resolving
   from tools.m1f.utils import validate_safe_path

   target_path = Path(user_input).resolve()
   validate_safe_path(target_path, base_path)
   ```

2. **Use the provided validation utilities**:
   - `validate_safe_path()` in `tools/m1f/utils.py` ensures paths stay within
     allowed boundaries
   - All user-provided paths should be validated before use

3. **Symlink safety**:
   - Symlinks are resolved and validated to prevent escaping directories
   - Target of symlinks must be within the allowed base path

### Common Pitfalls to Avoid

- Never use user input directly in file paths without validation
- Don't trust relative paths without resolving and validating them
- Always validate paths from configuration files and presets

## Web Scraping Security

### SSRF (Server-Side Request Forgery) Protection

The toolkit blocks access to:

- Private IP ranges (10.x.x.x, 172.16.x.x, 192.168.x.x)
- Localhost and loopback addresses (127.0.0.1, ::1)
- Link-local addresses (169.254.x.x)
- Cloud metadata endpoints (169.254.169.254)

### SSL/TLS Validation

1. **Default behavior**: SSL certificates are validated by default
2. **Disabling validation** (use with caution):

   ```bash
   # Only for trusted internal sites or testing
   m1f-scrape --ignore-https-errors https://internal-site.com
   ```

   ⚠️ **Warning**: Disabling SSL validation exposes you to man-in-the-middle
   attacks. Only use for trusted internal resources.

### robots.txt Compliance

All scrapers automatically respect robots.txt files:

- Automatically fetched and parsed for each domain
- Scraping is blocked for disallowed paths
- User-agent specific rules are respected
- This is always enabled - no configuration option to disable

### JavaScript Execution Safety

When using Playwright with custom scripts:

- Scripts are validated for dangerous patterns
- Avoid executing untrusted JavaScript code
- Use built-in actions instead of custom scripts when possible

## Command Injection Prevention

### Safe Command Execution

The toolkit uses proper escaping for all system commands:

```python
# Good - using shlex.quote()
import shlex
command = f"httrack {shlex.quote(url)} -O {shlex.quote(output_dir)}"

# Bad - direct string interpolation
command = f"httrack {url} -O {output_dir}"  # DON'T DO THIS
```

## Preset System Security

### File Size Limits

- Preset files are limited to 10MB to prevent memory exhaustion
- Large preset files are rejected with an error

### Path Validation in Presets

- All paths in preset files are validated
- Paths cannot escape the project directory
- Absolute paths outside the project are blocked

### Custom Processor Validation

- Processor names must be alphanumeric with underscores only
- Special characters that could enable code injection are blocked

## Secure Temporary File Handling

The toolkit uses Python's `tempfile` module for all temporary files:

- Temporary directories are created with restricted permissions
- All temporary files are cleaned up after use
- No sensitive data is left in temporary locations

## Security Scanning for Sensitive Data

### Built-in Secret Detection

m1f includes automatic scanning for:

- API keys and tokens
- Passwords and credentials
- Private keys
- High-entropy strings that might be secrets

### Security Check Modes

1. **Error mode** (default): Stops processing if secrets are found

   ```bash
   m1f -s ./src -o output.txt --security-check error
   ```

2. **Warn mode**: Logs warnings but continues processing

   ```bash
   m1f -s ./src -o output.txt --security-check warn
   ```

3. **Skip mode**: Disables security scanning (not recommended)
   ```bash
   m1f -s ./src -o output.txt --security-check skip
   ```

### Handling False Positives

If legitimate content is flagged as sensitive:

1. Review the warnings carefully
2. Use `--security-check warn` if you're certain the content is safe
3. Consider refactoring code to avoid patterns that trigger detection

## Input Validation Best Practices

### File Type Validation

- Use include/exclude patterns to limit processed file types
- Be explicit about allowed file extensions
- Validate file contents match expected formats

### Size and Resource Limits

- Set appropriate limits for file sizes
- Use `--max-file-size` to prevent processing huge files
- Monitor memory usage for large file sets

### Encoding Safety

- The toolkit automatically detects file encodings
- UTF-8 is preferred for text files by default
- Binary files are handled safely without interpretation

## Deployment Security Recommendations

### Environment Configuration

1. Run with minimal required permissions
2. Use dedicated service accounts when possible
3. Avoid running as root/administrator

### Network Security

1. Use HTTPS for all web scraping when possible
2. Configure firewall rules to limit outbound connections
3. Monitor for unusual network activity

### Logging and Monitoring

1. Enable verbose logging for security-sensitive operations
2. Review logs regularly for suspicious patterns
3. Set up alerts for security check failures

## Reporting Security Issues

If you discover a security vulnerability in m1f:

1. Do NOT open a public issue
2. Email security details to the maintainers
3. Include steps to reproduce the issue
4. Allow time for a fix before public disclosure

## Security Checklist for Users

Before running m1f in production:

- [ ] Validate all input paths and patterns
- [ ] Review security check mode settings
- [ ] Enable SSL validation for web scraping
- [ ] Set appropriate file size limits
- [ ] Use minimal required permissions
- [ ] Review preset files for suspicious content
- [ ] Test security scanning on sample data
- [ ] Configure proper logging and monitoring
- [ ] Keep the toolkit updated to the latest version

## Updates and Security Patches

Stay informed about security updates:

- Check the CHANGELOG for security-related fixes
- Update to new versions promptly
- Review breaking changes that might affect security

Remember: Security is a shared responsibility. While m1f implements many
protective measures, proper configuration and usage are essential for
maintaining a secure environment.

======= docs/01_m1f/41_version_3_2_features.md ======
# m1f v3.2 Feature Documentation

## Overview

Version 3.2 of the m1f toolkit introduces significant security enhancements,
performance improvements, and new configuration options. This document provides
a comprehensive overview of all v3.2 features and changes.

## Major Security Enhancements

### 1. Path Traversal Protection

- **What's New**: Comprehensive validation of all file paths to prevent
  directory traversal attacks
- **Impact**: Prevents malicious actors from accessing files outside intended
  directories
- **Implementation**:
  - New `validate_safe_path()` utility function
  - Applied to all user inputs, preset paths, and configuration files
  - Symlink targets are now validated

### 2. SSRF Protection in Web Scrapers

- **What's New**: Blocks access to private IP ranges and cloud metadata
  endpoints
- **Protected Ranges**:
  - Private networks (10.x.x.x, 172.16.x.x, 192.168.x.x)
  - Localhost (127.0.0.1, ::1)
  - Link-local (169.254.x.x)
  - Cloud metadata (169.254.169.254)
- **Applies to**: All web scraping tools (BeautifulSoup, Playwright, Scrapy,
  Selectolax)

### 3. robots.txt Compliance

- **What's New**: All scrapers now automatically respect robots.txt files
- **Features**:
  - Automatic robots.txt fetching and parsing
  - Per-path access validation
  - User-agent specific rule support

### 4. SSL/TLS Certificate Validation

- **What's New**: SSL validation is now enabled by default
- **Configuration**:
  - New `--ignore-https-errors` flag for exceptions
  - Per-scraper SSL configuration
- **Security**: Prevents man-in-the-middle attacks

### 5. Command Injection Prevention

- **What's New**: Proper escaping of all shell commands
- **Implementation**: Uses `shlex.quote()` for all user inputs in commands
- **Affected Tools**: HTTrack scraper, git operations

### 6. JavaScript Execution Safety

- **What's New**: Validation of custom JavaScript in Playwright scraper
- **Features**:
  - Detects dangerous patterns (eval, Function constructor)
  - Warns about custom script execution
  - Encourages use of built-in actions

### 7. Custom Processor Validation

- **What's New**: Validates processor names to prevent injection attacks
- **Rules**: Only alphanumeric characters and underscores allowed
- **Impact**: Prevents code injection through preset files

## Performance Improvements

### 1. Parallel File Processing

- **Enabled by Default**: Parallel processing is now always active
- **Features**:
  - Concurrent file reading with automatic batch size optimization
  - Thread-safe checksum deduplication
  - Maintains deterministic file order in output
- **Performance**: Up to 3-5x faster for large file sets

### 2. Optimized Checksum Verification

- **What's Changed**: Stream-based file reading for checksums
- **Benefits**:
  - Reduced memory usage for large files
  - Prevents out-of-memory errors
  - 8KB chunk processing

### 3. Concurrent Write Limits in s1f

- **What's New**: Semaphore-based write limiting
- **Default**: 10 concurrent file operations
- **Benefits**: Prevents "too many open files" errors

### 4. Async I/O Improvements

- **Updates**:
  - Uses `aiofiles` for truly async file operations
  - Modern async patterns (asyncio.run())
  - Proper exception handling in async contexts

## Configuration Enhancements

### 1. Content Deduplication Control

- **New CLI Option**: `--allow-duplicate-files`
- **Preset Setting**: `enable_content_deduplication`
- **Default**: Deduplication enabled (False for allow-duplicate)
- **Use Case**: When you need to preserve duplicate content

### 2. UTF-8 Preference Control

- **New CLI Option**: `--no-prefer-utf8-for-text-files`
- **Preset Setting**: `prefer_utf8_for_text_files`
- **Default**: UTF-8 preferred (True)
- **Use Case**: Working with legacy encodings like windows-1252

### 3. Security Check Modes

- **Options**:
  - `error` (default): Stop on security issues
  - `warn`: Log warnings but continue
  - `skip`: Disable security scanning
- **CLI**: `--security-check {error|warn|skip}`
- **Preset**: `security_check` setting

### 4. File Size Limits

- **Preset Files**: Limited to 10MB
- **Benefits**: Prevents memory exhaustion attacks
- **Error Handling**: Clear error messages for oversized files

## Improved Patterns and Flexibility

### 1. Flexible Metadata Stripping

- **What's New**: More flexible regex for scraped content metadata
- **Supports**:
  - Various horizontal rule styles (`---`, `___`, `***`)
  - Different emphasis markers
  - Multiple formatting variations

### 2. Code Block Detection in s1f

- **What's New**: Ignores separators inside code blocks
- **Benefits**: Prevents false positive file detection
- **Applies to**: Markdown code blocks (```)

### 3. Timezone-Aware Timestamps

- **What's Changed**: All timestamps now use UTC
- **Implementation**: `datetime.now(timezone.utc)`
- **Benefits**: Consistent timestamps across timezones

## CLI Updates

### New Options Summary

```bash
# Performance
--allow-duplicate-files         # Disable content deduplication

# Encoding
--no-prefer-utf8-for-text-files # Disable UTF-8 preference

# Security
--security-check {error|warn|skip}  # Security scanning mode
--ignore-https-errors              # Disable SSL validation (scraping)

# Existing options work as before
--source-directory, -s          # Source directory
--output-file, -o              # Output file
--preset                       # Use preset configuration
```

## Breaking Changes

### 1. Standard Separator Format

- **Change**: File separators no longer include checksums
- **Before**: `=== path/to/file.txt === SHA256: abc123...`
- **After**: `=== path/to/file.txt ===`
- **Impact**: s1f can still read old format files

### 2. SSL Validation Default

- **Change**: SSL validation now enabled by default
- **Impact**: May break scraping of sites with invalid certificates
- **Migration**: Use `--ignore-https-errors` if needed

### 3. Security Scanning Default

- **Change**: Security scanning in error mode by default
- **Impact**: Processing stops on sensitive data detection
- **Migration**: Use `--security-check warn` for old behavior

## Preset System Enhancements

### New Preset Settings

```yaml
# Performance
enable_content_deduplication: false # Allow duplicate files

# Encoding
prefer_utf8_for_text_files: false # Disable UTF-8 preference

# Security
security_check: warn # Security check mode

# Per-file settings still work
per_file_settings:
  "*.min.js":
    processors:
      - minify_content
```

## Test Suite Improvements

- Fixed test isolation issues
- Added proper async test support
- Improved test server connectivity handling
- Enhanced security test coverage

## Migration Guide

### From v3.1 to v3.2

1. **Review Security Settings**:
   - Default security scanning may flag legitimate content
   - Use `--security-check warn` during migration

2. **Check SSL Requirements**:
   - Sites with self-signed certificates need `--ignore-https-errors`
   - Review and update scraping scripts

3. **Update Separator Parsing**:
   - If you parse m1f output, update to handle new separator format
   - s1f handles both formats automatically

4. **Performance Tuning**:
   - Parallel processing is automatic - no configuration needed
   - Monitor memory usage with large file sets

## Examples

### Using New Features

```bash
# Security in warn mode (parallel processing is automatic)
m1f -s ./src -o bundle.txt --security-check warn

# Allow duplicates with custom encoding handling
m1f -s ./legacy -o output.txt --allow-duplicate-files --no-prefer-utf8-for-text-files

# Secure web scraping (robots.txt compliance is automatic)
m1f-scrape https://example.com -o ./scraped

# Using new features in presets
m1f -s . -o bundle.txt --preset my-preset.yml
```

### Sample v3.2 Preset

```yaml
name: "Modern Web Project v3.2"
version: "3.2"

# Global settings with v3.2 features
settings:
  enable_content_deduplication: true
  prefer_utf8_for_text_files: true
  security_check: error

# File patterns remain the same
include_patterns:
  - "src/**/*.{js,ts,jsx,tsx}"
  - "**/*.md"

exclude_patterns:
  - "**/node_modules/**"
  - "**/.git/**"

# Per-file settings with processors
per_file_settings:
  "*.min.js":
    processors:
      - minify_content
```

## Performance Benchmarks

Typical improvements with v3.2:

- **Parallel Processing**: 3-5x faster for 1000+ files
- **Memory Usage**: 50% reduction for large files
- **s1f Extraction**: 2x faster with concurrent writes
- **Checksum Calculation**: Constant memory usage regardless of file size

## Security Audit Results

v3.2 addresses all HIGH and MEDIUM priority security issues:

- ✅ Path traversal vulnerabilities fixed
- ✅ SSRF protection implemented
- ✅ Command injection prevented
- ✅ SSL validation enforced
- ✅ robots.txt compliance added
- ✅ JavaScript execution validated
- ✅ Race conditions eliminated

## Support and Resources

- [Security Best Practices Guide](./40_security_best_practices.md)
- [CLI Reference](./02_cli_reference.md)
- [Preset System Guide](./10_m1f_presets.md)
- [Troubleshooting Guide](./03_troubleshooting.md)

For questions or issues, please refer to the project repository.

======= docs/02_s1f/20_s1f.md ======
# s1f (Split One File)

A modern file extraction tool with async I/O that reconstructs original files
from combined archives with full metadata preservation.

## Overview

The s1f tool (v2.0.0) is the counterpart to m1f, designed to extract and
reconstruct original files from a combined file. Built with Python 3.10+ and
modern async architecture, it ensures reliable extraction with checksum
verification and proper encoding handling.

## Key Features

- **Async I/O**: High-performance concurrent file writing
- **Smart Parser Framework**: Automatic format detection with dedicated parsers
- **Type Safety**: Full type annotations throughout the codebase
- **Modern Architecture**: Clean modular design with dependency injection
- **Checksum Verification**: SHA256 integrity checking with line ending
  normalization
- **Encoding Support**: Intelligent encoding detection and conversion
- **Error Recovery**: Graceful fallbacks and detailed error reporting
- **Progress Tracking**: Real-time extraction statistics

## Quick Start

```bash
# Basic extraction (positional arguments - recommended)
m1f-s1f ./combined.txt ./extracted_files

# Basic extraction (option-style arguments)
m1f-s1f -i ./combined.txt -d ./extracted_files

# List files without extracting
m1f-s1f --list ./combined.txt

# Force overwrite of existing files
m1f-s1f ./combined.txt ./extracted_files -f

# Verbose output to see detailed extraction progress
m1f-s1f ./combined.txt ./extracted_files -v

# Extract with specific encoding (new in v2.0.0)
m1f-s1f ./combined.txt ./extracted_files --target-encoding utf-16-le
```

## Architecture

S1F v2.0.0 features a modern, modular architecture:

```
tools/s1f/
├── __init__.py       # Package initialization
├── __main__.py       # Entry point for module execution
├── cli.py            # Command-line interface
├── config.py         # Configuration management
├── core.py           # Core extraction logic with async I/O
├── exceptions.py     # Custom exceptions
├── logging.py        # Structured logging
├── models.py         # Data models (ExtractedFile, etc.)
├── parsers.py        # Abstract parser framework
├── utils.py          # Utility functions
└── writers.py        # Output writers (file, stdout)
```

### Key Components

- **Async I/O**: Concurrent file operations for better performance
- **Parser Framework**: Extensible system for handling different file formats
- **Type Safety**: Full type hints and dataclass models
- **Clean Architecture**: Separation of concerns with dependency injection

## Command Line Options

s1f supports both positional and option-style arguments for flexibility:

### Positional Arguments (recommended)

```bash
s1f <input_file> <destination_directory>
```

### Option-Style Arguments (backward compatibility)

```bash
s1f -i <input_file> -d <destination_directory>
```

### All Options

| Option                        | Description                                                                                                                                                                                                   |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `-i, --input-file`            | Path to the combined input file (can also be specified as first positional argument)                                                                                                                          |
| `-d, --destination-directory` | Directory where extracted files will be saved (can also be specified as second positional argument)                                                                                                           |
| `-l, --list`                  | List files in the archive without extracting them. When used, destination directory is not required                                                                                                           |
| `-f, --force`                 | Force overwrite of existing files without prompting                                                                                                                                                           |
| `-v, --verbose`               | Enable verbose output                                                                                                                                                                                         |
| `--version`                   | Show version information and exit                                                                                                                                                                             |
| `--timestamp-mode`            | How to set file timestamps (`original` or `current`). Original preserves timestamps from when files were combined, current uses the current time                                                              |
| `--ignore-checksum`           | Skip checksum verification for MachineReadable files. Useful when files were intentionally modified after being combined                                                                                      |
| `--respect-encoding`          | Try to use the original file encoding when writing extracted files. If enabled and original encoding information is available, files will be written using that encoding instead of UTF-8                     |
| `--target-encoding`           | Explicitly specify the character encoding to use for all extracted files (e.g., `utf-8`, `latin-1`, `utf-16-le`). This overrides the `--respect-encoding` option and any encoding information in the metadata |

## Usage Examples

### Basic Operations

```bash
# Basic command (positional arguments)
m1f-s1f /path/to/combined_output.txt /path/to/output_folder

# Basic command (option-style)
m1f-s1f --input-file /path/to/combined_output.txt \
  --destination-directory /path/to/output_folder

# List files in archive without extracting
m1f-s1f --list ./output/bundle.m1f.txt

# Splitting a MachineReadable file with force overwrite and verbose output
m1f-s1f ./output/bundle.m1f.txt ./extracted_project -f -v

# Check version
m1f-s1f --version
```

### Advanced Operations

```bash
# Using current system time for timestamps
m1f-s1f -i ./combined_file.txt -d ./extracted_files \
  --timestamp-mode current

# Preserving original file encodings
m1f-s1f -i ./with_encodings.txt -d ./extracted_files \
  --respect-encoding

# Using a specific encoding for all extracted files
m1f-s1f -i ./combined_file.txt -d ./extracted_files \
  --target-encoding utf-8

# Ignoring checksum verification (when files were intentionally modified)
m1f-s1f -i ./modified_bundle.m1f.txt -d ./extracted_files \
  --ignore-checksum
```

## Supported File Formats

The s1f tool can extract files from combined files created with any of the m1f
separator styles:

- **Standard Style** - Simple separators with file paths and checksums
- **Detailed Style** - Comprehensive separators with full metadata
- **Markdown Style** - Formatted with Markdown syntax for documentation
- **MachineReadable Style** - Structured format with JSON metadata and UUID
  boundaries
- **None Style** - Files combined without separators (limited extraction
  capability)

For the most reliable extraction, use files created with the MachineReadable
separator style, as these contain complete metadata and checksums for
verification.

## Common Workflows

### Extract and Verify

This workflow is useful when you want to ensure the integrity of extracted
files:

```bash
# Step 1: Extract the files with verification
m1f-s1f -i ./project_bundle.m1f.txt -d ./extracted_project -v

# Step 2: Check for any checksum errors in the output
# If any errors are reported, consider using --ignore-checksum if appropriate
```

### Multiple Extraction Targets

When you need to extract the same combined file to different locations:

```bash
# Extract for development
m1f-s1f -i ./project.m1f.txt -d ./dev_workspace

# Extract for backup with original timestamps
m1f-s1f -i ./project.m1f.txt -d ./backup --timestamp-mode original
```

## Performance

S1F v2.0.0 includes significant performance improvements:

- **Async I/O**: Concurrent file writing for 3-5x faster extraction on SSDs
- **Optimized Parsing**: Efficient line-by-line processing with minimal memory
  usage
- **Smart Buffering**: Adaptive buffer sizes based on file characteristics

## Error Handling

The tool provides comprehensive error handling:

- **Checksum Verification**: Automatic integrity checking with clear error
  messages
- **Encoding Fallbacks**: Graceful handling of encoding issues with multiple
  fallback strategies
- **Permission Errors**: Clear reporting of file system permission issues
- **Partial Recovery**: Continue extraction even if individual files fail

======= docs/03_html2md/30_html2md.md ======
# html2md (HTML to Markdown Converter)

A modern HTML to Markdown converter with HTML structure analysis, custom
extractors, async I/O, and parallel processing capabilities.

## Overview

The html2md tool (v3.4.0) provides a robust solution for converting HTML content
to Markdown format, with fine-grained control over the conversion process. Built
with Python 3.10+ and modern async architecture, it focuses on intelligent
content extraction and conversion.

**New in v3.4.0:** Custom extractor plugin system for site-specific content
extraction.

**Note:** Web scraping functionality has been moved to the separate `webscraper`
tool for better modularity. Use `webscraper` to download websites, then
`html2md` to convert the downloaded HTML files.

## Key Features

- **Custom Extractor System**: Create site-specific extractors for optimal
  content extraction
- **HTML Structure Analysis**: Analyze HTML files to find optimal content
  selectors
- **Intelligent Content Extraction**: Use CSS selectors to extract specific
  content
- **Async I/O**: High-performance concurrent file processing
- **API Mode**: Programmatic access for integration with other tools
- **Type Safety**: Full type annotations throughout the codebase
- **Modern Architecture**: Clean modular design
- **Workflow Integration**: .scrapes directory structure for organized
  processing
- Recursive directory scanning for batch conversion
- Smart internal link handling (HTML → Markdown)
- Customizable element filtering and removal
- YAML frontmatter generation
- Heading level adjustment
- Code block language detection
- Character encoding detection and conversion
- Parallel processing for faster conversion

## Quick Start

```bash
# Basic conversion of all HTML files in a directory
m1f-html2md convert ./website -o ./docs

# Use a custom extractor for site-specific conversion
m1f-html2md convert ./website -o ./docs \
  --extractor ./extractors/custom_extractor.py

# Extract only main content from HTML files
m1f-html2md convert ./website -o ./docs \
  --content-selector "main.content" --ignore-selectors nav .sidebar footer

# Skip YAML frontmatter and adjust heading levels
m1f-html2md convert ./website -o ./docs \
  --no-frontmatter --heading-offset 1

# Analyze HTML structure to find best selectors
m1f-html2md analyze ./html/*.html --suggest-selectors

# Analyze with detailed structure output
m1f-html2md analyze ./html/*.html --show-structure --common-patterns

# Use Claude AI to intelligently analyze HTML structure
m1f-html2md analyze ./html/ --claude

# Analyze with Claude and specify number of files to analyze (1-20)
m1f-html2md analyze ./html/ --claude --analyze-files 10

# Convert HTML to Markdown using Claude AI (clean content extraction)
m1f-html2md convert ./html/ -o ./markdown/ --claude --model opus --sleep 2

# Generate a configuration file
m1f-html2md config -o config.yaml
```

### Complete Workflow Example with .scrapes Directory

```bash
# Step 1: Create project structure
mkdir -p .scrapes/my-project/{html,md,extractors}

# Step 2: Download website using webscraper
m1f-scrape https://example.com -o .scrapes/my-project/html

# Step 3: Analyze HTML structure (optional)
m1f-html2md analyze .scrapes/my-project/html/ --suggest-selectors

# Step 4: Create custom extractor (optional)
# Use Claude to analyze and create site-specific extractor:
claude -p "Analyze these HTML files and create a custom extractor for html2md" \
  --files .scrapes/my-project/html/*.html

# Step 5: Convert with custom extractor
m1f-html2md convert .scrapes/my-project/html -o .scrapes/my-project/md \
  --extractor .scrapes/my-project/extractors/custom_extractor.py
```

## Command Line Interface

The html2md tool uses subcommands for different operations:

### Convert Command

Convert local HTML files to Markdown:

```bash
m1f-html2md convert <source> -o <output> [options]
```

| Option               | Description                                                   |
| -------------------- | ------------------------------------------------------------- |
| `source`             | Source file or directory                                      |
| `-o, --output`       | Output file or directory (required)                           |
| `-c, --config`       | Configuration file path (YAML format)                         |
| `--format`           | Output format: markdown, m1f_bundle, json (default: markdown) |
| `--extractor`        | Path to custom extractor Python file                          |
| `--content-selector` | CSS selector for main content                                 |
| `--ignore-selectors` | CSS selectors to ignore (space-separated)                     |
| `--heading-offset`   | Offset heading levels (default: 0)                            |
| `--no-frontmatter`   | Don't add YAML frontmatter                                    |
| `--parallel`         | Enable parallel processing                                    |
| `--claude`           | Use Claude AI to convert HTML to Markdown (content only)      |
| `--model`            | Claude model to use: opus, sonnet (default: sonnet)           |
| `--sleep`            | Sleep time in seconds between Claude API calls (default: 1.0) |
| `-v, --verbose`      | Enable verbose output                                         |
| `-q, --quiet`        | Suppress all output except errors                             |

### Analyze Command

Analyze HTML structure for optimal content extraction:

```bash
m1f-html2md analyze <paths> [options]
```

| Option                | Description                                                          |
| --------------------- | -------------------------------------------------------------------- |
| `paths`               | HTML files or directories to analyze                                 |
| `--show-structure`    | Show detailed HTML structure                                         |
| `--common-patterns`   | Find common patterns across files                                    |
| `--suggest-selectors` | Suggest CSS selectors for content extraction (default if no options) |
| `--claude`            | Use Claude AI to intelligently select files and suggest selectors    |
| `--analyze-files`     | Number of files to analyze with Claude (1-20, default: 5)            |
| `-v, --verbose`       | Enable verbose output                                                |
| `-q, --quiet`         | Suppress all output except errors                                    |

### Config Command

Generate a configuration file template:

```bash
m1f-html2md config [options]
```

| Option         | Description                                            |
| -------------- | ------------------------------------------------------ |
| `-o, --output` | Output configuration file (default: config.yaml)       |
| `--format`     | Configuration format: yaml, toml, json (default: yaml) |

## Claude AI Integration

html2md offers optional Claude AI integration for intelligent HTML analysis and
conversion:

### Claude Command Detection

The tool automatically detects Claude Code installations in various locations:

- Standard PATH locations
- `~/.claude/local/claude` (common for local installations)
- `/usr/local/bin/claude` and `/usr/bin/claude`

If you have Claude Code installed but get a "command not found" error, the tool
will automatically find and use your Claude binary.

### AI-Powered Analysis

Use Claude to automatically select representative HTML files and suggest optimal
CSS selectors:

```bash
# Analyze a directory of HTML files with Claude
m1f-html2md analyze ./scraped-site/ --claude

# Analyze more files for better coverage (up to 20)
m1f-html2md analyze ./scraped-site/ --claude --analyze-files 10

# Claude will:
# 1. Prompt for project description and important files (if applicable)
# 2. Select representative files from the directory (default: 5)
# 3. Analyze each file's structure individually
# 4. Synthesize findings to suggest optimal selectors
# 5. Generate a YAML configuration (html2md_extract_config.yaml)
```

**Features of Claude Analysis:**

- **Project Context**: Provides project description to help Claude understand
  the content
- **Important File Priority**: Can specify important files for Claude to
  prioritize
- **Multi-phase Analysis**: Individual file analysis followed by synthesis
- **Transparent Process**: Creates temporary analysis files in m1f/ directory
- **Smart Subprocess Handling**: Uses subprocess.run() for reliable Claude CLI
  integration
- **Streaming Output**: Real-time progress display during Claude analysis
  (v3.4.0)
- **Robust Config Loading**: Handles Claude-generated configs with unknown
  fields gracefully (v3.4.0)

### AI-Powered Conversion

Use Claude to convert HTML to clean Markdown, extracting only the main content:

```bash
# Convert all HTML files using Claude AI
m1f-html2md convert ./html/ -o ./markdown/ --claude

# Use Opus model for higher quality (default is Sonnet)
m1f-html2md convert ./html/ -o ./markdown/ --claude --model opus

# Add delay between API calls to avoid rate limits
m1f-html2md convert ./html/ -o ./markdown/ --claude --sleep 3
```

The Claude conversion:

- Extracts only the main content (no navigation, ads, etc.)
- Preserves document structure and formatting
- Handles complex HTML layouts intelligently
- Generates clean, readable Markdown

## Usage Examples

### Basic Conversion

```bash
# Simple conversion of all HTML files in a directory
m1f-html2md convert ./website -o ./docs

# Convert files with verbose logging
m1f-html2md convert ./website -o ./docs --verbose

# Convert to m1f bundle format
m1f-html2md convert ./website -o ./docs.m1f --format m1f_bundle

# Convert to JSON format for processing
m1f-html2md convert ./website -o ./data.json --format json
```

### Content Selection

```bash
# Extract only the main content and ignore navigation elements
m1f-html2md convert ./website -o ./docs \
  --content-selector "main" --ignore-selectors nav .sidebar footer

# Extract article content from specific selectors
m1f-html2md convert ./website -o ./docs \
  --content-selector "article.content" \
  --ignore-selectors .author-bio .share-buttons .related-articles
```

### HTML Analysis

```bash
# Analyze HTML files to find optimal selectors
m1f-html2md analyze ./html/ --suggest-selectors

# Show detailed structure of HTML files
m1f-html2md analyze ./html/ --show-structure

# Find common patterns across multiple files
m1f-html2md analyze ./html/ --common-patterns

# Get all analysis options
m1f-html2md analyze ./html/ \
  --show-structure --common-patterns --suggest-selectors
```

### File Filtering

```bash
# Process only specific file types
m1f-html2md convert ./website -o ./docs \
  -c config.yaml  # Use a configuration file for file filtering
```

### Formatting Options

```bash
# Adjust heading levels (e.g., h1 → h2, h2 → h3)
m1f-html2md convert ./website -o ./docs \
  --heading-offset 1

# Skip frontmatter generation
m1f-html2md convert ./website -o ./docs \
  --no-frontmatter

# Use configuration file for advanced formatting options
m1f-html2md convert ./website -o ./docs -c config.yaml

# Log conversion process to file
m1f-html2md convert ./website -o ./docs \
  --log-file conversion.log
```

### Performance Optimization

```bash
# Use parallel processing for faster conversion of large sites
m1f-html2md convert ./website -o ./docs \
  --parallel
```

## Custom Extractors

The custom extractor system allows you to create site-specific content
extraction logic for optimal results. Extractors can be simple functions or full
classes.

### Creating a Custom Extractor

#### Function-based Extractor

```python
# extractors/simple_extractor.py
from bs4 import BeautifulSoup
from typing import Optional, Dict, Any

def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    """Extract main content from HTML."""
    # Remove navigation elements
    for nav in soup.find_all(['nav', 'header', 'footer']):
        nav.decompose()

    # Find main content
    main = soup.find('main') or soup.find('article')
    if main:
        new_soup = BeautifulSoup('<html><body></body></html>', 'html.parser')
        new_soup.body.append(main)
        return new_soup

    return soup

def postprocess(markdown: str, config: Optional[Dict[str, Any]] = None) -> str:
    """Clean up the converted markdown."""
    # Remove duplicate newlines
    import re
    return re.sub(r'\n{3,}', '\n\n', markdown)
```

#### Class-based Extractor

```python
# extractors/advanced_extractor.py
from tools.html2md.extractors import BaseExtractor
from bs4 import BeautifulSoup
from typing import Optional, Dict, Any

class Extractor(BaseExtractor):
    """Custom extractor for specific website."""

    def extract(self, soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
        """Extract content with site-specific logic."""
        # Custom extraction logic
        return soup

    def preprocess(self, html: str, config: Optional[Dict[str, Any]] = None) -> str:
        """Preprocess raw HTML before parsing."""
        # Fix common HTML issues
        return html.replace('&nbsp;', ' ')

    def postprocess(self, markdown: str, config: Optional[Dict[str, Any]] = None) -> str:
        """Post-process converted markdown."""
        # Clean up site-specific artifacts
        return markdown
```

### Using Custom Extractors

```bash
# Use with CLI
m1f-html2md convert ./html -o ./markdown \
  --extractor ./extractors/my_extractor.py

# Use with API
from tools.html2md.api import Html2mdConverter
from pathlib import Path

converter = Html2mdConverter(
    config,
    extractor=Path("./extractors/my_extractor.py")
)
```

### .scrapes Directory Structure

The recommended workflow uses a `.scrapes` directory (gitignored) for organizing
scraping projects:

```
.scrapes/
└── project-name/
    ├── html/         # Raw HTML files from scraping
    ├── md/           # Converted Markdown files
    └── extractors/   # Custom extraction scripts
        └── custom_extractor.py
```

This structure keeps scraped content organized and separate from your main
codebase.

## Advanced Features

### YAML Frontmatter

By default, the converter adds YAML frontmatter to each Markdown file,
including:

- Title extracted from HTML title tag or first h1 element
- Source filename
- Conversion date
- Original file modification date

To disable frontmatter generation, use the `--no-frontmatter` option:

```bash
m1f-html2md convert ./website -o ./docs --no-frontmatter
```

The generated frontmatter looks like:

```yaml
---
title: Extracted from HTML
source_file: original.html
date_converted: 2023-06-15T14:30:21
date_modified: 2023-06-12T10:15:33
---
```

### Heading Level Adjustment

The `--heading-offset` option allows you to adjust the hierarchical structure of
the document by incrementing or decrementing heading levels. This is useful
when:

- Integrating content into an existing document with its own heading hierarchy
- Making h1 headings become h2 headings for better document structure
- Ensuring proper nesting of headings for better semantics

Positive values increase heading levels (e.g., h1 → h2), while negative values
decrease them (e.g., h2 → h1).

### Code Block Language Detection

The converter can automatically detect language hints from HTML code blocks that
use language classes, such as:

```html
<pre><code class="language-python">def example():
    return "Hello, world!"
</code></pre>
```

This will be converted to a properly formatted Markdown code block with language
hint:

````markdown
```python
def example():
    return "Hello, world!"
```
````

### Character Encoding Handling

The converter provides robust character encoding detection and conversion:

1. Automatically detects the encoding of source HTML files
2. Properly handles UTF-8, UTF-16, and other encodings
3. All output files are written in UTF-8 encoding
4. Handles BOM (Byte Order Mark) detection for Unicode files

## Architecture

HTML2MD v3.4.0 features a modern, modular architecture:

```
tools/html2md/
├── __init__.py       # Package initialization
├── __main__.py       # Entry point for module execution
├── api.py            # Programmatic API for other tools
├── cli.py            # Command-line interface
├── config/           # Configuration management
│   ├── __init__.py
│   ├── loader.py     # Config file loader
│   └── models.py     # Config data models
├── core.py           # Core conversion logic
├── extractors.py     # Custom extractor system
├── preprocessors.py  # HTML preprocessing
├── analyze_html.py   # HTML structure analysis
└── utils.py          # Utility functions

.scrapes/             # Project scrapes directory (gitignored)
└── project-name/
    ├── html/         # Raw HTML files
    ├── md/           # Converted Markdown
    └── extractors/   # Custom extractors
```

### Key Components

- **API Mode**: Use as a library in other Python projects
- **Custom Extractors**: Pluggable extractor system for site-specific logic
- **Type Safety**: Full type hints and dataclass models
- **Clean Architecture**: Separation of concerns with dependency injection
- **Async Support**: Modern async/await for high performance
- **Workflow Integration**: Organized .scrapes directory structure

## Integration with m1f

The html2md tool works well with the m1f (Make One File) tool for comprehensive
documentation handling:

1. First convert HTML files to Markdown:

   ```bash
   m1f-html2md convert ./html-docs -o ./markdown-docs
   ```

2. Then use m1f to combine the Markdown files:
   ```bash
   m1f -s ./markdown-docs -o ./combined-docs.m1f.txt \
     --separator-style Markdown
   ```

This workflow is ideal for:

- Converting documentation from HTML to Markdown format
- Consolidating documentation from multiple sources
- Preparing content for LLM context windows
- Creating searchable knowledge bases

## Performance Considerations

- For large websites with many HTML files, use the `--parallel` option
- Conversion speed depends on file size, complexity, and number of files
- Memory usage scales with file sizes when parallel processing is enabled
- The tool uses async I/O for efficient file operations

## Programmatic API

Use html2md in your Python projects:

```python
from tools.html2md.api import Html2mdConverter
from tools.html2md.config import Config
from tools.html2md.extractors import BaseExtractor
from tools.shared.colors import info, success
from pathlib import Path

# Create converter with configuration
config = Config(
    source=Path("./html"),
    destination=Path("./markdown")
)
converter = Html2mdConverter(config)

# Convert with custom extractor
converter = Html2mdConverter(
    config,
    extractor=Path("./extractors/custom_extractor.py")
)

# Or with inline extractor
class MyExtractor(BaseExtractor):
    def extract(self, soup, config=None):
        # Custom logic
        return soup

converter = Html2mdConverter(config, extractor=MyExtractor())

# Convert a single file
output_path = converter.convert_file(Path("page.html"))
success(f"Converted to: {output_path}")

# Convert entire directory
results = converter.convert_directory()
info(f"Converted {len(results)} files")
```

## Requirements and Dependencies

- Python 3.10 or newer
- Required packages:
  - beautifulsoup4: For HTML parsing
  - markdownify: For HTML to Markdown conversion
  - aiofiles: For async file operations
  - rich: For console output
  - pydantic: For configuration models
- Optional packages:
  - chardet: For encoding detection
  - pyyaml: For YAML configuration files
  - toml: For TOML configuration files

Install dependencies:

```bash
pip install beautifulsoup4 markdownify chardet pyyaml aiofiles rich pydantic
```

**Note**: For web scraping functionality, use the separate `webscraper` tool
which provides multiple backend options including HTTrack.

======= docs/03_html2md/31_html2md_guide.md ======
# HTML to Markdown Converter Guide

The `html2md` tool (v3.1.0) is a modern, async converter designed to transform
HTML content into clean Markdown format. Built with Python 3.10+ and modern
async architecture, it focuses on intelligent content extraction and conversion.

**Note:** Web scraping functionality has been moved to the separate `webscraper`
tool. Use `webscraper` to download websites, then `html2md` to convert the
downloaded HTML files.

## Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Command Line Usage](#command-line-usage)
- [Configuration](#configuration)
- [Python API](#python-api)
- [Custom Extractors](#custom-extractors)
- [Advanced Features](#advanced-features)
- [Examples](#examples)
- [Troubleshooting](#troubleshooting)

## Installation

### Python Dependencies

```bash
pip install beautifulsoup4 markdownify pydantic rich httpx chardet pyyaml aiofiles

# Optional dependencies
pip install toml      # For TOML configuration files
```

### Installation

```bash
pip install beautifulsoup4 markdownify pydantic rich chardet pyyaml aiofiles

# Optional dependencies
pip install toml      # For TOML configuration files
```

## Quick Start

### Convert a Single File

```bash
m1f-html2md convert index.html -o index.md
```

### Convert a Directory

```bash
m1f-html2md convert ./html_docs/ -o ./markdown_docs/
```

### Analyze HTML Structure

```bash
m1f-html2md analyze ./html/*.html --suggest-selectors
```

### Generate Configuration

```bash
m1f-html2md config -o config.yaml
```

## Command Line Usage

The tool provides three main commands:

### `convert` - Convert Files or Directories

```bash
m1f-html2md convert [source] -o [output] [options]

Options:
  -c, --config FILE         Configuration file (YAML format)
  --format FORMAT          Output format (markdown, m1f_bundle, json)
  --content-selector SEL    CSS selector for main content
  --ignore-selectors SEL    CSS selectors to ignore (space-separated)
  --heading-offset N        Offset heading levels by N
  --no-frontmatter         Don't add YAML frontmatter
  --parallel               Enable parallel processing
  --extractor FILE         Path to custom extractor Python file
  --log-file FILE          Log to file
  -v, --verbose            Enable verbose output
  -q, --quiet              Suppress all output except errors
```

### `analyze` - Analyze HTML Structure

```bash
m1f-html2md analyze [files] [options]

Options:
  --show-structure         Show detailed HTML structure
  --common-patterns        Find common patterns across files
  --suggest-selectors      Suggest CSS selectors (default)
  -v, --verbose            Enable verbose output
```

### `config` - Generate Configuration File

```bash
m1f-html2md config [options]

Options:
  -o, --output FILE        Output file (default: config.yaml)
  --format FORMAT          Config format (yaml, toml, json)
```

## Configuration

### Configuration File Structure

Create a `config.yaml` file:

```yaml
# Basic settings (v3.1.0 format)
source: ./html_docs
destination: ./markdown_docs
output_format: markdown

# Content extraction
extractor:
  content_selector: "article.content, main, .documentation"
  ignore_selectors:
    - nav
    - header
    - footer
    - .sidebar
    - .ads
    - "#comments"
  remove_elements:
    - script
    - style
    - iframe
  extract_metadata: true
  extract_opengraph: true

# Markdown processing
processor:
  heading_offset: 0
  add_frontmatter: true
  heading_style: atx
  link_handling: convert
  link_extensions:
    .html: .md
    .htm: .md
  normalize_whitespace: true
  fix_encoding: true

# Parallel processing
parallel: true

# Logging
verbose: false
quiet: false
log_file: ./conversion.log
```

### Configuration Options Explained

#### Extractor Configuration

- `content_selector`: CSS selector(s) to find main content
- `ignore_selectors`: Elements to remove before conversion
- `remove_elements`: HTML tags to completely remove
- `preserve_attributes`: HTML attributes to keep
- `extract_metadata`: Extract meta tags and title
- `extract_opengraph`: Extract OpenGraph metadata

#### Processor Configuration

- `heading_offset`: Adjust heading levels (e.g., h1→h2)
- `link_handling`: How to process links (convert/preserve/absolute/relative)
- `normalize_whitespace`: Clean up extra whitespace
- `fix_encoding`: Fix common encoding issues

#### Processing Configuration

- `parallel`: Enable parallel processing for multiple files
- `verbose`: Enable verbose logging
- `quiet`: Suppress all output except errors
- `log_file`: Path to log file

## Python API

### Basic Usage

```python
from tools.html2md.api import HTML2MDConverter
import asyncio

# Create converter with configuration
converter = HTML2MDConverter(
    outermost_selector="main",
    ignore_selectors=["nav", "footer"],
    add_frontmatter=True
)

# Convert a directory (async)
results = asyncio.run(converter.convert_directory("./html", "./markdown"))

# Convert a single file (async)
result = asyncio.run(converter.convert_file("index.html"))

# Convert with custom extractor
from pathlib import Path

converter = HTML2MDConverter(
    outermost_selector="main",
    extractor=Path("./extractors/custom_extractor.py")
)

result = asyncio.run(converter.convert_file("index.html"))
```

### Advanced Configuration

```python
from tools.html2md.config.models import HTML2MDConfig

# Create configuration with v3.1.0 models
config = HTML2MDConfig(
    source_dir="./html",
    destination_dir="./output",
    outermost_selector="div.documentation",
    ignore_selectors=[".nav-menu", ".footer"],
    strip_attributes=True,
    heading_offset=1,
    add_frontmatter=True,
    parallel=True,
    max_workers=4
)

converter = HTML2MDConverter.from_config(config)
```

### Convenience Functions

```python
from tools.html2md.api import convert_file, convert_directory
import asyncio

# Simple file conversion (async)
result = asyncio.run(convert_file("page.html", destination="page.md"))

# Directory conversion with options (async)
results = asyncio.run(convert_directory(
    source="./html",
    destination="./markdown",
    outermost_selector="article",
    parallel=True
))
```

## Custom Extractors

The custom extractor system allows you to create site-specific content
extraction logic:

### Function-based Extractor

```python
# extractors/my_extractor.py
from bs4 import BeautifulSoup

def extract(soup: BeautifulSoup, config=None):
    """Extract main content."""
    # Custom extraction logic
    main = soup.find('main')
    if main:
        new_soup = BeautifulSoup('<html><body></body></html>', 'html.parser')
        new_soup.body.append(main)
        return new_soup
    return soup

def postprocess(markdown: str, config=None):
    """Clean up converted markdown."""
    import re
    return re.sub(r'\n{3,}', '\n\n', markdown)
```

### Using Custom Extractors

```bash
m1f-html2md convert ./html -o ./markdown \
  --extractor ./extractors/my_extractor.py
```

## Advanced Features

### Content Extraction with CSS Selectors

Target specific content areas:

```yaml
extractor:
  content_selector: |
    article.post-content,
    div.documentation-body,
    main[role="main"],
    #content:not(.sidebar)
```

### Link Handling Strategies

1. **Convert**: Change `.html` to `.md`

   ```yaml
   processor:
     link_handling: convert
     link_extensions:
       .html: .md
       .php: .md
   ```

2. **Preserve**: Keep original links

   ```yaml
   processor:
     link_handling: preserve
   ```

3. **Absolute**: Make all links absolute
   ```yaml
   processor:
     link_handling: absolute
   ```

### Metadata Extraction

The tool can extract and preserve:

- Page title
- Meta description
- OpenGraph data
- Schema.org structured data
- Custom meta tags

### m1f Bundle Creation

Generate m1f bundles directly:

```yaml
output_format: m1f_bundle
m1f:
  create_bundle: true
  bundle_name: my-documentation
  include_assets: true
  generate_index: true
  metadata:
    project: My Project Docs
    version: 1.0.0
```

## Examples

### Example 1: Convert Documentation Site

```bash
# Create configuration
cat > docs-config.yaml << EOF
source: ./python-docs-html
destination: ./python-docs-md
extractor:
  content_selector: "div.document"
  ignore_selectors:
    - ".sphinxsidebar"
    - ".related"
processor:
  heading_offset: 1
  add_frontmatter: true
parallel: true
EOF

# Run conversion
m1f-html2md convert ./python-docs-html -o ./python-docs-md -c docs-config.yaml
```

### Example 2: Convert Blog with Specific Content

```python
from tools.html2md.api import HTML2MDConverter
import asyncio

converter = HTML2MDConverter(
    outermost_selector="article.post",
    ignore_selectors=[
        ".post-navigation",
        ".comments-section",
        ".social-share"
    ],
    add_frontmatter=True,
    heading_offset=0
)

# Convert all blog posts (async)
results = asyncio.run(converter.convert_directory(
    "./blog-html",
    "./blog-markdown"
))
```

### Example 3: Create m1f Bundle from HTML

```bash
# First download the website using webscraper
m1f-scrape https://docs.example.com -o ./html

# Then convert to m1f bundle
m1f-html2md convert ./html \
  -o ./output.m1f \
  --format m1f_bundle \
  --content-selector "main.content" \
  --ignore-selectors nav footer
```

## Troubleshooting

### Common Issues

1. **Content selector not matching**

   ```
   WARNING: Content selector 'article' not found
   ```

   Solution: Use the analyze command to find the right selectors:

   ```bash
   m1f-html2md analyze ./html/*.html --suggest-selectors
   ```

2. **Encoding issues**

   ```
   UnicodeDecodeError: 'utf-8' codec can't decode
   ```

   Solution: The tool auto-detects encoding, but HTML files may have mixed
   encodings. All output is converted to UTF-8.

3. **Large directories timing out**

   Solution: Use parallel processing:

   ```bash
   m1f-html2md convert ./html -o ./md --parallel
   ```

4. **Missing content after conversion**

   Solution: Check your ignore selectors - they may be too broad:

   ```bash
   m1f-html2md convert ./html -o ./md \
     --content-selector "body" \
     --ignore-selectors .ads .cookie-notice
   ```

### Debug Mode

Enable verbose logging for debugging:

```bash
m1f-html2md convert ./html -o ./md -v --log-file debug.log
```

Or in configuration:

```yaml
verbose: true
log_file: ./conversion-debug.log
```

### Performance Tips

1. **Use parallel processing** for large directories:

   ```yaml
   parallel: true
   ```

2. **Target specific content** to reduce processing:

   ```yaml
   extractor:
     content_selector: "article.documentation"
   ```

3. **Use custom extractors** for complex sites to optimize extraction

## Integration with m1f

The converted Markdown files are optimized for m1f bundling:

1. Clean, consistent formatting
2. Preserved metadata in frontmatter
3. Proper link structure
4. UTF-8 encoding

To create an m1f bundle after conversion:

```bash
# Download website first
m1f-scrape https://docs.example.com -o ./html/

# Convert to Markdown
m1f-html2md convert ./html/ -o ./docs/

# Create m1f bundle
m1f -s ./docs/ -o documentation.m1f.txt
```

Or convert directly to m1f bundle format:

```bash
m1f-html2md convert ./html/ \
  -o ./docs.m1f \
  --format m1f_bundle
```

======= docs/03_html2md/32_html2md_workflow_guide.md ======
# HTML2MD Workflow Guide

This guide explains the recommended workflow for converting websites to Markdown
using html2md with custom extractors.

## Overview

The html2md tool now supports a flexible workflow that separates concerns:

1. HTML acquisition (scraping or external)
2. Content analysis and extractor development
3. Conversion with site-specific extraction

## Directory Structure

All scraping projects use the `.scrapes` directory (gitignored):

```
.scrapes/
└── project-name/
    ├── html/         # Raw HTML files
    ├── md/           # Converted Markdown files
    └── extractors/   # Custom extraction scripts
```

## Complete Workflow

### Step 1: Set Up Project Structure

```bash
# Create project directories
mkdir -p .scrapes/my-docs/{html,md,extractors}
```

### Step 2: Acquire HTML Content

You have several options:

#### Option A: Use webscraper tool

```bash
m1f-scrape https://example.com \
  -o .scrapes/my-docs/html \
  --max-pages 50 \
  --scraper playwright
```

#### Option B: Manual download

- Save HTML files directly to `.scrapes/my-docs/html/`
- Use browser "Save As" or wget/curl
- Any method that gets HTML files

#### Option C: External scraping

- Use any scraping tool you prefer
- Just ensure HTML files end up in the html/ directory

### Step 3: Analyze HTML Structure (Optional)

Understand the HTML structure before creating extractors:

```bash
# Analyze a few sample files
m1f-html2md analyze \
  .scrapes/my-docs/html/*.html \
  --suggest-selectors

# Get detailed structure analysis
m1f-html2md analyze \
  .scrapes/my-docs/html/*.html \
  --show-structure \
  --common-patterns
```

### Step 4: Create Custom Extractor (Optional)

#### Manual Creation

Create `.scrapes/my-docs/extractors/custom_extractor.py`:

```python
from bs4 import BeautifulSoup
from typing import Optional, Dict, Any

def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    """Extract main content from HTML."""
    # Remove site-specific navigation
    for selector in ['nav', '.sidebar', '#header', '#footer']:
        for elem in soup.select(selector):
            elem.decompose()

    # Find main content area
    main = soup.find('main') or soup.find('article') or soup.find('.content')
    if main:
        # Create clean soup with just main content
        new_soup = BeautifulSoup('<html><body></body></html>', 'html.parser')
        new_soup.body.append(main)
        return new_soup

    return soup

def postprocess(markdown: str, config: Optional[Dict[str, Any]] = None) -> str:
    """Clean up converted markdown."""
    lines = markdown.split('\n')
    cleaned = []

    for line in lines:
        # Remove "Copy" buttons before code blocks
        if line.strip() == 'Copy':
            continue
        cleaned.append(line)

    return '\n'.join(cleaned)
```

#### Claude-Assisted Creation

Use Claude to analyze HTML and create a custom extractor:

```bash
# Have Claude analyze the HTML structure
claude -p "Analyze these HTML files and create a custom extractor for html2md. \
The extractor should:
1. Remove all navigation, headers, footers, and sidebars
2. Extract only the main content
3. Clean up any site-specific artifacts in the markdown
4. Handle the specific structure of this website

Write the extractor to .scrapes/my-docs/extractors/custom_extractor.py" \
--files .scrapes/my-docs/html/*.html
```

### Step 5: Convert HTML to Markdown

#### With Custom Extractor

```bash
cd .scrapes/my-docs
m1f-html2md convert html -o md \
  --extractor extractors/custom_extractor.py
```

#### With Default Extractor

```bash
cd .scrapes/my-docs
m1f-html2md convert html -o md
```

#### With CSS Selectors Only

```bash
cd .scrapes/my-docs
m1f-html2md convert html -o md \
  --content-selector "main.content" \
  --ignore-selectors "nav" ".sidebar" ".ads"
```

### Step 6: Review and Refine

1. Check the converted Markdown files
2. If quality needs improvement:
   - Update the custom extractor
   - Re-run the conversion
   - Iterate until satisfied

## Example: Documentation Site

Here's a complete example for converting a documentation site:

```bash
# 1. Setup
mkdir -p .scrapes/docs-site/{html,md,extractors}

# 2. Download documentation
m1f-scrape https://docs.example.com \
  -o .scrapes/docs-site/html \
  --max-pages 100 \
  --scraper playwright

# 3. Analyze structure
m1f-html2md analyze \
  .scrapes/docs-site/html/*.html \
  --suggest-selectors

# 4. Create extractor for docs site
cat > .scrapes/docs-site/extractors/docs_extractor.py << 'EOF'
from bs4 import BeautifulSoup
from typing import Optional, Dict, Any

def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    # Remove docs-specific elements
    for selector in [
        '.docs-nav', '.docs-sidebar', '.docs-header',
        '.docs-footer', '.edit-page', '.feedback',
        '[class*="navigation"]', '[id*="toc"]'
    ]:
        for elem in soup.select(selector):
            elem.decompose()

    # Extract article content
    article = soup.find('article') or soup.find('.docs-content')
    if article:
        new_soup = BeautifulSoup('<html><body></body></html>', 'html.parser')
        new_soup.body.append(article)
        return new_soup

    return soup

def postprocess(markdown: str, config: Optional[Dict[str, Any]] = None) -> str:
    # Clean up docs-specific patterns
    import re

    # Remove "Copy" buttons
    markdown = re.sub(r'^Copy\s*\n', '', markdown, flags=re.MULTILINE)

    # Remove "On this page" sections
    markdown = re.sub(r'^On this page.*?(?=^#|\Z)', '', markdown,
                      flags=re.MULTILINE | re.DOTALL)

    return markdown.strip()
EOF

# 5. Convert with custom extractor
cd .scrapes/docs-site
m1f-html2md convert html -o md \
  --extractor extractors/docs_extractor.py

# 6. Create m1f bundle (optional)
m1f -s md -o docs-bundle.txt
```

## Best Practices

### 1. Start Small

- Test with a few HTML files first
- Refine the extractor before processing everything

### 2. Iterative Development

- Create basic extractor
- Convert a sample
- Identify issues
- Update extractor
- Repeat until satisfied

### 3. Extractor Tips

- Use specific CSS selectors for the site
- Remove navigation early in extraction
- Handle site-specific patterns in postprocess
- Test with different page types

### 4. Organization

- Keep each project in its own directory
- Document site-specific quirks
- Save working extractors for reuse

### 5. Performance

- Use `--parallel` for large conversions
- Process in batches if needed
- Monitor memory usage

## Troubleshooting

### Common Issues

**Issue**: Navigation elements still appear in Markdown

- **Solution**: Add more specific selectors to the extractor
- Check for dynamic class names or IDs

**Issue**: Missing content

- **Solution**: Verify content selector is correct
- Check if content is loaded dynamically (use playwright scraper)

**Issue**: Broken formatting

- **Solution**: Adjust extraction logic
- Use postprocess to fix patterns

**Issue**: Encoding errors

- **Solution**: Ensure HTML files are UTF-8
- Use `--target-encoding utf-8` if needed

### Debug Tips

1. **Test extractor standalone**:

```python
from bs4 import BeautifulSoup
from pathlib import Path
from tools.shared.colors import info

# Load your extractor
import sys
sys.path.append('.scrapes/my-docs/extractors')
import custom_extractor

# Test on single file
html = Path('.scrapes/my-docs/html/sample.html').read_text()
soup = BeautifulSoup(html, 'html.parser')
result = custom_extractor.extract(soup)
info(result.prettify())
```

2. **Use verbose mode**:

```bash
m1f-html2md convert html -o md \
  --extractor extractors/custom_extractor.py \
  --verbose
```

3. **Process single file**:

```bash
m1f-html2md convert html/single-file.html \
  -o test.md \
  --extractor extractors/custom_extractor.py
```

## Advanced Techniques

### Multi-Stage Extraction

For complex sites, use multiple extraction stages:

```python
def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    # Stage 1: Remove obvious non-content
    remove_selectors = ['script', 'style', 'nav', 'header', 'footer']
    for selector in remove_selectors:
        for elem in soup.select(selector):
            elem.decompose()

    # Stage 2: Find content container
    container = soup.select_one('.main-container') or soup.body

    # Stage 3: Clean within container
    for elem in container.select('.ads, .social-share, .related'):
        elem.decompose()

    # Stage 4: Extract final content
    content = container.select_one('article') or container

    new_soup = BeautifulSoup('<html><body></body></html>', 'html.parser')
    new_soup.body.append(content)
    return new_soup
```

### Conditional Extraction

Handle different page types:

```python
def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    # Detect page type
    if soup.find('article', class_='blog-post'):
        return extract_blog_post(soup)
    elif soup.find('div', class_='documentation'):
        return extract_documentation(soup)
    elif soup.find('div', class_='api-reference'):
        return extract_api_reference(soup)
    else:
        return extract_generic(soup)
```

### Metadata Preservation

Keep important metadata:

```python
def extract(soup: BeautifulSoup, config: Optional[Dict[str, Any]] = None) -> BeautifulSoup:
    # Preserve title
    title = soup.find('title')

    # Extract content
    content = soup.find('main')

    # Create new soup with metadata
    new_soup = BeautifulSoup('<html><head></head><body></body></html>', 'html.parser')
    if title:
        new_soup.head.append(title)
    if content:
        new_soup.body.append(content)

    return new_soup
```

## Conclusion

The html2md workflow provides maximum flexibility:

- Separate HTML acquisition from conversion
- Site-specific extractors for optimal results
- Iterative refinement process
- Integration with other tools (webscraper, m1f)

This approach ensures you can handle any website structure and produce clean,
readable Markdown output.

======= docs/03_html2md/33_html2md_test_suite.md ======
# HTML2MD Test Suite Documentation

A comprehensive test suite for validating the html2md converter (v2.0.0) with
challenging real-world HTML structures.

## Overview

The HTML2MD test suite provides a robust testing framework consisting of:

- A Flask-based web server serving complex HTML test pages
- Comprehensive pytest test cases covering all conversion features including
  async operations
- Real-world documentation examples with challenging HTML structures
- Automated test runner with coverage reporting
- Full support for testing async/await patterns and parallel processing

## Architecture

```
tests/
├── html2md_server/
│   ├── server.py              # Flask test server
│   ├── requirements.txt       # Test suite dependencies
│   ├── run_tests.sh          # Automated test runner
│   ├── README.md             # Test suite documentation
│   ├── static/
│   │   ├── css/
│   │   │   └── modern.css    # Modern CSS with dark mode
│   │   └── js/
│   │       └── main.js       # Interactive features
│   └── test_pages/
│       ├── index.html        # Test suite homepage
│       ├── m1f-documentation.html
│       ├── html2md-documentation.html
│       ├── complex-layout.html
│       ├── code-examples.html
│       └── ...               # Additional test pages
└── test_html2md_server.py    # Pytest test cases
```

## Test Server

### Features

- Modern Flask-based web server
- RESTful API endpoints for test page discovery
- CORS enabled for cross-origin testing
- Dynamic page generation support
- Static asset serving with proper MIME types

### Running the Server

```bash
# Start server on default port 8080
python tests/html2md_server/server.py

# Server provides:
# - http://localhost:8080/            # Test suite homepage
# - http://localhost:8080/page/{name} # Individual test pages
# - http://localhost:8080/api/test-pages # JSON API
```

## Test Pages

### 1. M1F Documentation (`m1f-documentation.html`)

Tests real documentation conversion with:

- Complex heading hierarchies
- Code examples in multiple languages
- Nested structures and feature grids
- Command-line documentation tables
- Advanced layout with inline styles

### 2. HTML2MD Documentation (`html2md-documentation.html`)

Comprehensive documentation page testing:

- Multi-level navigation structures
- API documentation with code examples
- Complex tables and option grids
- Details/Summary elements
- Sidebar navigation

### 3. Complex Layout Test (`complex-layout.html`)

CSS layout challenges:

- **Flexbox layouts**: Multi-item flex containers
- **CSS Grid**: Complex grid with spanning items
- **Nested structures**: Up to 4 levels deep
- **Positioning**: Absolute, relative, sticky elements
- **Multi-column layouts**: CSS columns with rules
- **Masonry layouts**: Pinterest-style card layouts
- **Overflow containers**: Scrollable areas

### 4. Code Examples Test (`code-examples.html`)

Programming language support:

- **Languages tested**: Python, TypeScript, JavaScript, Bash, SQL, Go, Rust
- **Inline code**: Mixed with regular text
- **Code with special characters**: HTML entities, Unicode
- **Configuration files**: YAML, JSON examples
- **Edge cases**: Empty blocks, long lines, whitespace-only

### 5. Additional Test Pages (Planned)

- **Edge Cases**: Malformed HTML, special characters
- **Modern Features**: HTML5 elements, web components
- **Tables and Lists**: Complex nested structures
- **Multimedia**: Images, videos, iframes

## Test Suite Features

### Content Selection Testing

```python
# Test CSS selector-based extraction (v2.0.0 async API)
from tools.html2md.api import HTML2MDConverter
import asyncio

converter = HTML2MDConverter(
    outermost_selector="article",
    ignore_selectors=["nav", ".sidebar", "footer"]
)

# Async conversion
result = asyncio.run(converter.convert_file("test.html"))
```

### Code Block Detection

- Automatic language detection from class names
- Preservation of syntax highlighting hints
- Special character handling in code

### Layout Preservation

- Nested structure maintenance
- List hierarchy preservation
- Table structure conversion
- Heading level consistency

### Edge Case Handling

- Empty HTML documents
- Malformed HTML structures
- Very long lines
- Unicode and special characters
- Missing closing tags

## Running Tests

### Quick Start

```bash
# Run all tests with the automated script
./tests/html2md_server/run_tests.sh

# This will:
# 1. Install dependencies
# 2. Start the test server
# 3. Run all pytest tests
# 4. Generate coverage report
# 5. Clean up processes
```

### Manual Testing

```bash
# Install dependencies
pip install -r tests/html2md_server/requirements.txt

# Start server in one terminal
python tests/html2md_server/server.py

# Run tests in another terminal
pytest tests/test_html2md_server.py -v

# Run with coverage
pytest tests/test_html2md_server.py --cov=tools.html2md_tool --cov-report=html
```

### Test Options

```bash
# Run specific test
pytest tests/test_html2md_server.py::TestHTML2MDConversion::test_code_examples -v

# Run with detailed output
pytest tests/test_html2md_server.py -vv -s

# Run only fast tests
pytest tests/test_html2md_server.py -m "not slow"
```

## Test Coverage

### Core Features Tested

- ✅ Basic HTML to Markdown conversion
- ✅ Async I/O operations with aiofiles
- ✅ CSS selector content extraction
- ✅ Element filtering with ignore selectors
- ✅ Complex nested HTML structures
- ✅ Code block language detection
- ✅ Table conversion (simple and complex)
- ✅ List conversion (ordered, unordered, nested)
- ✅ Special characters and HTML entities
- ✅ Unicode support
- ✅ YAML frontmatter generation
- ✅ Heading level offset adjustment
- ✅ Parallel processing with asyncio
- ✅ Configuration file loading (YAML/TOML)
- ✅ CLI argument parsing
- ✅ API mode for programmatic access
- ✅ HTTrack integration (when available)
- ✅ URL conversion from lists

### Performance Testing

- Parallel conversion of multiple files
- Large file handling
- Memory usage monitoring
- Conversion speed benchmarks

## Writing New Tests

### Adding Test Pages

1. Create HTML file in `tests/html2md_server/test_pages/`
2. Register in `server.py`:
   ```python
   TEST_PAGES = {
       'your-test': {
           'title': 'Your Test Title',
           'description': 'What this tests'
       }
   }
   ```
3. Add corresponding test case

### Test Case Structure

```python
class TestYourFeature:
    async def test_your_feature(self, test_server, temp_output_dir):
        """Test description."""
        from tools.html2md.api import HTML2MDConverter

        converter = HTML2MDConverter(
            outermost_selector="main",
            ignore_selectors=["nav", "footer"],
            add_frontmatter=True
        )

        # Perform async conversion
        results = await converter.convert_directory(
            f"{test_server.base_url}/page",
            temp_output_dir
        )

        # Assert expected results
        assert len(results) > 0
```

## Continuous Integration

### GitHub Actions Integration

```yaml
# .github/workflows/test.yml
- name: Run HTML2MD Tests
  run: |
    cd tests/html2md_server
    ./run_tests.sh
```

### Local Development

```bash
# Watch mode for development
pytest-watch tests/test_html2md_server.py

# Run with debugging
pytest tests/test_html2md_server.py --pdb
```

## Troubleshooting

### Common Issues

**Server won't start**

- Check if port 8080 is already in use
- Ensure Flask dependencies are installed
- Check Python version (3.9+ required)

**Tests fail with connection errors**

- Ensure server is running
- Check firewall settings
- Verify localhost resolution

**Coverage report issues**

- Install pytest-cov: `pip install pytest-cov`
- Ensure tools.html2md module is in Python path
- For async tests, use pytest-asyncio: `pip install pytest-asyncio`

## Future Enhancements

1. **Additional Test Pages**
   - SVG content handling
   - MathML equations
   - Microdata and structured data
   - Progressive web app features
   - WebAssembly integration tests
   - Shadow DOM content extraction

2. **Test Automation**
   - Visual regression testing
   - Performance benchmarking
   - Memory leak detection
   - Cross-platform testing

3. **Enhanced Reporting**
   - HTML test reports with screenshots
   - Conversion diff visualization
   - Performance metrics dashboard

## Contributing

To contribute to the test suite:

1. Identify untested scenarios
2. Create representative HTML test pages
3. Write comprehensive test cases
4. Document the test purpose
5. Submit PR with test results

The test suite aims to cover all real-world HTML conversion scenarios to ensure
robust and reliable Markdown output.

======= docs/04_scrape/40_webscraper.md ======
# webscraper (Website Downloader)

A modern web scraping tool for downloading websites with multiple backend
options, async I/O, and intelligent crawling capabilities.

## Overview

The webscraper tool provides a robust solution for downloading websites for
offline viewing and analysis. Built with Python 3.10+ and modern async
architecture, it features pluggable scraper backends for different use cases.

**Primary Use Case**: Download online documentation to make it available to LLMs
(like Claude) for analysis and reference. The downloaded HTML files can be
converted to Markdown with html2md, then bundled into a single file with m1f for
optimal LLM context usage.

## Key Features

- **Multiple Scraper Backends**: Choose from BeautifulSoup (default), HTTrack,
  Scrapy, Playwright, or Selectolax
- **Async I/O**: High-performance concurrent downloading
- **Intelligent Crawling**: Automatically respects robots.txt, follows
  redirects, handles encoding
- **Duplicate Prevention**: Three-layer deduplication system:
  - Canonical URL checking (enabled by default)
  - Content-based deduplication (enabled by default)
  - GET parameter normalization (optional with `--ignore-get-params`)
- **Metadata Preservation**: Saves HTTP headers and metadata alongside HTML
  files
- **Domain Restriction**: Automatically restricts crawling to the starting
  domain
- **Subdirectory Restriction**: When URL contains a path, only scrapes within
  that subdirectory
- **Rate Limiting**: Configurable delays between requests
- **Progress Tracking**: Real-time download progress with file listing
- **Resume Support**: Interrupt and resume scraping sessions with SQLite
  tracking

## Quick Start

```bash
# Basic website download
m1f-scrape https://example.com -o ./downloaded_html

# Download with specific depth and page limits
m1f-scrape https://example.com -o ./html \
  --max-pages 50 \
  --max-depth 3

# Use different scraper backend
m1f-scrape https://example.com -o ./html --scraper httrack

# List downloaded files after completion (limited to 30 files for large sites)
m1f-scrape https://example.com -o ./html --list-files

# Save all scraped URLs to a file for later analysis
m1f-scrape https://example.com -o ./html --save-urls ./scraped_urls.txt

# Save list of all downloaded files to a file
m1f-scrape https://example.com -o ./html --save-files ./file_list.txt

# Resume interrupted scraping (with verbose mode to see progress)
m1f-scrape https://example.com -o ./html -v

# Force rescrape to update content (ignores cache)
m1f-scrape https://example.com -o ./html --force-rescrape

# Clear URLs and start fresh (keeps content checksums)
m1f-scrape https://example.com -o ./html --clear-urls
```

## Command Line Interface

```bash
m1f-scrape <url> -o <output> [options]
```

### Required Arguments

| Option         | Description                |
| -------------- | -------------------------- |
| `url`          | URL to start scraping from |
| `-o, --output` | Output directory           |

### Optional Arguments

| Option                  | Description                                                   | Default       |
| ----------------------- | ------------------------------------------------------------- | ------------- |
| `--scraper`             | Scraper backend to use (choices: httrack, beautifulsoup, bs4, | beautifulsoup |
|                         | selectolax, httpx, scrapy, playwright)                        |               |
| `--scraper-config`      | Path to scraper-specific config file (YAML/JSON)              | None          |
| `--max-depth`           | Maximum crawl depth                                           | 5             |
| `--max-pages`           | Maximum pages to crawl (-1 for unlimited)                     | 10000         |
| `--allowed-path`        | Restrict crawling to this path (overrides automatic)          | None          |
| `--request-delay`       | Delay between requests in seconds (for Cloudflare protection) | 15.0          |
| `--concurrent-requests` | Number of concurrent requests (for Cloudflare protection)     | 2             |
| `--user-agent`          | Custom user agent string                                      | Mozilla/5.0   |
| `--ignore-get-params`   | Ignore GET parameters in URLs (e.g., ?tab=linux)              | False         |
| `--ignore-canonical`    | Ignore canonical URL tags (checking is enabled by default)    | False         |
| `--ignore-duplicates`   | Ignore duplicate content detection (enabled by default)       | False         |
| `--clear-urls`          | Clear all URLs from database and start fresh                  | False         |
| `--force-rescrape`      | Force rescraping of all URLs (ignores cached content)         | False         |
| `--list-files`          | List all downloaded files after completion (limited display)  | False         |
| `--save-urls`           | Save all scraped URLs to a file (one per line)                | None          |
| `--save-files`          | Save list of all downloaded files to a file (one per line)    | None          |
| `-v, --verbose`         | Enable verbose output (file listing limited to 30 files)      | False         |
| `-q, --quiet`           | Suppress all output except errors                             | False         |
| `--show-db-stats`       | Show scraping statistics from the database                    | False         |
| `--show-errors`         | Show URLs that had errors during scraping                     | False         |
| `--show-scraped-urls`   | List all scraped URLs from the database                       | False         |
| `--show-sessions`       | Show all scraping sessions with basic info                    | False         |
| `--show-sessions-detailed` | Show detailed information for all sessions                 | False         |
| `--clear-session`       | Clear a specific session by ID                                | None          |
| `--clear-last-session`  | Clear the most recent scraping session                        | False         |
| `--cleanup-sessions`    | Clean up orphaned sessions from crashes                       | False         |
| `--version`             | Show version information and exit                             | -             |

## Scraper Backends

### BeautifulSoup (default)

- **Best for**: General purpose scraping, simple websites
- **Features**: Fast HTML parsing, good encoding detection
- **Limitations**: No JavaScript support

```bash
m1f-scrape https://example.com -o ./html --scraper beautifulsoup
```

### HTTrack

- **Best for**: Complete website mirroring, preserving structure
- **Features**: External links handling, advanced mirroring options
- **Limitations**: Requires HTTrack to be installed separately

```bash
m1f-scrape https://example.com -o ./html --scraper httrack
```

### Scrapy

- **Best for**: Large-scale crawling, complex scraping rules
- **Features**: Advanced crawling settings, middleware support
- **Limitations**: More complex configuration

```bash
m1f-scrape https://example.com -o ./html --scraper scrapy
```

### Playwright

- **Best for**: JavaScript-heavy sites, SPAs
- **Features**: Full browser automation, JavaScript execution
- **Limitations**: Slower, requires more resources

```bash
m1f-scrape https://example.com -o ./html --scraper playwright
```

### Selectolax

- **Best for**: Speed-critical applications
- **Features**: Fastest HTML parsing, minimal overhead
- **Limitations**: Basic feature set

```bash
m1f-scrape https://example.com -o ./html --scraper selectolax
```

## Usage Examples

### Basic Website Download

```bash
# Download a simple website
m1f-scrape https://docs.example.com -o ./docs_html

# Download with verbose output
m1f-scrape https://docs.example.com -o ./docs_html -v
```

### Canonical URL Checking

By default, the scraper checks for canonical URLs to avoid downloading duplicate
content:

```bash
# Pages with different canonical URLs are automatically skipped
m1f-scrape https://example.com -o ./html

# Ignore canonical tags if you want all page versions
m1f-scrape https://example.com -o ./html --ignore-canonical
```

When enabled (default), the scraper:

- Checks the `<link rel="canonical">` tag on each page
- Skips pages where the canonical URL differs from the current URL
- Prevents downloading duplicate content (e.g., print versions, mobile versions)
- Logs skipped pages with their canonical URLs for transparency

This is especially useful for sites that have multiple URLs pointing to the same
content.

### Content Deduplication

By default, the scraper detects and skips pages with duplicate content based on
text-only checksums:

```bash
# Content deduplication is enabled by default
m1f-scrape https://example.com -o ./html

# Disable content deduplication if needed
m1f-scrape https://example.com -o ./html --ignore-duplicates
```

This feature:

- Enabled by default to avoid downloading duplicate content
- Extracts plain text from HTML (removes all tags, scripts, styles)
- Calculates SHA-256 checksum of the normalized text
- Skips pages with identical text content
- Useful for sites with multiple URLs serving the same content
- Works together with canonical URL checking for thorough deduplication

The scraper now has three levels of duplicate prevention, applied in this order:

1. **GET parameter normalization** (default: disabled) - Use
   `--ignore-get-params` to enable
2. **Canonical URL checking** (default: enabled) - Respects
   `<link rel="canonical">`
3. **Content deduplication** (default: enabled) - Compares text content

**Important**: All deduplication data is stored in the SQLite database
(`scrape_tracker.db`), which means:

- Content checksums persist across resume operations
- Canonical URL information is saved for each page
- The deduplication works correctly even when resuming interrupted scrapes
- Memory-efficient: checksums are queried from database, not loaded into memory
- Scales to large websites without excessive memory usage

### Subdirectory Restriction

When you specify a URL with a path, the scraper automatically restricts crawling
to that subdirectory:

```bash
# Only scrape pages under /docs subdirectory
m1f-scrape https://example.com/docs -o ./docs_only

# Only scrape API documentation pages
m1f-scrape https://api.example.com/v2/reference -o ./api_docs

# This will NOT scrape /products, /blog, etc. - only /tutorials/*
m1f-scrape https://learn.example.com/tutorials -o ./tutorials_only
```

### Advanced Path Control with --allowed-path

Sometimes you need to start from a specific page but allow crawling in a different directory. 
Use `--allowed-path` to override the automatic path restriction:

```bash
# Start from extensions index but allow crawling all extensions
m1f-scrape https://ezpublishdoc.mugo.ca/Extensions/eZ-Publish-extensions.html -o ./extensions \
  --allowed-path /Extensions/

# Start from a deep nested page but allow broader documentation crawling
m1f-scrape https://docs.example.com/v2/api/users/create.html -o ./api_docs \
  --allowed-path /v2/api/

# Start from main docs page but restrict to specific section
m1f-scrape https://docs.example.com/index.html -o ./guides \
  --allowed-path /guides/
```

The start URL is always scraped regardless of path restrictions, making it perfect for
documentation sites where the index page links to content in different directories.

### Controlled Crawling

```bash
# Limit crawl depth for shallow scraping
m1f-scrape https://blog.example.com -o ./blog \
  --max-depth 2 \
  --max-pages 20

# Unlimited scraping (use with caution!)
m1f-scrape https://docs.example.com -o ./docs \
  --max-pages -1 \
  --request-delay 2.0

# Slow crawling to be respectful
m1f-scrape https://example.com -o ./html \
  --request-delay 2.0 \
  --concurrent-requests 2

# Start from specific page but allow broader crawling area
m1f-scrape https://docs.example.com/api/index.html -o ./api_docs \
  --allowed-path /api/ \
  --max-pages 100
```

### Custom Configuration

```bash
# Use custom user agent
m1f-scrape https://example.com -o ./html \
  --user-agent "MyBot/1.0 (Compatible)"

# Use scraper-specific configuration
m1f-scrape https://example.com -o ./html \
  --scraper scrapy \
  --scraper-config ./scrapy-settings.yaml
```

## Session Management

m1f-scrape tracks each scraping run as a session with full statistics and state management.

### Session Tracking

Every scraping run creates a session with:
- Unique session ID
- Start/end timestamps  
- Configuration parameters used
- Success/failure statistics
- Session status (running, completed, interrupted, failed)

### View Sessions

```bash
# Show all sessions with basic info
m1f-scrape --show-sessions -o ./html

# Show detailed session information
m1f-scrape --show-sessions-detailed -o ./html

# Example output:
ID  | Status    | Started             | Pages | Success | Failed | URL
----------------------------------------------------------------------------------------------------
3   | completed | 2025-08-03 14:23:12 | 142   | 140     | 2      | https://docs.example.com
2   | interrupted| 2025-08-03 13:45:00 | 45    | 45      | 0      | https://api.example.com/v2
1   | completed | 2025-08-03 12:00:00 | 250   | 248     | 2      | https://example.com
```

### Clean Up Sessions

```bash
# Clear the most recent session (database only, asks about files)
m1f-scrape --clear-last-session -o ./html

# Clear session and automatically delete files (no prompt)
m1f-scrape --clear-last-session --delete-files -o ./html

# Clear a specific session by ID (asks about files)
m1f-scrape --clear-session 2 -o ./html

# Clear session 2 and delete files without confirmation
m1f-scrape --clear-session 2 --delete-files -o ./html

# Clean up orphaned sessions (from crashes)
m1f-scrape --cleanup-sessions -o ./html
```

#### File Deletion Behavior

When clearing sessions, the scraper will:
1. **Always delete** database entries (URLs, checksums, session records)
2. **Optionally delete** downloaded HTML files and metadata files
3. **Ask for confirmation** by default when files would be deleted
4. **Skip confirmation** if `--delete-files` flag is provided

This allows you to:
- Keep downloaded files while cleaning the database
- Fully clean up both database and files
- Automate cleanup in scripts with `--delete-files`

### Automatic Cleanup

The scraper automatically:
- Detects sessions left in 'running' state from crashes
- Marks sessions as 'interrupted' if no URLs have been scraped for >1 hour
- Preserves statistics for interrupted sessions
- Does NOT interrupt long-running active sessions (they can run for many hours)

### Session Recovery

If a process is killed (kill -9, system crash, etc.), the session will be left in 'running' state. On the next run:

1. **Automatic cleanup**: Sessions older than 1 hour are automatically marked as interrupted
2. **Manual cleanup**: Use `--cleanup-sessions` to manually review and clean up
3. **Resume capability**: The scraping can still resume from where it left off

```bash
# After a crash, cleanup and resume
m1f-scrape --cleanup-sessions -o ./html
m1f-scrape https://example.com -o ./html  # Resumes from last position
```

## Scraping Summary and Statistics

After each scraping session, m1f-scrape displays a comprehensive summary with:

- **Session ID**: Unique identifier for this scraping run
- **Success metrics**: Number of successfully scraped pages
- **Error count**: Number of failed page downloads
- **Success rate**: Percentage of successful downloads
- **Time statistics**: Total duration and average time per page
- **File counts**: Number of HTML files saved

Example output:
```
============================================================
Scraping Summary (Session #3)
============================================================
✓ Successfully scraped 142 pages
⚠ Failed to scrape 3 pages
Total URLs processed: 145
Success rate: 97.9%
Total duration: 435.2 seconds
Average time per page: 3.00 seconds
Output directory: ./html/example.com
HTML files saved in this session: 142

Session ID: #3
To clear this session: m1f-scrape --clear-session 3 -o ./html
```

## Output Structure

Downloaded files are organized to mirror the website structure:

```
output_directory/
├── scrape_tracker.db         # SQLite database for resume functionality
├── example.com/
│   ├── index.html
│   ├── index.meta.json
│   ├── about/
│   │   ├── index.html
│   │   └── index.meta.json
│   ├── blog/
│   │   ├── post1/
│   │   │   ├── index.html
│   │   │   └── index.meta.json
│   │   └── post2/
│   │       ├── index.html
│   │       └── index.meta.json
│   └── contact/
│       ├── index.html
│       └── index.meta.json
```

### Metadata Files

Each HTML file has an accompanying `.meta.json` file containing:

```json
{
  "url": "https://example.com/about/",
  "title": "About Us - Example",
  "encoding": "utf-8",
  "status_code": 200,
  "headers": {
    "Content-Type": "text/html; charset=utf-8",
    "Last-Modified": "2024-01-15T10:30:00Z"
  },
  "metadata": {
    "description": "Learn more about Example company",
    "og:title": "About Us",
    "canonical": "https://example.com/about/"
  }
}
```

## Integration with m1f Workflow

webscraper is designed as the first step in a workflow to provide documentation
to LLMs:

```bash
# Step 1: Download documentation website
m1f-scrape https://docs.example.com -o ./html_files

# Step 2: Analyze HTML structure
m1f-html2md analyze ./html_files/*.html --suggest-selectors

# Step 3: Convert to Markdown
m1f-html2md convert ./html_files -o ./markdown \
  --content-selector "main.content" \
  --ignore-selectors "nav" ".sidebar"

# Step 4: Bundle for LLM consumption
m1f -s ./markdown -o ./docs_bundle.txt \
  --remove-scraped-metadata

# Now docs_bundle.txt contains all documentation in a single file
# that can be provided to Claude or other LLMs for analysis
```

### Complete Documentation Download Example

```bash
# Download React documentation for LLM analysis
m1f-scrape https://react.dev/learn -o ./react_docs \
  --max-pages 100 \
  --max-depth 3

# Convert to clean Markdown
m1f-html2md convert ./react_docs -o ./react_md \
  --content-selector "article" \
  --ignore-selectors "nav" "footer" ".sidebar"

# Create single file for LLM
m1f -s ./react_md -o ./react_documentation.txt

# Now you can provide react_documentation.txt to Claude:
# "Here is the React documentation: <contents of react_documentation.txt>"
```

## Resume Functionality

The scraper supports interrupting and resuming downloads, making it ideal for
large websites or unreliable connections.

### How It Works

- **SQLite Database**: Creates `scrape_tracker.db` in the output directory to
  track:
  - URL of each scraped page
  - HTTP status code and target filename
  - Timestamp and error messages (if any)
- **Progress Display**: Shows real-time progress in verbose mode:
  ```
  Processing: https://example.com/page1 (page 1)
  Processing: https://example.com/page2 (page 2)
  ```
- **Graceful Interruption**: Press Ctrl+C to interrupt cleanly:
  ```
  Press Ctrl+C to interrupt and resume later
  ^C
  ⚠️  Scraping interrupted by user
  Run the same command again to resume where you left off
  ```

### Resume Example

```bash
# Start scraping with verbose mode
m1f-scrape https://docs.example.com -o ./docs --max-pages 100 -v

# Interrupt with Ctrl+C when needed
# Resume by running the exact same command:
m1f-scrape https://docs.example.com -o ./docs --max-pages 100 -v

# You'll see:
# Resuming crawl - found 25 previously scraped URLs
# Populating queue from previously scraped pages...
# Found 187 URLs to visit after analyzing scraped pages
# Processing: https://docs.example.com/new-page (page 26)
```

### Overriding Resume Behavior

You can override the resume functionality using the new flags:

```bash
# Force rescraping all pages even if already in database
m1f-scrape https://docs.example.com -o ./docs --force-rescrape

# Clear all URLs and start from the beginning
m1f-scrape https://docs.example.com -o ./docs --clear-urls

# Both together for a complete fresh start
m1f-scrape https://docs.example.com -o ./docs --clear-urls --force-rescrape
```

### Database Inspection

```bash
# Show scraping statistics
m1f-scrape -o docs/ --show-db-stats

# View all scraped URLs with status codes
m1f-scrape -o docs/ --show-scraped-urls

# Check for errors
m1f-scrape -o docs/ --show-errors

# Combine multiple queries
m1f-scrape -o docs/ --show-db-stats --show-errors
```

## Force Rescraping and Clearing URLs

The scraper provides two options for managing cached content and URLs in the database:

### --clear-urls: Start Fresh

The `--clear-urls` option removes all URL tracking from the database while preserving content checksums:

```bash
# Clear all URLs and start a fresh scrape
m1f-scrape https://docs.example.com -o ./docs --clear-urls

# This will:
# - Remove all URL records from the database
# - Keep content checksums for deduplication
# - Start scraping from the beginning
```

**Use cases:**
- Website structure has changed significantly
- Want to re-crawl all pages without resetting content deduplication
- Need to update navigation paths while avoiding duplicate content

### --force-rescrape: Ignore Cached Content

The `--force-rescrape` option forces the scraper to re-download all pages, ignoring the cache:

```bash
# Force rescraping all pages (ignores cache)
m1f-scrape https://docs.example.com -o ./docs --force-rescrape

# Combine with clear-urls for complete reset
m1f-scrape https://docs.example.com -o ./docs --clear-urls --force-rescrape
```

**Use cases:**
- Content has been updated on the website
- Need fresh copies of all pages
- Want to override resume functionality temporarily

### Interaction with Content Checksums

Content checksums are preserved even when using `--clear-urls`, which means:

```bash
# First scrape - downloads all content
m1f-scrape https://example.com -o ./html

# Clear URLs but keep checksums
m1f-scrape https://example.com -o ./html --clear-urls

# Second scrape - URLs are re-crawled but duplicate content is still detected
# Pages with identical text content will be skipped based on checksums
```

To completely reset everything including checksums:

```bash
# Option 1: Delete the database file
rm ./html/scrape_tracker.db
m1f-scrape https://example.com -o ./html

# Option 2: Use both flags together
m1f-scrape https://example.com -o ./html --clear-urls --force-rescrape
```

### Examples of Force Rescraping Scenarios

#### Scenario 1: Documentation Update
```bash
# Initial scrape of documentation
m1f-scrape https://docs.framework.com -o ./docs_v1

# Framework releases new version with updated docs
# Force rescrape to get all updated content
m1f-scrape https://docs.framework.com -o ./docs_v2 --force-rescrape
```

#### Scenario 2: Partial Scrape Recovery
```bash
# Scrape was interrupted or had errors
m1f-scrape https://large-site.com -o ./site --max-pages 1000

# Clear URLs and try again with different settings
m1f-scrape https://large-site.com -o ./site \
  --clear-urls \
  --max-pages 500 \
  --request-delay 30
```

#### Scenario 3: Testing Different Scraper Backends
```bash
# Try with BeautifulSoup first
m1f-scrape https://complex-site.com -o ./test --max-pages 10

# Site has JavaScript - clear and try with Playwright
m1f-scrape https://complex-site.com -o ./test \
  --clear-urls \
  --scraper playwright \
  --max-pages 10
```

## Best Practices

1. **Respect robots.txt**: The tool automatically respects robots.txt files
2. **Use appropriate delays**: Set `--request-delay` to avoid overwhelming
   servers (default: 15 seconds)
3. **Limit concurrent requests**: Use `--concurrent-requests` responsibly
   (default: 2 connections)
4. **Test with small crawls**: Start with `--max-pages 10` to test your settings
5. **Check output**: Use `--list-files` to verify what was downloaded (limited to 30 files for large sites)
6. **Save URLs for analysis**: Use `--save-urls` to keep a record of all scraped URLs
7. **Track downloaded files**: Use `--save-files` to maintain a list of all downloaded files
8. **Use verbose mode**: Add `-v` flag to see progress and resume information
9. **Keep commands consistent**: Use the exact same command to resume a session
10. **Monitor statistics**: Check the summary statistics to verify scraping efficiency

## Dealing with Cloudflare Protection

Many websites use Cloudflare or similar services to protect against bots. The
scraper now includes conservative defaults to help avoid detection:

### Default Conservative Settings

- **Request delay**: 15 seconds between requests
- **Concurrent requests**: 2 simultaneous connections
- **HTTrack backend**: Limited to 0.5 connections/second max
- **Bandwidth limiting**: 100KB/s for HTTrack backend
- **Robots.txt**: Always respected (cannot be disabled)

### For Heavy Cloudflare Protection

For heavily protected sites, manually set very conservative values:

```bash
m1f-scrape https://protected-site.com -o ./output \
  --request-delay 30 \
  --concurrent-requests 1 \
  --max-pages 50 \
  --scraper httrack
```

### Cloudflare Avoidance Tips

1. **Start conservative**: Begin with 30-60 second delays
2. **Use realistic user agents**: The default is a current Chrome browser
3. **Limit scope**: Download only what you need with `--max-pages`
4. **Single connection**: Use `--concurrent-requests 1` for sensitive sites
5. **Respect robots.txt**: Always enabled by default
6. **Add randomness**: Consider adding random delays in custom scripts

### When Cloudflare Still Blocks

If conservative settings don't work:

1. **Try Playwright backend**: Uses real browser automation

   ```bash
   m1f-scrape https://site.com -o ./output --scraper playwright
   ```

2. **Manual download**: Some sites require manual browsing
3. **API access**: Check if the site offers an API
4. **Contact site owner**: Request permission or access

## Troubleshooting

### No files downloaded

- Check if the website blocks automated access
- Try a different scraper backend
- Verify the URL is accessible

### Incomplete downloads

- Increase `--max-depth` if pages are deeply nested
- Increase `--max-pages` if hitting the limit
- Check for JavaScript-rendered content (use Playwright)

### Encoding issues

- The tool automatically detects encoding
- Check `.meta.json` files for encoding information
- Use html2md with proper encoding settings for conversion

## See Also

- [html2md Documentation](../03_html2md/30_html2md.md) - For converting
  downloaded HTML to Markdown
- [m1f Documentation](../01_m1f/00_m1f.md) - For bundling converted content for
  LLMs

======= docs/04_scrape/41_html2md_scraper_backends.md ======
# Web Scraper Backends

The HTML2MD tool supports multiple web scraping backends, each optimized for
different use cases. Choose the right backend based on your specific needs for
optimal results.

## Overview

The HTML2MD scraper backend system provides flexibility to choose the most
appropriate tool for your web scraping needs:

- **Static websites**: BeautifulSoup4 (default) - Fast and lightweight
- **Complete mirroring**: HTTrack - Professional website copying
- **JavaScript-heavy sites**: Playwright (coming soon)
- **Large-scale scraping**: Scrapy (coming soon)
- **Performance-critical**: httpx + selectolax (coming soon)

## Available Backends

### BeautifulSoup4 (Default)

BeautifulSoup4 is the default backend, ideal for scraping static HTML websites.

**Pros:**

- Easy to use and lightweight
- Fast for simple websites
- Good encoding detection
- Excellent HTML parsing capabilities

**Cons:**

- No JavaScript support
- Basic crawling capabilities
- Single-threaded by default

**Usage:**

```bash
# Default backend (no need to specify)
m1f-scrape https://example.com -o output/

# Explicitly specify BeautifulSoup
m1f-scrape https://example.com -o output/ --scraper beautifulsoup

# With custom options
m1f-scrape https://example.com -o output/ \
  --scraper beautifulsoup \
  --max-depth 3 \
  --max-pages 100 \
  --request-delay 1.0
```

### HTTrack

HTTrack is a professional website copier that creates complete offline mirrors.

**Pros:**

- Complete website mirroring
- Preserves directory structure
- Handles complex websites well
- Resume interrupted downloads
- Automatic robots.txt compliance

**Cons:**

- Requires system installation
- Less flexible for custom parsing
- Larger resource footprint

**Installation:**

```bash
# Ubuntu/Debian
sudo apt-get install httrack

# macOS
brew install httrack

# Windows
# Download from https://www.httrack.com/
```

**Usage:**

```bash
m1f-scrape https://example.com -o output/ --scraper httrack

# With HTTrack-specific options
m1f-scrape https://example.com -o output/ \
  --scraper httrack \
  --max-depth 5 \
  --concurrent-requests 8
```

## Configuration Options

### Command Line Options

Common options for all scrapers:

```bash
--scraper BACKEND           # Choose scraper backend (beautifulsoup, bs4, httrack,
                           # selectolax, httpx, scrapy, playwright)
--max-depth N               # Maximum crawl depth (default: 5)
--max-pages N               # Maximum pages to crawl (default: 10000, -1 for unlimited)
--allowed-path PATH         # Restrict crawling to this path (overrides automatic restriction)
--request-delay SECONDS     # Delay between requests (default: 15.0)
--concurrent-requests N     # Number of concurrent requests (default: 2)
--user-agent STRING         # Custom user agent
--scraper-config PATH       # Path to scraper-specific config file (YAML/JSON)
--list-files                # List all downloaded files after completion
-v, --verbose               # Enable verbose output
-q, --quiet                 # Suppress all output except errors
--version                   # Show version information
```

Note: robots.txt is always respected and cannot be disabled.

### Configuration File

You can specify scraper-specific settings in a YAML or JSON configuration file:

```yaml
# beautifulsoup-config.yaml
parser: "html.parser" # Options: "html.parser", "lxml", "html5lib"
features: "lxml"
encoding: "auto" # Or specific encoding like "utf-8"
```

```yaml
# httrack-config.yaml
mirror_options:
  - "--assume-insecure" # For HTTPS issues
  - "--robots=3" # Strict robots.txt compliance
extra_filters:
  - "+*.css"
  - "+*.js"
  - "-*.zip"
```

Use with:

```bash
m1f-scrape https://example.com -o output/ \
  --scraper beautifulsoup \
  --scraper-config beautifulsoup-config.yaml
```

### Backend-Specific Configuration

Each backend can have specific configuration options:

#### BeautifulSoup Configuration

Create a `beautifulsoup.yaml`:

```yaml
scraper_config:
  parser: "lxml" # Options: "html.parser", "lxml", "html5lib"
  features: "lxml"
  encoding: "auto" # Or specific encoding like "utf-8"
```

#### HTTrack Configuration

Create a `httrack.yaml`:

```yaml
scraper_config:
  mirror_options:
    - "--assume-insecure" # For HTTPS issues
    - "--robots=3" # Strict robots.txt compliance
  extra_filters:
    - "+*.css"
    - "+*.js"
    - "-*.zip"
```

## Use Cases and Recommendations

### Static Documentation Sites

For sites with mostly static HTML content:

```bash
m1f-scrape https://docs.example.com -o docs/ \
  --scraper beautifulsoup \
  --max-depth 10 \
  --request-delay 0.2
```

### Complete Website Backup

For creating a complete offline mirror:

```bash
m1f-scrape https://example.com -o backup/ \
  --scraper httrack \
  --max-pages 10000
```

### Rate-Limited APIs

For sites with strict rate limits:

```bash
m1f-scrape https://api.example.com/docs -o api-docs/ \
  --scraper beautifulsoup \
  --request-delay 2.0 \
  --concurrent-requests 1
```

## Troubleshooting

### BeautifulSoup Issues

**Encoding Problems:**

```bash
# Create a config file with UTF-8 encoding
echo 'encoding: utf-8' > bs-config.yaml
m1f-scrape https://example.com -o output/ \
  --scraper beautifulsoup \
  --scraper-config bs-config.yaml
```

**Parser Issues:**

```bash
# Create a config file with different parser
echo 'parser: html5lib' > bs-config.yaml
m1f-scrape https://example.com -o output/ \
  --scraper beautifulsoup \
  --scraper-config bs-config.yaml
```

### HTTrack Issues

**SSL Certificate Problems:**

```bash
# Create a config file to ignore SSL errors (use with caution)
echo 'mirror_options: ["--assume-insecure"]' > httrack-config.yaml
m1f-scrape https://example.com -o output/ \
  --scraper httrack \
  --scraper-config httrack-config.yaml
```

**Incomplete Downloads:** HTTrack creates a cache that allows resuming. Check
the `.httrack` directory in your output folder.

## Performance Comparison

| Backend       | Speed     | Memory Usage | JavaScript | Accuracy  |
| ------------- | --------- | ------------ | ---------- | --------- |
| BeautifulSoup | Fast      | Low          | No         | High      |
| HTTrack       | Medium    | Medium       | No         | Very High |
| Selectolax    | Fastest   | Very Low     | No         | Medium    |
| Scrapy        | Very Fast | Low-Medium   | No         | High      |
| Playwright    | Slow      | High         | Yes        | Very High |

## Additional Backends

### Selectolax (httpx + selectolax)

The fastest HTML parsing solution using httpx for networking and selectolax for
parsing.

**Pros:**

- Blazing fast performance (C-based parser)
- Minimal memory footprint
- Excellent for large-scale simple scraping
- Modern async HTTP/2 support

**Cons:**

- No JavaScript support
- Limited parsing features compared to BeautifulSoup
- Less mature ecosystem

**Installation:**

```bash
pip install httpx selectolax
```

**Usage:**

```bash
# Basic usage
m1f-scrape https://example.com -o output/ --scraper selectolax

# With custom configuration
m1f-scrape https://example.com -o output/ \
  --scraper selectolax \
  --concurrent-requests 20 \
  --request-delay 0.1

# Using httpx alias
m1f-scrape https://example.com -o output/ --scraper httpx
```

### Scrapy

Industrial-strength web scraping framework with advanced features.

**Pros:**

- Battle-tested in production
- Built-in retry logic and error handling
- Auto-throttle based on server response
- Extensive middleware system
- Distributed crawling support
- Advanced caching and queuing

**Cons:**

- Steeper learning curve
- Heavier than simple scrapers
- Twisted-based (different async model)

**Installation:**

```bash
pip install scrapy
```

**Usage:**

```bash
# Basic usage
m1f-scrape https://example.com -o output/ --scraper scrapy

# With auto-throttle and caching
m1f-scrape https://example.com -o output/ \
  --scraper scrapy \
  --scraper-config scrapy.yaml

# Large-scale crawling
m1f-scrape https://example.com -o output/ \
  --scraper scrapy \
  --max-pages 10000 \
  --concurrent-requests 16
```

### Playwright

Browser automation for JavaScript-heavy websites and SPAs.

**Pros:**

- Full JavaScript execution
- Handles SPAs and dynamic content
- Multiple browser engines (Chromium, Firefox, WebKit)
- Screenshot and PDF generation
- Mobile device emulation
- Network interception

**Cons:**

- High resource usage
- Slower than HTML-only scrapers
- Requires browser installation

**Installation:**

```bash
pip install playwright
playwright install  # Install browser binaries
```

**Usage:**

```bash
# Basic usage
m1f-scrape https://example.com -o output/ --scraper playwright

# With custom browser settings
m1f-scrape https://example.com -o output/ \
  --scraper playwright \
  --scraper-config playwright.yaml

# For SPA with wait conditions
m1f-scrape https://spa-example.com -o output/ \
  --scraper playwright \
  --request-delay 2.0 \
  --concurrent-requests 2
```

## API Usage

You can also use the scraper backends programmatically:

```python
import asyncio
from tools.html2md.scrapers import create_scraper, ScraperConfig

async def scrape_example():
    # Configure scraper
    config = ScraperConfig(
        max_depth=5,
        max_pages=100,
        request_delay=0.5
    )

    # Create scraper instance
    scraper = create_scraper('beautifulsoup', config)

    # Scrape single page
    async with scraper:
        page = await scraper.scrape_url('https://example.com')
        print(f"Title: {page.title}")
        print(f"Content length: {len(page.content)}")

    # Scrape entire site
    async with scraper:
        async for page in scraper.scrape_site('https://example.com'):
            print(f"Scraped: {page.url}")

# Run the example
asyncio.run(scrape_example())
```

## Contributing

To add a new scraper backend:

1. Create a new file in `tools/html2md/scrapers/`
2. Inherit from `WebScraperBase`
3. Implement required methods: `scrape_url()` and `scrape_site()`
4. Register in `SCRAPER_REGISTRY` in `__init__.py`
5. Add tests in `tests/html2md/test_scrapers.py`
6. Update this documentation

See the BeautifulSoup implementation for a complete example.

======= docs/05_development/README.md ======
# Development Documentation

This section contains guides and references for developers working on or with
the m1f toolkit.

## Contents

- [**56_git_hooks_setup.md**](./56_git_hooks_setup.md) - Git hooks for automated
  bundling

## Quick Links

- [Main m1f Documentation](../01_m1f/)
- [s1f Documentation](../02_s1f/)
- [html2md Documentation](../03_html2md/)
- [Scraper Documentation](../04_scrape/)

======= docs/05_development/56_git_hooks_setup.md ======
# m1f Git Hooks Setup Guide

This guide explains how to set up Git hooks for automatic m1f bundle generation
and code formatting in your projects.

## Overview

m1f provides two types of Git pre-commit hooks:

1. **Internal Hook** - For m1f project development

   - Formats Python files with Black
   - Formats Markdown files with Prettier
   - Runs m1f auto-bundle

2. **External Hook** - For projects using m1f
   - Runs m1f auto-bundle when `.m1f.config.yml` exists

Both hooks support Linux, macOS, and Windows platforms.

## Features

- **Automatic bundle generation** - Bundles are regenerated on every commit
- **Code formatting** (internal hook only) - Python and Markdown files are
  auto-formatted
- **Cross-platform support** - Works on Linux, macOS, and Windows
- **Fail-safe commits** - Commits are blocked if bundle generation fails
- **Auto-staging** - Modified files are automatically staged
- **Smart detection** - Automatically detects project type and suggests
  appropriate hook

## Installation

### Prerequisites

You must have m1f installed locally before setting up Git hooks:

```bash
# Clone m1f repository
git clone https://github.com/franz-agency/m1f.git
cd m1f

# Install m1f using the installation script
# Linux/macOS:
./scripts/install.sh

# Windows PowerShell:
.\scripts\install.ps1
```

### Quick Installation

#### Linux/macOS

```bash
# Run from your project directory (not the m1f directory)
bash /path/to/m1f/scripts/install-git-hooks.sh
```

#### Windows (PowerShell)

```powershell
# Run from your project directory (not the m1f directory)
& C:\path\to\m1f\scripts\install-git-hooks.ps1
```

### Installation Process

The installer will:

1. **Detect your project type**:

   - If in the m1f project: Offers both internal and external hooks
   - If in another project: Installs external hook

2. **Choose the appropriate hook**:

   - Internal: For m1f contributors (includes formatters)
   - External: For m1f users (auto-bundle only)

3. **Install platform-specific version**:
   - Linux/macOS: Bash script
   - Windows: PowerShell script with Git wrapper

### Manual Installation

If you prefer manual installation:

#### External Hook (for projects using m1f)

```bash
# Create the hook file
cat > .git/hooks/pre-commit << 'EOF'
#!/bin/bash
# m1f Git Pre-Commit Hook (External Projects)

if [ ! -f ".m1f.config.yml" ]; then
    echo "No .m1f.config.yml found. Skipping m1f auto-bundle."
    exit 0
fi

if command -v m1f-update &> /dev/null; then
    echo "Running m1f auto-bundle..."
    if m1f-update --quiet; then
        echo "✓ Auto-bundle completed"
        find . -path "*/m1f/*.txt" -type f | while read -r file; do
            git add "$file"
        done
    else
        echo "✗ Auto-bundle failed"
        exit 1
    fi
fi
exit 0
EOF

# Make it executable
chmod +x .git/hooks/pre-commit
```

## How It Works

### External Hook Workflow

1. Checks if `.m1f.config.yml` exists
2. Verifies m1f is available in PATH
3. Runs `m1f-update` to generate bundles
4. Automatically stages generated bundle files
5. Allows commit to proceed

### Internal Hook Workflow (m1f project only)

1. Formats staged Python files with Black
2. Formats staged Markdown files with Prettier
3. Runs m1f auto-bundle
4. Re-stages all modified files
5. Shows warning about modified files

## Usage Examples

### Normal Usage

```bash
# Make changes to your code
vim src/feature.py

# Stage changes
git add src/feature.py

# Commit - bundles are generated automatically
git commit -m "feat: add new feature"
```

### Skip Hook When Needed

```bash
# Skip all pre-commit hooks
git commit --no-verify -m "wip: quick save"
```

### Check What the Hook Does

```bash
# See hook output without committing
git add .
git commit --dry-run
```

## Platform-Specific Notes

### Windows

On Windows, the installer creates:

- `.git/hooks/pre-commit` - Bash wrapper for Git
- `.git/hooks/pre-commit.ps1` - PowerShell script with actual logic

Both files are needed for proper operation.

### Linux/macOS

The hook is a standard bash script that works with Git's hook system.

## Troubleshooting

### Hook Not Running

1. **Check if hook exists**:

   ```bash
   ls -la .git/hooks/pre-commit*
   ```

2. **Check if executable** (Linux/macOS):

   ```bash
   chmod +x .git/hooks/pre-commit
   ```

3. **Check Git version**:
   ```bash
   git --version  # Should be 2.9+
   ```

### m1f Command Not Found

m1f must be installed using the official installation scripts:

```bash
# Clone m1f if you haven't already
git clone https://github.com/franz-agency/m1f.git
cd m1f

# Install using the appropriate script
# Linux/macOS:
./scripts/install.sh

# Windows PowerShell:
.\scripts\install.ps1
```

The installation script will:

- Create a Python virtual environment
- Install all dependencies
- Add m1f to your PATH
- Set up command aliases

After installation, restart your terminal or reload your shell configuration:

```bash
# Linux/macOS
source ~/.bashrc  # or ~/.zshrc for zsh

# Windows PowerShell
. $PROFILE
```

### Bundle Generation Fails

1. **Run manually to see errors**:

   ```bash
   m1f-update
   ```

2. **Check config syntax**:

   ```bash
   # Validate YAML syntax
   python -c "import yaml; yaml.safe_load(open('.m1f.config.yml'))"
   ```

3. **Check file permissions**:
   ```bash
   # Ensure m1f can write to output directory
   ls -la m1f/
   ```

### Formatter Issues (Internal Hook)

**Black not found**:

```bash
pip install black
```

**Prettier not found**:

```bash
npm install -g prettier
```

## Uninstallation

### Linux/macOS

```bash
rm .git/hooks/pre-commit
```

### Windows

```powershell
Remove-Item .git\hooks\pre-commit
Remove-Item .git\hooks\pre-commit.ps1
```

## Best Practices

1. **Commit bundle files** - Include `m1f/` directory in version control
2. **Review changes** - Check bundle diffs before committing
3. **Keep bundles small** - Use focused bundles for better performance
4. **Use descriptive names** - Name bundles clearly (e.g., `api-docs`,
   `frontend-code`)
5. **Document dependencies** - Note formatter requirements in your README

## Configuration Examples

### Basic Project Setup

```yaml
# .m1f.config.yml
bundles:
  docs:
    description: "Project documentation"
    output: "m1f/docs.txt"
    sources:
      - path: "docs"
        include_extensions: [".md", ".rst"]

  code:
    description: "Source code"
    output: "m1f/code.txt"
    sources:
      - path: "src"
        include_extensions: [".py", ".js"]
```

### Advanced Setup with Groups

```yaml
# .m1f.config.yml
bundles:
  api-docs:
    description: "API documentation"
    group: "documentation"
    output: "m1f/api-docs.txt"
    sources:
      - path: "docs/api"

  api-code:
    description: "API implementation"
    group: "backend"
    output: "m1f/api-code.txt"
    sources:
      - path: "src/api"
```

## Integration with Development Tools

### VS Code

Add to `.vscode/settings.json`:

```json
{
  "git.enableCommitSigning": true,
  "files.exclude": {
    "m1f/**/*.txt": false
  }
}
```

### Pre-commit Framework

If using [pre-commit](https://pre-commit.com/):

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: m1f-bundle
        name: m1f auto-bundle
        entry: m1f-update
        language: system
        pass_filenames: false
        always_run: true
```

## CI/CD Integration

While the Git hook handles local development, you should also run m1f in CI/CD:

### GitHub Actions

```yaml
- name: Setup Python
  uses: actions/setup-python@v4
  with:
    python-version: "3.10"

- name: Clone and install m1f
  run: |
    git clone https://github.com/franz-agency/m1f.git
    cd m1f
    source ./scripts/install.sh
    cd ..

- name: Generate bundles
  run: |
    source m1f/.venv/bin/activate
    m1f-update

- name: Check for changes
  run: |
    git diff --exit-code || (echo "Bundles out of sync!" && exit 1)
```

### GitLab CI

```yaml
bundle-check:
  stage: test
  before_script:
    - git clone https://github.com/franz-agency/m1f.git
    - cd m1f && source ./scripts/install.sh && cd ..
  script:
    - source m1f/.venv/bin/activate
    - m1f-update
    - git diff --exit-code
```

## See Also

- [Auto-Bundle Guide](../01_m1f/20_auto_bundle_guide.md) - Complete auto-bundle
  documentation
- [Configuration Reference](../01_m1f/10_m1f_presets.md) - Detailed
  configuration options
- [Quick Reference](../01_m1f/99_quick_reference.md) - Common m1f commands

======= docs/06_research/README.md ======
# m1f-research Documentation

AI-powered research tool that extends m1f with intelligent web research
capabilities.

## Documentation Files

- [60_research_overview.md](60_research_overview.md) - Overview and quick start
- [62_job_management.md](62_job_management.md) - Job persistence and filtering
- [63_cli_reference.md](63_cli_reference.md) - Complete command reference
- [64_api_reference.md](64_api_reference.md) - Developer documentation
- [65_architecture.md](65_architecture.md) - Technical architecture
- [66_examples.md](66_examples.md) - Real-world usage examples
- [67_cli_improvements.md](67_cli_improvements.md) - Enhanced CLI features and
  UX

## Quick Start

```bash
# Basic research
m1f-research "python async programming"

# List all jobs
m1f-research --list-jobs

# Resume a job
m1f-research --resume abc123
```

For detailed documentation, see the numbered files above.

======= docs/06_research/60_research_overview.md ======
# m1f-research

AI-powered research tool that automatically finds, scrapes, and bundles
information on any topic.

## Overview

m1f-research extends the m1f toolkit with intelligent research capabilities. It
uses LLMs to:

- Find relevant URLs for any research topic
- Scrape and convert web content to clean Markdown
- Analyze content for relevance and extract key insights
- Create organized research bundles

## Quick Start

```bash
# Basic research
m1f-research "microservices best practices"

# Research with more sources
m1f-research "react state management" --urls 30 --scrape 15

# List all research jobs
m1f-research --list-jobs

# Resume a job
m1f-research --resume abc123

# Filter jobs by date
m1f-research --list-jobs --date 2025-07

# Search for specific topics
m1f-research --list-jobs --search "python"
```

## Installation

m1f-research is included with the m1f toolkit. Ensure you have:

1. m1f installed with the research extension
2. An API key for your chosen LLM provider:
   - Claude: Set `ANTHROPIC_API_KEY`
   - Gemini: Set `GOOGLE_API_KEY`

## Features

### 🗄️ Job Management

- **Persistent Jobs**: All research tracked in SQLite database
- **Resume Support**: Continue interrupted research
- **Advanced Filtering**: Search by date, query term
- **Pagination**: Handle large job lists efficiently

### 🔍 Intelligent Search

- Uses LLMs to find high-quality, relevant URLs
- Manual URL support via `--urls-file`
- Focuses on authoritative sources
- Mixes different content types

### 📥 Smart Scraping

- **Per-host delays**: Only after 3+ requests to same host
- Concurrent scraping across different hosts
- Automatic HTML to Markdown conversion
- Content deduplication via checksums

### 🧠 Content Analysis

- Relevance scoring (0-10 scale)
- Key points extraction
- Content summarization
- Duplicate detection

### 📦 Organized Output

- **Hierarchical structure**: YYYY/MM/DD/job_id/
- Prominent bundle files (📚_RESEARCH_BUNDLE.md)
- Clean Markdown output
- Symlink to latest research

## Usage Examples

### Basic Research

```bash
# Research a programming topic
m1f-research "golang error handling"

# Output saved to: ./research-data/golang-error-handling-20240120-143022/
```

### Advanced Options

```bash
# Specify output location and name
m1f-research "kubernetes security" \
  --output ./research \
  --name k8s-security

# Use a specific template
m1f-research "react hooks" --template technical

# Skip analysis for faster results
m1f-research "python asyncio" --no-analysis

# Dry run to see what would happen
m1f-research "rust ownership" --dry-run
```

### Configuration File

```bash
# Use a custom configuration
m1f-research "database optimization" --config research.yml
```

## Configuration

### Key Command Line Options

| Option             | Description              | Default |
| ------------------ | ------------------------ | ------- |
| **Research**       |                          |         |
| `--urls`           | Number of URLs to find   | 20      |
| `--scrape`         | Number of URLs to scrape | 10      |
| `--urls-file`      | File with manual URLs    | None    |
| **Job Management** |                          |         |
| `--resume`         | Resume job by ID         | None    |
| `--list-jobs`      | List all jobs            | False   |
| `--status`         | Show job details         | None    |
| **Filtering**      |                          |         |
| `--search`         | Search jobs by query     | None    |
| `--date`           | Filter by date           | None    |
| `--limit`          | Pagination limit         | None    |
| `--offset`         | Pagination offset        | 0       |
| **Cleanup**        |                          |         |
| `--clean-raw`      | Clean job raw data       | None    |
| `--clean-all-raw`  | Clean all raw data       | False   |

See [63_cli_reference.md](63_cli_reference.md) for complete option list.

### Configuration File (.m1f.config.yml)

```yaml
research:
  # LLM settings
  llm:
    provider: claude
    model: claude-3-opus-20240229
    temperature: 0.7

  # Default counts
  defaults:
    url_count: 30
    scrape_count: 15

  # Scraping behavior
  scraping:
    timeout_range: "1-3"
    max_concurrent: 5
    retry_attempts: 2

  # Content analysis
  analysis:
    relevance_threshold: 7.0
    min_content_length: 100
    prefer_code_examples: true

  # Output settings
  output:
    directory: ./research-data
    create_summary: true
    create_index: true

  # Research templates
  templates:
    technical:
      description: "Technical documentation and code"
      url_count: 30
      analysis_focus: implementation

    academic:
      description: "Academic papers and theory"
      url_count: 20
      analysis_focus: theory
```

## Templates

Pre-configured templates optimize research for different needs:

### technical

- Focuses on implementation details
- Prioritizes code examples
- Higher URL count for comprehensive coverage

### academic

- Emphasizes theoretical content
- Looks for citations and references
- Filters for authoritative sources

### tutorial

- Searches for step-by-step guides
- Prioritizes beginner-friendly content
- Includes examples and exercises

### general (default)

- Balanced approach
- Mixes different content types
- Suitable for most topics

## Output Structure

Research data uses hierarchical date-based organization:

```
./research-data/
├── research_jobs.db              # Main job database
├── latest_research.md           # Symlink to latest bundle
└── 2025/
    └── 07/
        └── 23/
            └── abc123_topic-name/
                ├── research.db           # Job-specific database
                ├── 📚_RESEARCH_BUNDLE.md # Main bundle
                ├── 📊_EXECUTIVE_SUMMARY.md # Summary
                ├── metadata.json         # Job metadata
                └── search_results.json   # Found URLs
```

### Bundle Format

```markdown
# Research: [Your Topic]

Generated on: 2024-01-20 14:30:22 Total sources: 10

---

## Table of Contents

1. [Source Title 1](#1-source-title-1)
2. [Source Title 2](#2-source-title-2) ...

---

## Summary

[Research summary and top sources]

---

## 1. Source Title

**Source:** https://example.com/article **Relevance:** 8.5/10

### Key Points:

- Important point 1
- Important point 2

### Content:

[Full content in Markdown]

---
```

## Providers

### Claude (Anthropic)

- Default provider
- Best for: Comprehensive research, nuanced analysis
- Set: `ANTHROPIC_API_KEY`

### Gemini (Google)

- Fast and efficient
- Best for: Quick research, technical topics
- Set: `GOOGLE_API_KEY`

### CLI Tools

- Use local tools like `gemini-cli`
- Best for: Privacy, offline capability
- Example: `--provider gemini-cli`

## Tips

1. **Start broad, then narrow**: Use more URLs initially, let analysis filter
2. **Use templates**: Match template to your research goal
3. **Interactive mode**: Great for exploratory research
4. **Combine with m1f**: Feed research bundles into m1f for AI analysis

## Troubleshooting

### No API Key

```
Error: API key not set for ClaudeProvider
```

Solution: Set environment variable or pass in config

### Rate Limiting

```
Error: 429 Too Many Requests
```

Solution: Reduce `--concurrent` or increase timeout range

### Low Quality Results

- Increase `--urls` for more options
- Adjust `relevance_threshold` in config
- Try different `--template`

## Documentation

- [62_job_management.md](62_job_management.md) - Job persistence and filtering
  guide
- [63_cli_reference.md](63_cli_reference.md) - Complete CLI reference
- [64_api_reference.md](64_api_reference.md) - Developer API documentation
- [65_architecture.md](65_architecture.md) - Technical architecture details
- [66_examples.md](66_examples.md) - Real-world usage examples

## Future Features

- Multi-source research (GitHub, arXiv, YouTube)
- Knowledge graph building
- Research collaboration
- Export to various formats
- Job tagging system

## Contributing

m1f-research is part of the m1f project. Contributions welcome!

- Report issues: [GitHub Issues](https://github.com/m1f/m1f/issues)
- Submit PRs: Follow m1f contribution guidelines
- Request features: Open a discussion

======= docs/06_research/62_job_management.md ======
# Job Management in m1f-research

m1f-research uses a SQLite-based job management system that tracks all research
tasks, enabling persistence, resume functionality, and advanced filtering.

## Overview

Every research task creates a **job** with:

- Unique job ID
- SQLite databases for tracking
- Hierarchical directory structure
- Full resume capability
- Advanced search and filtering

## Job Structure

### Directory Layout

```
research-data/
├── research_jobs.db          # Main job tracking database
├── latest_research.md        # Symlink to most recent bundle
└── 2025/
    └── 07/
        └── 23/
            └── abc123_query-name/
                ├── research.db           # Job-specific database
                ├── 📚_RESEARCH_BUNDLE.md # Main research bundle
                ├── 📊_EXECUTIVE_SUMMARY.md # Executive summary
                └── metadata.json         # Job metadata
```

### Database Architecture

**Main Database (`research_jobs.db`)**

- Tracks all jobs across the system
- Stores job metadata and statistics
- Enables cross-job queries and filtering

**Per-Job Database (`research.db`)**

- URL tracking and status
- Content storage (markdown)
- Analysis results
- Filtering decisions

## Job Management Commands

### Listing Jobs

```bash
# List all jobs
m1f-research --list-jobs

# List with pagination
m1f-research --list-jobs --limit 10 --offset 20

# Filter by date
m1f-research --list-jobs --date 2025-07-23  # Specific day
m1f-research --list-jobs --date 2025-07     # Specific month
m1f-research --list-jobs --date 2025        # Specific year

# Search by query term
m1f-research --list-jobs --search "react"
m1f-research --list-jobs --search "tailwind"

# Combine filters
m1f-research --list-jobs --date 2025-07 --search "python" --limit 5
```

### Viewing Job Details

```bash
# Show detailed job status
m1f-research --status abc123
```

Output includes:

- Job ID and query
- Creation/update timestamps
- URL statistics
- Bundle availability
- Output directory

### Resuming Jobs

```bash
# Resume an interrupted job
m1f-research --resume abc123

# Add more URLs to existing job
m1f-research --resume abc123 --urls-file additional-urls.txt
```

## Advanced Filtering

### Pagination

Use `--limit` and `--offset` for large job lists:

```bash
# First page (10 items)
m1f-research --list-jobs --limit 10

# Second page
m1f-research --list-jobs --limit 10 --offset 10

# Third page
m1f-research --list-jobs --limit 10 --offset 20
```

### Date Filtering

Filter jobs by creation date:

```bash
# Jobs from today
m1f-research --list-jobs --date 2025-07-23

# Jobs from this month
m1f-research --list-jobs --date 2025-07

# Jobs from this year
m1f-research --list-jobs --date 2025
```

### Search Filtering

Find jobs by query content:

```bash
# Find all React-related research
m1f-research --list-jobs --search "react"

# Case-insensitive search
m1f-research --list-jobs --search "PYTHON"
```

Search terms are highlighted in the output for easy identification.

## Data Cleanup

### Cleaning Individual Jobs

Remove raw HTML data while preserving analysis:

```bash
# Clean specific job
m1f-research --clean-raw abc123
```

This removes:

- Raw HTML files
- Temporary download data

This preserves:

- Markdown content
- Analysis results
- Research bundles
- Job metadata

### Bulk Cleanup

Clean all jobs at once:

```bash
# Clean all raw data (with confirmation)
m1f-research --clean-all-raw
```

**Warning**: This action cannot be undone. You'll be prompted to confirm.

## Job Status

Jobs can have the following statuses:

| Status      | Description               |
| ----------- | ------------------------- |
| `active`    | Job is currently running  |
| `completed` | Job finished successfully |
| `failed`    | Job encountered errors    |

## Manual URL Management

Add URLs from a file:

```bash
# Create URL file
cat > my-urls.txt << EOF
https://example.com/article1
https://example.com/article2
EOF

# Start new job with URLs
m1f-research "my topic" --urls-file my-urls.txt

# Add to existing job
m1f-research --resume abc123 --urls-file more-urls.txt
```

## Smart Delay Management

The scraper implements intelligent per-host delays:

- **No delay** for first 3 requests to any host
- **1-3 second random delay** after 3 requests
- **Parallel scraping** across different hosts

This ensures:

- Fast scraping for diverse sources
- Respectful behavior for repeated requests
- Optimal performance

## Examples

### Research Workflow

```bash
# 1. Start research
m1f-research "python async best practices"
# Output: Job ID: abc123

# 2. Check progress
m1f-research --status abc123

# 3. Add more URLs if needed
m1f-research --resume abc123 --urls-file extra-urls.txt

# 4. View all Python research
m1f-research --list-jobs --search "python"

# 5. Clean up old data
m1f-research --clean-raw abc123
```

### Monthly Research Review

```bash
# List all research from July 2025
m1f-research --list-jobs --date 2025-07

# Page through results
m1f-research --list-jobs --date 2025-07 --limit 20
m1f-research --list-jobs --date 2025-07 --limit 20 --offset 20

# Find specific topic
m1f-research --list-jobs --date 2025-07 --search "react hooks"
```

### Disk Space Management

```bash
# Check job sizes (future feature)
# m1f-research --list-jobs --show-size

# Clean specific old job
m1f-research --clean-raw old-job-id

# Bulk cleanup
m1f-research --clean-all-raw
```

## Tips

1. **Use job IDs**: Save job IDs for easy resume/reference
2. **Regular cleanup**: Clean raw data after analysis is complete
3. **Combine filters**: Use multiple filters for precise searches
4. **Manual URLs**: Supplement LLM search with your own URLs
5. **Check status**: Monitor long-running jobs with --status

## Future Enhancements

- Export job lists to CSV/JSON
- Job size statistics
- Automatic cleanup policies
- Job tagging system
- Cross-job deduplication
- Job templates

======= docs/06_research/63_cli_reference.md ======
# m1f-research CLI Reference

Complete command-line interface reference for m1f-research.

## Synopsis

```bash
m1f-research [QUERY] [OPTIONS]
```

## Positional Arguments

### `query`

Research topic or query (required for new jobs, optional when using job
management commands)

## Options

### General Options

| Option            | Short | Description                            | Default |
| ----------------- | ----- | -------------------------------------- | ------- |
| `--help`          | `-h`  | Show help message and exit             | -       |
| `--version`       |       | Show program version                   | -       |
| `--verbose`       | `-v`  | Increase verbosity (use -vv for debug) | Warning |
| `--dry-run`       |       | Preview without executing              | False   |
| `--config CONFIG` | `-c`  | Path to configuration file             | None    |

### LLM Provider Options

| Option                | Short | Description                                                          | Default          |
| --------------------- | ----- | -------------------------------------------------------------------- | ---------------- |
| `--provider PROVIDER` | `-p`  | LLM provider: claude, claude-cli, gemini, gemini-cli, openai         | claude           |
| `--model MODEL`       | `-m`  | Specific model to use                                                | Provider default |
| `--template TEMPLATE` | `-t`  | Analysis template: general, technical, academic, tutorial, reference | general          |

### Research Options

| Option           | Short | Description                        | Default |
| ---------------- | ----- | ---------------------------------- | ------- |
| `--urls N`       |       | Number of URLs to search for       | 20      |
| `--scrape N`     |       | Maximum URLs to scrape             | 10      |
| `--concurrent N` |       | Max concurrent scraping operations | 5       |
| `--no-filter`    |       | Disable content filtering          | False   |
| `--no-analysis`  |       | Skip AI analysis (just scrape)     | False   |
| `--interactive`  | `-i`  | Start in interactive mode          | False   |

### Output Options

| Option         | Short | Description                     | Default         |
| -------------- | ----- | ------------------------------- | --------------- |
| `--output DIR` | `-o`  | Output directory                | ./research-data |
| `--name NAME`  | `-n`  | Custom name for research bundle | Auto-generated  |

### Job Management

| Option             | Description                                |
| ------------------ | ------------------------------------------ |
| `--resume JOB_ID`  | Resume an existing research job            |
| `--list-jobs`      | List all research jobs                     |
| `--status JOB_ID`  | Show detailed status of a specific job     |
| `--urls-file FILE` | File containing URLs to add (one per line) |

### List Filtering Options

| Option          | Description                 | Example             |
| --------------- | --------------------------- | ------------------- |
| `--limit N`     | Limit number of results     | `--limit 10`        |
| `--offset N`    | Skip N results (pagination) | `--offset 20`       |
| `--date DATE`   | Filter by date              | `--date 2025-07-23` |
| `--search TERM` | Search jobs by query term   | `--search "react"`  |

### Cleanup Options

| Option               | Description                          |
| -------------------- | ------------------------------------ |
| `--clean-raw JOB_ID` | Clean raw HTML data for specific job |
| `--clean-all-raw`    | Clean raw HTML data for all jobs     |

## Command Examples

### Basic Research

```bash
# Simple research
m1f-research "python async programming"

# With custom settings
m1f-research "react hooks" --urls 30 --scrape 15

# Using different provider
m1f-research "machine learning" --provider gemini --model gemini-1.5-pro

# Skip analysis for faster results
m1f-research "tailwind css" --no-analysis

# Custom output location
m1f-research "rust ownership" --output ~/research --name rust-guide
```

### Job Management

```bash
# List all jobs
m1f-research --list-jobs

# List with pagination
m1f-research --list-jobs --limit 10 --offset 0

# Filter by date
m1f-research --list-jobs --date 2025-07-23  # Specific day
m1f-research --list-jobs --date 2025-07     # Month
m1f-research --list-jobs --date 2025        # Year

# Search for jobs
m1f-research --list-jobs --search "python"

# Combined filters
m1f-research --list-jobs --date 2025-07 --search "async" --limit 5

# Check job status
m1f-research --status abc123

# Resume a job
m1f-research --resume abc123

# Add URLs to existing job
m1f-research --resume abc123 --urls-file additional-urls.txt
```

### Manual URL Management

```bash
# Start with manual URLs only
m1f-research "my topic" --urls 0 --urls-file my-urls.txt

# Combine LLM search with manual URLs
m1f-research "my topic" --urls 20 --urls-file my-urls.txt

# Add URLs to existing job
m1f-research --resume abc123 --urls-file more-urls.txt
```

### Data Cleanup

```bash
# Clean specific job
m1f-research --clean-raw abc123

# Clean all jobs (with confirmation)
m1f-research --clean-all-raw
```

### Advanced Workflows

```bash
# Dry run to preview
m1f-research "test query" --dry-run

# Very verbose output for debugging
m1f-research "test query" -vv

# Interactive mode
m1f-research --interactive

# Technical analysis with high URL count
m1f-research "kubernetes networking" --template technical --urls 50 --scrape 25
```

## Date Format Examples

The `--date` filter supports multiple formats:

| Format | Example      | Matches               |
| ------ | ------------ | --------------------- |
| Y-M-D  | `2025-07-23` | Specific day          |
| Y-M    | `2025-07`    | All jobs in July 2025 |
| Y      | `2025`       | All jobs in 2025      |

## Exit Codes

| Code | Meaning                      |
| ---- | ---------------------------- |
| 0    | Success                      |
| 1    | General error                |
| 130  | Interrupted by user (Ctrl+C) |

## Environment Variables

| Variable            | Description        |
| ------------------- | ------------------ |
| `ANTHROPIC_API_KEY` | API key for Claude |
| `GOOGLE_API_KEY`    | API key for Gemini |
| `OPENAI_API_KEY`    | API key for OpenAI |

## Configuration File

Create `.m1f.config.yml` for persistent settings:

```yaml
research:
  llm:
    provider: claude
    model: claude-3-opus-20240229

  defaults:
    url_count: 30
    scrape_count: 15

  output:
    directory: ~/research-data
```

## Tips

1. **Save Job IDs**: Copy job IDs for easy resume/reference
2. **Use Filters**: Combine date and search for precise results
3. **Pagination**: Use limit/offset for large job lists
4. **Cleanup**: Regularly clean raw data to save space
5. **Manual URLs**: Supplement with your own curated links

======= docs/06_research/64_api_reference.md ======
# m1f-research API Reference

## Command Line Interface

### Basic Usage

```bash
m1f-research [OPTIONS] <query>
```

### Options

#### Search Options

- `--urls <count>` - Number of URLs to find (default: 20)
- `--scrape <count>` - Number of URLs to scrape (default: 10)
- `--template <name>` - Research template to use (default: general)

#### LLM Options

- `--provider <name>` - LLM provider (claude, gemini, cli)
- `--model <name>` - Specific model to use
- `--temperature <float>` - LLM temperature (0.0-1.0)

#### Output Options

- `--output <dir>` - Output directory (default: ./m1f/research)
- `--name <name>` - Bundle name (default: auto-generated)
- `--format <format>` - Output format (markdown, json)

#### Processing Options

- `--concurrent <count>` - Max concurrent scrapes (default: 5)
- `--timeout <range>` - Timeout range in seconds (e.g., "1-3")
- `--no-filter` - Disable URL filtering
- `--no-analysis` - Skip content analysis
- `--no-summary` - Skip summary generation

#### Other Options

- `--config <file>` - Custom config file
- `--interactive` - Interactive mode
- `--dry-run` - Preview without execution
- `--verbose` - Verbose output
- `--quiet` - Minimal output

## Python API

### Basic Usage

```python
from tools.research import ResearchOrchestrator
from tools.shared.colors import info, success

# Create orchestrator
orchestrator = ResearchOrchestrator()

# Run research
results = await orchestrator.research(
    query="microservices best practices",
    url_count=30,
    scrape_count=15
)

# Access results
info(f"Found {len(results.urls)} URLs")
info(f"Scraped {len(results.content)} pages")
success(f"Bundle saved to: {results.bundle_path}")
```

### Configuration

```python
from tools.research import ResearchConfig

config = ResearchConfig(
    llm_provider="claude",
    model="claude-3-opus-20240229",
    temperature=0.7,
    url_count=30,
    scrape_count=15,
    output_dir="./research",
    concurrent_limit=5,
    timeout_range=(1, 3)
)

orchestrator = ResearchOrchestrator(config)
```

### Custom Templates

```python
from tools.research import ResearchTemplate

template = ResearchTemplate(
    name="custom",
    description="Custom research template",
    search_prompt="Find {query} focusing on...",
    analysis_focus="implementation details",
    relevance_criteria="practical examples"
)

results = await orchestrator.research(
    query="react hooks",
    template=template
)
```

### Providers

```python
from tools.research import ClaudeProvider, GeminiProvider

# Claude provider
claude = ClaudeProvider(
    api_key="your-api-key",
    model="claude-3-opus-20240229"
)

# Gemini provider
gemini = GeminiProvider(
    api_key="your-api-key",
    model="gemini-pro"
)

# Use custom provider
orchestrator = ResearchOrchestrator(
    config=config,
    llm_provider=claude
)
```

### Scraping

```python
from tools.research import Scraper

scraper = Scraper(
    concurrent_limit=5,
    timeout_range=(1, 3),
    retry_attempts=2
)

# Scrape single URL
content = await scraper.scrape_url("https://example.com")

# Scrape multiple URLs
urls = ["https://example1.com", "https://example2.com"]
results = await scraper.scrape_urls(urls)
```

### Analysis

```python
from tools.research import Analyzer
from tools.shared.colors import info

analyzer = Analyzer(llm_provider=claude)

# Analyze content
analysis = await analyzer.analyze_content(
    content="Article content...",
    query="microservices",
    template="technical"
)

info(f"Relevance: {analysis.relevance}/10")
info(f"Key points: {analysis.key_points}")
```

### Bundle Creation

```python
from tools.research import BundleCreator

creator = BundleCreator()

# Create bundle
bundle_path = await creator.create_bundle(
    query="microservices",
    scraped_content=results,
    analysis_results=analyses,
    output_dir="./research"
)
```

## Data Models

### ResearchResult

```python
@dataclass
class ResearchResult:
    query: str
    urls: List[str]
    content: List[ScrapedContent]
    analyses: List[ContentAnalysis]
    bundle_path: Path
    metadata: Dict[str, Any]
```

### ScrapedContent

```python
@dataclass
class ScrapedContent:
    url: str
    title: str
    content: str
    scraped_at: datetime
    success: bool
    error: Optional[str]
```

### ContentAnalysis

```python
@dataclass
class ContentAnalysis:
    url: str
    relevance: float
    key_points: List[str]
    summary: str
    metadata: Dict[str, Any]
```

## Error Handling

```python
from tools.research import ResearchError, ScrapingError, AnalysisError
from tools.shared.colors import error

try:
    results = await orchestrator.research("query")
except ResearchError as e:
    error(f"Research failed: {e}")
except ScrapingError as e:
    error(f"Scraping failed: {e}")
except AnalysisError as e:
    error(f"Analysis failed: {e}")
```

## Events and Callbacks

```python
from tools.shared.colors import info, error

# Progress callback
def on_progress(stage: str, current: int, total: int):
    info(f"{stage}: {current}/{total}")

# Error callback
def on_error(error: Exception, context: Dict):
    error(f"Error in {context['stage']}: {error}")

# Use callbacks
results = await orchestrator.research(
    query="microservices",
    on_progress=on_progress,
    on_error=on_error
)
```

## Advanced Usage

### Custom URL Filters

```python
def custom_filter(url: str) -> bool:
    # Only allow specific domains
    allowed = ["docs.python.org", "realpython.com"]
    return any(domain in url for domain in allowed)

orchestrator.add_url_filter(custom_filter)
```

### Content Processors

```python
def process_content(content: str) -> str:
    # Custom content processing
    return content.replace("old_term", "new_term")

orchestrator.add_content_processor(process_content)
```

### Result Transformers

```python
def transform_results(results: ResearchResult) -> Dict:
    # Custom result transformation
    return {
        "query": results.query,
        "sources": len(results.content),
        "top_relevance": max(a.relevance for a in results.analyses)
    }

transformed = transform_results(results)
```

======= docs/06_research/65_architecture.md ======
# m1f-research Architecture

## Overview

The m1f-research tool is built on a modular architecture that combines web
search, content scraping, and AI-powered analysis to create comprehensive
research bundles.

## Core Components

### 1. Orchestrator (`orchestrator.py`)

- Central coordination of the research workflow
- Manages the pipeline: search → scrape → analyze → bundle
- Handles configuration and state management

### 2. LLM Interface (`llm_interface.py`)

- Abstraction layer for different LLM providers
- Supports Claude, Gemini, and CLI tools
- Manages API calls and response parsing

### 3. Scraper (`scraper.py`)

- Concurrent web scraping with rate limiting
- Integrates with html2md for content conversion
- Handles failures gracefully with retry logic

### 4. Analyzer (`analyzer.py`)

- Content relevance scoring
- Key points extraction
- Duplicate detection
- Template-based analysis

### 5. Bundle Creator (`bundle_creator.py`)

- Organizes scraped content into structured bundles
- Creates table of contents and summaries
- Formats output in clean Markdown

## Data Flow

```
User Query
    ↓
Orchestrator
    ↓
LLM Search → URLs
    ↓
Concurrent Scraping → Raw Content
    ↓
HTML to Markdown → Clean Content
    ↓
Content Analysis → Scored Content
    ↓
Bundle Creation → Research Bundle
```

## Configuration System

The research tool uses a hierarchical configuration system:

1. **Default Config**: Built-in defaults
2. **User Config**: ~/.m1f.config.yml
3. **Project Config**: ./.m1f.config.yml
4. **CLI Arguments**: Command-line overrides

## Templates

Templates customize the research process for different use cases:

- **Search Prompts**: How to find URLs
- **Analysis Focus**: What to extract
- **Output Format**: How to structure results

### Template Structure

```yaml
template_name:
  description: "Purpose of this template"
  search:
    focus: "What to look for"
    source_types: ["tutorial", "documentation", "discussion"]
  analysis:
    relevance_prompt: "Custom relevance criteria"
    key_points_prompt: "What to extract"
  output:
    structure: "How to organize results"
```

## Concurrency Model

The tool uses asyncio for efficient concurrent operations:

- **URL Search**: Sequential (LLM rate limits)
- **Web Scraping**: Concurrent with semaphore (default: 5)
- **Content Analysis**: Batch processing
- **Bundle Creation**: Sequential

## Error Handling

- **Graceful Degradation**: Failed scrapes don't stop the process
- **Retry Logic**: Automatic retries for transient failures
- **Fallback Providers**: Switch providers on API errors
- **Detailed Logging**: Track issues for debugging

## Security Considerations

- **URL Validation**: Prevent SSRF attacks
- **Content Sanitization**: Remove potentially harmful content
- **Rate Limiting**: Respect server resources
- **API Key Management**: Secure credential handling

## Extension Points

The architecture supports several extension mechanisms:

1. **Custom Providers**: Add new LLM providers
2. **Scraper Backends**: Integrate new scraping tools
3. **Analysis Templates**: Create domain-specific templates
4. **Output Formats**: Add new bundle formats

## Performance Optimizations

- **Concurrent Scraping**: Parallel downloads
- **Streaming Processing**: Handle large content
- **Caching**: Avoid duplicate work
- **Lazy Loading**: Load components on demand

## Future Architecture Plans

- **Plugin System**: Dynamic loading of extensions
- **Distributed Scraping**: Scale across multiple machines
- **Knowledge Graph**: Build connections between research
- **Real-time Updates**: Monitor sources for changes

======= docs/06_research/66_examples.md ======
# m1f-research Examples

## Command Line Examples

### Basic Research

```bash
# Simple research on a topic
m1f-research "python async programming"

# Research with more sources
m1f-research "kubernetes networking" --urls 40 --scrape 20

# Use a specific template
m1f-research "react performance optimization" --template technical
```

### Different Providers

```bash
# Use Gemini instead of Claude
m1f-research "machine learning basics" --provider gemini

# Use a CLI tool
m1f-research "rust ownership" --provider gemini-cli

# Specify a particular model
m1f-research "quantum computing" --provider claude --model claude-3-opus-20240229
```

### Output Control

```bash
# Custom output location
m1f-research "microservices patterns" --output ~/research/microservices

# Named bundle
m1f-research "docker best practices" --name docker-guide

# JSON output format
m1f-research "api design" --format json
```

### Processing Options

```bash
# Faster scraping with more concurrency
m1f-research "golang concurrency" --concurrent 10

# Slower, more respectful scraping
m1f-research "web scraping ethics" --concurrent 2 --timeout "2-5"

# Skip analysis for raw content
m1f-research "css grid layouts" --no-analysis

# Skip filtering to get all URLs
m1f-research "obscure programming languages" --no-filter
```

### Interactive Mode

```bash
# Start interactive research session
m1f-research --interactive

# In interactive mode:
# > Enter research query: microservices vs monoliths
# > Number of URLs to find [20]: 30
# > Number to scrape [10]: 15
# > Template [general]: technical
# > Start research? [Y/n]: y
```

## Configuration File Examples

### Basic Configuration

```yaml
# .m1f.config.yml
research:
  llm:
    provider: claude
    temperature: 0.7

  defaults:
    url_count: 30
    scrape_count: 15

  output:
    directory: ./my-research
```

### Advanced Configuration

```yaml
# research-config.yml
research:
  llm:
    provider: gemini
    model: gemini-pro
    temperature: 0.8
    max_tokens: 4000

  defaults:
    url_count: 50
    scrape_count: 25

  scraping:
    timeout_range: "2-4"
    max_concurrent: 8
    retry_attempts: 3
    user_agent: "m1f-research/1.0"

  analysis:
    relevance_threshold: 7.5
    min_content_length: 200
    prefer_code_examples: true
    extract_metadata: true

  output:
    directory: ./research-output
    create_summary: true
    create_index: true
    include_metadata: true

  filters:
    allowed_domains:
      - "*.github.io"
      - "docs.*.com"
      - "*.readthedocs.io"
    blocked_domains:
      - "spam-site.com"
    url_patterns:
      - "*/api/*"
      - "*/reference/*"
```

### Template-Specific Config

```yaml
# technical-research.yml
research:
  templates:
    technical:
      description: "Deep technical documentation"
      url_count: 40
      scrape_count: 20

      search:
        focus: "implementation, architecture, code examples"
        prefer_sources:
          - "GitHub"
          - "official docs"
          - "technical blogs"

      analysis:
        relevance_prompt: |
          Rate based on:
          - Code examples
          - Technical depth
          - Practical applicability

        key_points_prompt: |
          Extract:
          - Core concepts
          - Implementation details
          - Best practices
          - Common pitfalls

      output:
        group_by: "subtopic"
        include_code_stats: true
```

## Python Script Examples

### Basic Research Script

```python
#!/usr/bin/env python3
import asyncio
from tools.research import ResearchOrchestrator
from tools.shared.colors import info, success

async def main():
    orchestrator = ResearchOrchestrator()

    results = await orchestrator.research(
        query="GraphQL best practices",
        url_count=30,
        scrape_count=15
    )

    success(f"Research complete!")
    info(f"Bundle saved to: {results.bundle_path}")
    info(f"Total sources: {len(results.content)}")
    info(f"Average relevance: {sum(a.relevance for a in results.analyses) / len(results.analyses):.1f}")

if __name__ == "__main__":
    asyncio.run(main())
```

### Custom Template Script

```python
#!/usr/bin/env python3
import asyncio
from tools.research import ResearchOrchestrator, ResearchTemplate
from tools.shared.colors import info

# Define custom template
security_template = ResearchTemplate(
    name="security",
    description="Security-focused research",
    search_prompt="""
    Find authoritative sources about {query} focusing on:
    - Security vulnerabilities
    - Best practices for security
    - OWASP guidelines
    - Security tools and scanning
    """,
    analysis_focus="security implications",
    relevance_criteria="security relevance and actionable advice"
)

async def main():
    orchestrator = ResearchOrchestrator()

    results = await orchestrator.research(
        query="API security",
        template=security_template,
        url_count=40,
        scrape_count=20
    )

    # Print security-specific summary
    info("\n=== Security Research Summary ===")
    for analysis in sorted(results.analyses, key=lambda a: a.relevance, reverse=True)[:5]:
        info(f"\n{analysis.url}")
        info(f"Relevance: {analysis.relevance}/10")
        info("Key Security Points:")
        for point in analysis.key_points[:3]:
            info(f"  - {point}")

if __name__ == "__main__":
    asyncio.run(main())
```

### Batch Research Script

```python
#!/usr/bin/env python3
import asyncio
from pathlib import Path
from tools.research import ResearchOrchestrator
from tools.shared.colors import info

async def research_topic(orchestrator, topic, output_dir):
    """Research a single topic"""
    info(f"\nResearching: {topic}")

    results = await orchestrator.research(
        query=topic,
        url_count=20,
        scrape_count=10,
        output_dir=output_dir / topic.replace(" ", "_")
    )

    return topic, results

async def main():
    topics = [
        "microservices architecture",
        "event-driven design",
        "domain-driven design",
        "CQRS pattern",
        "saga pattern"
    ]

    orchestrator = ResearchOrchestrator()
    output_dir = Path("./architecture-research")
    output_dir.mkdir(exist_ok=True)

    # Research all topics
    tasks = [research_topic(orchestrator, topic, output_dir) for topic in topics]
    results = await asyncio.gather(*tasks)

    # Create index
    with open(output_dir / "index.md", "w") as f:
        f.write("# Architecture Research\n\n")
        for topic, result in results:
            f.write(f"## {topic}\n")
            f.write(f"- Sources: {len(result.content)}\n")
            f.write(f"- Bundle: [{result.bundle_path.name}](./{result.bundle_path.relative_to(output_dir)})\n\n")

if __name__ == "__main__":
    asyncio.run(main())
```

### Research Pipeline Script

```python
#!/usr/bin/env python3
import asyncio
import json
from datetime import datetime
from tools.research import ResearchOrchestrator
from tools.m1f import bundle_files
from tools.shared.colors import info, success

async def research_and_bundle(query):
    """Research a topic and create an m1f bundle"""

    # Phase 1: Research
    info(f"Phase 1: Researching {query}")
    orchestrator = ResearchOrchestrator()

    research_results = await orchestrator.research(
        query=query,
        url_count=30,
        scrape_count=15,
        output_dir=f"./pipeline/{query.replace(' ', '_')}"
    )

    # Phase 2: Bundle with m1f
    info(f"Phase 2: Creating m1f bundle")
    bundle_path = bundle_files(
        paths=[str(research_results.bundle_path.parent)],
        output=f"./pipeline/{query.replace(' ', '_')}_complete.txt",
        preset="docs-bundle"
    )

    # Phase 3: Create report
    info(f"Phase 3: Generating report")
    report = {
        "query": query,
        "timestamp": datetime.now().isoformat(),
        "research": {
            "urls_found": len(research_results.urls),
            "urls_scraped": len(research_results.content),
            "avg_relevance": sum(a.relevance for a in research_results.analyses) / len(research_results.analyses)
        },
        "bundle": {
            "path": str(bundle_path),
            "size": bundle_path.stat().st_size
        }
    }

    report_path = f"./pipeline/{query.replace(' ', '_')}_report.json"
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2)

    return report

async def main():
    queries = [
        "react state management",
        "vue composition api",
        "angular signals"
    ]

    # Process all queries
    results = []
    for query in queries:
        result = await research_and_bundle(query)
        results.append(result)
        success(f"Completed: {query}\n")

    # Summary
    info("\n=== Pipeline Summary ===")
    for result in results:
        info(f"\n{result['query']}:")
        info(f"  - URLs scraped: {result['research']['urls_scraped']}")
        info(f"  - Avg relevance: {result['research']['avg_relevance']:.1f}")
        info(f"  - Bundle size: {result['bundle']['size'] / 1024:.1f} KB")

if __name__ == "__main__":
    asyncio.run(main())
```

## Real-World Use Cases

### 1. Technology Evaluation

```bash
# Research multiple competing technologies
m1f-research "kafka vs rabbitmq vs redis streams" --urls 50 --scrape 30 --template technical

# Deep dive into one technology
m1f-research "apache kafka internals architecture" --urls 40 --scrape 25
```

### 2. Learning New Topics

```bash
# Beginner-friendly research
m1f-research "python for beginners" --template tutorial

# Advanced topics with academic sources
m1f-research "distributed consensus algorithms" --template academic
```

### 3. Problem Solving

```bash
# Debug specific issues
m1f-research "kubernetes pod stuck terminating" --urls 30

# Find best practices
m1f-research "postgresql performance tuning large tables" --template technical
```

### 4. Documentation Collection

```bash
# Gather API documentation
m1f-research "stripe api payment intents" --template reference

# Collect migration guides
m1f-research "migrate django 3 to 4" --urls 40
```

### 5. Security Research

```bash
# Security audit preparation
m1f-research "OWASP top 10 2023 examples" --urls 50 --scrape 30

# Vulnerability research
m1f-research "log4j vulnerability explanation CVE-2021-44228"
```

## Tips and Tricks

### 1. Optimize for Quality

```bash
# More URLs, selective scraping
m1f-research "complex topic" --urls 60 --scrape 20

# This finds many options but only scrapes the best
```

### 2. Domain-Specific Research

```bash
# Create custom config for specific domains
cat > medical-research.yml << EOF
research:
  filters:
    allowed_domains:
      - "*.nih.gov"
      - "pubmed.ncbi.nlm.nih.gov"
      - "*.nature.com"
EOF

m1f-research "covid vaccine efficacy" --config medical-research.yml
```

### 3. Combine with Other Tools

```bash
# Research → m1f bundle → AI analysis
m1f-research "topic" && \
m1f ./m1f/research/topic-*/ -o analysis.txt && \
cat analysis.txt | llm "Summarize the key findings"
```

### 4. Scheduled Research

```bash
# Daily research updates (cron job)
0 9 * * * /usr/local/bin/m1f-research "AI news today" --name "ai-news-$(date +%Y%m%d)"
```

### 5. Research Archive

```bash
# Organize research by date
m1f-research "topic" --output "./research/$(date +%Y)/$(date +%m)/$(date +%d)/"
```

======= docs/06_research/67_cli_improvements.md ======
# 67. CLI Improvements for m1f-research

## Overview

The m1f-research CLI has been enhanced with improved user experience features
including colored output, JSON format support, extended help system, and better
progress tracking.

## Key Improvements

### 1. Colored Output

- **Colorama integration** for cross-platform color support
- **Graceful fallback** when colorama is not available
- **Status indicators** with color coding:
  - ✅ Green for success/completed
  - ⚠️ Yellow for warnings/active
  - ❌ Red for errors/failed
  - ℹ️ Cyan for information
- **Formatted headers** with bold blue text
- **Progress bars** with real-time updates
- **Consistent with other m1f tools** using the same colorama pattern

### 2. Output Formats

```bash
# Default text output with colors
m1f-research --list-jobs

# JSON output for automation
m1f-research --list-jobs --format json

# Quiet mode (suppress non-error output)
m1f-research "query" --quiet

# Verbose mode for debugging
m1f-research "query" --verbose  # -v for info, -vv for debug
```

### 3. Extended Help System

```bash
# Standard help
m1f-research --help

# Extended examples
m1f-research --help-examples

# Filtering guide
m1f-research --help-filters

# Provider setup guide
m1f-research --help-providers
```

### 4. Enhanced Job Listing

```bash
# Pagination
m1f-research --list-jobs --limit 10 --offset 0

# Date filtering
m1f-research --list-jobs --date 2025-07-24  # Specific day
m1f-research --list-jobs --date 2025-07     # Specific month
m1f-research --list-jobs --date 2025        # Specific year

# Search filtering
m1f-research --list-jobs --search "python"

# Status filtering
m1f-research --list-jobs --status-filter completed

# Combined filters
m1f-research --list-jobs \
  --search "react" \
  --date 2025-07 \
  --status-filter completed \
  --limit 20
```

### 5. Progress Tracking

- **Real-time progress bars** for long operations
- **ETA calculation** for time estimates
- **Phase indicators**:
  - Searching for URLs
  - Scraping URLs
  - Analyzing content
- **Callbacks** integrated throughout the pipeline

### 6. Interactive Mode

```bash
# Start interactive mode
m1f-research --interactive

# Available commands:
research <query>     # Start new research
list                # List all jobs
status <job_id>     # Show job status
resume <job_id>     # Resume a job
help               # Show help
exit/quit          # Exit
```

### 7. Better Error Handling

- **Helpful error messages** with suggestions
- **Input validation** with clear feedback
- **Graceful handling** of interrupts (Ctrl+C)

## Implementation Details

### Output Formatter (`output.py`)

```python
class OutputFormatter:
    """Handles formatted output for m1f-research"""

    def __init__(self, format: str = 'text', verbose: int = 0, quiet: bool = False):
        self.format = format
        self.verbose = verbose
        self.quiet = quiet
```

Key methods:

- `success()`, `error()`, `warning()`, `info()` - Colored messages
- `table()` - Formatted tables with column alignment
- `progress()` - Progress bars with ETA
- `job_status()` - Formatted job information
- `confirm()` - User confirmation prompts

### Enhanced CLI (`cli.py`)

```python
class EnhancedResearchCommand:
    """Enhanced CLI with better user experience"""
```

Features:

- Argument validation
- Extended help generation
- Progress callback integration
- JSON/text output switching
- Interactive mode support

### Progress Tracking

Progress callbacks integrated at multiple levels:

- URL searching phase
- Web scraping phase
- Content analysis phase
- Bundle creation phase

## Usage Examples

### 1. Research with Progress

```bash
m1f-research "python async programming" --verbose
# Shows progress bars for each phase
```

### 2. Job Management

```bash
# List recent jobs with colors
m1f-research --list-jobs --limit 10

# Watch job progress
m1f-research --watch abc123

# Export job data
m1f-research --export abc123 > job-data.json
```

### 3. Automation

```bash
# Get completed jobs as JSON
jobs=$(m1f-research --list-jobs --status-filter completed --format json)

# Process each job
echo "$jobs" | jq -r '.[].job_id' | while read id; do
    m1f-research --export "$id" > "exports/$id.json"
done
```

### 4. Batch Operations

```bash
# Clean all raw data with confirmation
m1f-research --clean-all-raw

# Skip confirmation
m1f-research --clean-all-raw --yes
```

## Benefits

1. **Better User Experience**

   - Clear visual feedback
   - Progress tracking
   - Helpful error messages

2. **Automation Support**

   - JSON output format
   - Machine-readable responses
   - Scriptable interface

3. **Debugging Support**

   - Verbose logging levels
   - Detailed error traces
   - Dry-run mode

4. **Accessibility**
   - `--no-color` option for terminals without color support
   - Clear text alternatives for all visual elements
   - Consistent formatting

## Future Enhancements

1. **Terminal UI (TUI)**

   - Full-screen interface with panels
   - Real-time job monitoring dashboard
   - Interactive job management

2. **Additional Output Formats**

   - CSV export for job lists
   - YAML configuration export
   - HTML reports

3. **Advanced Filtering**

   - Regex support in search
   - Multiple status filters
   - Custom query builders

4. **Performance Metrics**
   - Timing information per phase
   - Resource usage tracking
   - Success rate statistics

======= docs/06_research/index.md ======
# Research Tool Documentation

The m1f research tool is an AI-powered research assistant that automatically
finds, scrapes, and bundles information on any topic.

## Documentation

- [README](./README.md) - Main documentation for the m1f-research tool
- [Architecture](./architecture.md) - Technical architecture and design
  decisions
- [API Reference](./api-reference.md) - Detailed API documentation
- [Examples](./examples.md) - Usage examples and recipes
- [Example Config](./example-config.yml) - Complete configuration example

## Quick Links

- **Getting Started**: See the [README](./README.md#quick-start)
- **Configuration**: See the [Configuration section](./README.md#configuration)
- **Templates**: See the [Templates section](./README.md#templates)
- **Troubleshooting**: See the
  [Troubleshooting section](./README.md#troubleshooting)

## Related Documentation

- [m1f Documentation](../01_m1f/) - Core bundler documentation
- [s1f Documentation](../02_s1f/) - File extraction tool
- [HTML2MD Documentation](../03_html2md/) - HTML to Markdown converter
- [Scraper Documentation](../04_scrape/) - Web scraping tools
- [Development Documentation](../05_development/) - Development guides and tools

======= docs/99_development/unified_colorama_guide.md ======
# Unified Colorama Guide

This document describes the unified colorama approach used across all m1f tools.

## Overview

All m1f tools use a centralized color handling module located at
`tools/shared/colors.py`. This provides:

- Consistent color output across all tools
- Automatic fallback when colorama is not available
- Unified helper functions for common message types
- Cross-platform terminal color support

## Using the Unified Colors Module

### Basic Import

```python
from tools.shared.colors import Colors, success, error, warning, info, header
```

For relative imports within tools:

```python
from ..shared.colors import Colors, success, error, warning, info, header
```

### Available Colors

The `Colors` class provides these color constants:

- `Colors.BLACK`, `Colors.RED`, `Colors.GREEN`, `Colors.YELLOW`
- `Colors.BLUE`, `Colors.MAGENTA`, `Colors.CYAN`, `Colors.WHITE`
- `Colors.BRIGHT_BLACK`, `Colors.BRIGHT_RED`, `Colors.BRIGHT_GREEN`, etc.
- `Colors.RESET` - Reset all formatting
- `Colors.BOLD`, `Colors.DIM` - Text styles

### Helper Functions

Instead of using `print()` directly, use these semantic helper functions:

```python
# Success messages (green with checkmark)
success("Operation completed successfully!")

# Error messages (red with X, goes to stderr)
error("Failed to process file")

# Warning messages (yellow with warning symbol)
warning("File size exceeds recommended limit")

# Info messages (normal color)
info("Processing 10 files...")

# Headers (cyan and bold)
header("Starting Conversion", "Converting HTML to Markdown")
```

### Colored Logging

For tools using Python's logging module:

```python
import logging
from tools.shared.colors import ColoredFormatter

# Create logger with colored output
logger = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setFormatter(ColoredFormatter())
logger.addHandler(handler)
```

### Colored Argparse Help

For tools using argparse:

```python
import argparse
from tools.shared.colors import ColoredHelpFormatter

parser = argparse.ArgumentParser(
    formatter_class=ColoredHelpFormatter,
    description="Tool description"
)
```

## Migration from Rich

The m1f project has migrated from Rich to colorama for better compatibility. Key
changes:

1. Replace `from rich.console import Console` with imports from `shared.colors`
2. Replace `console.print()` with appropriate helper functions
3. Remove Rich from requirements.txt
4. Use colorama's simpler color syntax

## Best Practices

1. **Always use helper functions** - Don't use `print()` directly for
   user-facing messages
2. **Import from shared module** - Never define local Colors classes
3. **Handle missing colorama gracefully** - The shared module handles this
   automatically
4. **Use semantic functions** - Choose success/error/warning/info based on
   message type
5. **Keep it simple** - Avoid complex formatting; focus on readability

## Testing Color Output

To test with colors disabled:

```bash
export NO_COLOR=1
m1f --help
```

To force colors (even in pipes):

```bash
export FORCE_COLOR=1
m1f --help | less -R
```

## Common Patterns

### Status Messages

```python
info("Starting process...")
# ... do work ...
success("Process completed!")
```

### Error Handling

```python
try:
    # ... operation ...
except Exception as e:
    error(f"Operation failed: {e}")
```

### Progress Updates

```python
for i, file in enumerate(files):
    info(f"Processing file {i+1}/{len(files)}: {file.name}")
```

### Colored File Paths

```python
info(f"Reading from: {Colors.CYAN}{file_path}{Colors.RESET}")
```

## Troubleshooting

1. **Colors not showing on Windows**: Colorama should handle this automatically.
   If not, ensure colorama is installed.

2. **Colors in CI/CD logs**: Most CI systems support ANSI colors. The module
   respects NO_COLOR and CI environment variables.

3. **Import errors**: Ensure you're using the correct relative import path based
   on your tool's location.

## Module API Reference

### Colors Class

- Static class providing color constants
- All attributes return ANSI escape codes or empty strings
- Use `Colors.disable()` to turn off colors programmatically

### Helper Functions

- `success(msg: str)` - Print success message with green color
- `error(msg: str)` - Print error message with red color to stderr
- `warning(msg: str)` - Print warning message with yellow color
- `info(msg: str)` - Print info message with default color
- `header(title: str, subtitle: str = None)` - Print formatted header

### Formatters

- `ColoredFormatter` - Logging formatter with level-based colors
- `ColoredHelpFormatter` - Argparse formatter with colored help text

### Global Variables

- `COLORAMA_AVAILABLE` - Boolean indicating if colorama is installed
- Respects `NO_COLOR` and `FORCE_COLOR` environment variables

======= docs/99_misc/98_token_counter.md ======
# token_counter - Token Estimation Tool

The token_counter tool (v2.0.0) estimates token usage for LLM context planning,
helping you optimize your use of large language models by managing context
window limits.

## Overview

When working with LLMs like ChatGPT, Claude, or GPT-4, understanding token
consumption is essential for effective prompt engineering and context
management. Built with Python 3.10+, the token_counter tool allows you to
precisely measure how many tokens your combined files will use, helping you stay
within the context window limits of your chosen LLM.

## Key Features

- Uses OpenAI's tiktoken library for accurate estimates
- Supports different encoding schemes for various LLMs
- Helps optimize context usage for LLMs
- Simple command-line interface

## Quick Start

```bash
# Check token count of a file
m1f-token-counter ./combined.txt

# Use a specific encoding model
m1f-token-counter ./combined.txt -e p50k_base
```

## Command Line Options

| Option           | Description                                         |
| ---------------- | --------------------------------------------------- |
| `file_path`      | Path to the text file to analyze                    |
| `-e, --encoding` | The tiktoken encoding to use (default: cl100k_base) |

## Usage Examples

Basic usage with default encoding (cl100k_base, used by GPT-4 and ChatGPT):

```bash
m1f-token-counter combined_output.txt
```

Using a specific encoding:

```bash
m1f-token-counter myfile.txt -e p50k_base
```

## Encoding Models

The tool supports different encoding models depending on which LLM you're using:

- `cl100k_base` - Default, used by GPT-4, ChatGPT
- `p50k_base` - Used by GPT-3.5-Turbo, text-davinci-003
- `r50k_base` - Used by older GPT-3 models

## Token Limits by Model

Understanding token limits is crucial for effective usage:

| Model           | Token Limit | Recommended Encoding |
| --------------- | ----------- | -------------------- |
| GPT-4 Turbo     | 128,000     | cl100k_base          |
| GPT-4           | 8,192       | cl100k_base          |
| GPT-3.5-Turbo   | 16,385      | cl100k_base          |
| Claude 3.5 Opus | 200,000     | -                    |
| Claude 3 Opus   | 200,000     | -                    |
| Claude 3 Sonnet | 200,000     | -                    |
| Claude 3 Haiku  | 200,000     | -                    |

## Integration with m1f

The token_counter tool is particularly useful when used with m1f to check if
your combined files will fit within the token limit of your chosen LLM:

1. First, combine files with m1f:

   ```bash
   m1f -s ./project -o ./combined.txt --include-extensions .py .js
   ```

2. Then, check the token count:
   ```bash
   m1f-token-counter ./combined.txt
   ```

This workflow helps you adjust your file selection to stay within token limits
for your AI assistant.

## Optimizing Token Usage

To reduce token consumption while maintaining context quality:

1. **Be selective with files**: Include only the most relevant files for your
   prompt
2. **Use minimal separator style**: The `None` separator style uses fewer tokens
3. **Trim unnecessary content**: Remove comments, unused code, or redundant text
4. **Focus on key files**: Prioritize files that directly address your question
5. **Use file filtering**: Utilize m1f's filtering options to target specific
   files

## Architecture

Token counter v2.0.0 features a simple but effective design:

- **Module Structure**: Can be run as a module (`m1f-token-counter`)
- **Type Safety**: Full type hints for better IDE support
- **Error Handling**: Graceful handling of encoding errors and file issues
- **Performance**: Efficient token counting for large files

## Requirements

- Python 3.10 or newer
- The `tiktoken` Python package:

```bash
pip install tiktoken
```

This dependency is included in the project's requirements.txt file.

## Tips for Accurate Token Counting

1. **Model-Specific Encoding**: Always use the encoding that matches your target
   LLM
2. **Include Prompts**: Remember to count tokens in your prompts as well as the
   context
3. **Buffer Space**: Leave 10-20% buffer for model responses
4. **Regular Checks**: Re-check token counts after file modifications

======= examples/claude_code_doc/README.md ======
# Claude Code Documentation Scraper

Creates a bundled documentation file from the Claude Code documentation website.

## What it does

1. **Scrapes** ~31 HTML pages from docs.anthropic.com/claude-code
2. **Analyzes** HTML structure using Claude AI (or uses existing config)
3. **Converts** HTML to clean Markdown with parallel processing
4. **Creates** documentation bundle using m1f-init

## Usage

**Important**: Run from the m1f project root with virtual environment activated!

### Fast mode with existing config (recommended - saves 5-8 minutes!)

#### Linux/macOS
```bash
# From m1f project root:
source .venv/bin/activate
python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-docs \
    --use-config examples/claude_code_doc/html2md_claude_code_doc.config.yml
```

#### Windows
```powershell
# From m1f project root:
.venv\Scripts\activate
python examples\claude_code_doc\scrape_claude_code_docs.py %USERPROFILE%\claude-docs `
    --use-config examples\claude_code_doc\html2md_claude_code_doc.config.yml
```

### With full logging

#### Linux/macOS (using script command)
```bash
# Capture complete output including color codes
source .venv/bin/activate
script -c "python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-doc \
    --use-config examples/claude_code_doc/html2md_claude_code_doc.config.yml" \
    ~/claude-code-doc-scrape.log
```

#### Windows (using PowerShell)
```powershell
# Capture complete output with Start-Transcript
.venv\Scripts\activate
Start-Transcript -Path "$env:USERPROFILE\claude-code-doc-scrape.log"
python examples\claude_code_doc\scrape_claude_code_docs.py $env:USERPROFILE\claude-doc `
    --use-config examples\claude_code_doc\html2md_claude_code_doc.config.yml
Stop-Transcript
```

### Basic usage (with Claude analysis - slower)

#### Linux/macOS
```bash
# Analyzes HTML structure with Claude (adds 5-8 minutes)
source .venv/bin/activate
python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-docs
```

#### Windows
```powershell
.venv\Scripts\activate
python examples\claude_code_doc\scrape_claude_code_docs.py %USERPROFILE%\claude-docs
```

### Force re-download

#### Linux/macOS
```bash
# Re-download HTML files even if they exist
source .venv/bin/activate
python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-docs --force-download
```

#### Windows
```powershell
.venv\Scripts\activate
python examples\claude_code_doc\scrape_claude_code_docs.py %USERPROFILE%\claude-docs --force-download
```

### Show help
```bash
# Works on all platforms
python examples/claude_code_doc/scrape_claude_code_docs.py --help
```

## Timing

### Fast mode (using existing config) ⚡
⏱️ **Total: ~10 minutes**
- Scraping: 8 minutes (31 pages with 15s delays)
- ~~Claude analysis: SKIPPED~~
- Conversion & bundling: <1 minute

### With existing HTML files + config ⚡⚡
⏱️ **Total: ~1-2 minutes**
- ~~Scraping: SKIPPED~~
- ~~Claude analysis: SKIPPED~~
- Conversion & bundling: <1 minute

### Full process (with Claude analysis)
⏱️ **Total: ~18 minutes**
- Scraping: 8 minutes (31 pages with 15s delays)
- Claude analysis: 5-8 minutes
- Conversion & bundling: <2 minutes

## Logging

### Linux/macOS

#### Using script command (captures everything)
```bash
# From m1f project root - captures colors and progress bars
source .venv/bin/activate
script -c "python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-doc \
    --use-config examples/claude_code_doc/html2md_claude_code_doc.config.yml" \
    ~/claude-code-doc/scrape_$(date +%Y%m%d_%H%M%S).log
```

#### Basic logging with tee
```bash
# Basic logging
source .venv/bin/activate
python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-docs \
    --use-config examples/claude_code_doc/html2md_claude_code_doc.config.yml \
    2>&1 | tee scrape_log.txt

# With timestamps (requires moreutils)
source .venv/bin/activate
python examples/claude_code_doc/scrape_claude_code_docs.py ~/claude-docs \
    --use-config examples/claude_code_doc/html2md_claude_code_doc.config.yml \
    2>&1 | ts '[%Y-%m-%d %H:%M:%S]' | tee scrape_log.txt
```

### Windows

#### Using PowerShell transcript
```powershell
# Capture all output including errors
.venv\Scripts\activate
Start-Transcript -Path "$env:USERPROFILE\claude-code-doc\scrape_$(Get-Date -Format 'yyyyMMdd_HHmmss').log"
python examples\claude_code_doc\scrape_claude_code_docs.py $env:USERPROFILE\claude-doc `
    --use-config examples\claude_code_doc\html2md_claude_code_doc.config.yml
Stop-Transcript
```

#### Basic logging with redirection
```powershell
# Basic logging with output redirection
.venv\Scripts\activate
python examples\claude_code_doc\scrape_claude_code_docs.py $env:USERPROFILE\claude-docs `
    --use-config examples\claude_code_doc\html2md_claude_code_doc.config.yml `
    2>&1 | Tee-Object -FilePath scrape_log.txt
```

## Output

The script creates:
```
<target_directory>/
├── claude-code-html/           # Downloaded HTML files
├── claude-code-markdown/       # Converted Markdown files
│   └── m1f/
│       └── *_docs.txt         # Final documentation bundle
└── html2md_claude_code_doc.config.yml  # Config (if generated by Claude)
```

### Using the bundle

#### Linux/macOS
```bash
# Create a symlink
ln -s ~/claude-code-doc/claude-code-markdown/m1f/*_docs.txt ~/claude-code-docs.txt

# Copy to another location
cp ~/claude-code-doc/claude-code-markdown/m1f/*_docs.txt /path/to/destination/

# Use with Claude
m1f-claude ~/claude-code-doc/claude-code-markdown/m1f/*_docs.txt
```

#### Windows
```powershell
# Create a symlink (requires admin privileges)
New-Item -ItemType SymbolicLink -Path "$env:USERPROFILE\claude-code-docs.txt" `
    -Target "$env:USERPROFILE\claude-code-doc\claude-code-markdown\m1f\*_docs.txt"

# Or just copy the file
Copy-Item "$env:USERPROFILE\claude-code-doc\claude-code-markdown\m1f\*_docs.txt" `
    -Destination "C:\path\to\destination\"

# Use with Claude
m1f-claude "$env:USERPROFILE\claude-code-doc\claude-code-markdown\m1f\*_docs.txt"
```

## Configuration

The included `html2md_claude_code_doc.config.yml` file contains optimized selectors for Claude Code documentation:
- Extracts main content from `div.max-w-8xl.px-4.mx-auto`
- Removes navigation, sidebars, search UI, and other non-content elements
- Preserves code blocks and formatting

## Options

- `--use-config CONFIG_FILE`: Use existing config (skip Claude analysis) - **recommended**
- `--force-download`: Re-download HTML files even if they exist
- `--delay SECONDS`: Delay between requests (default: 15)
- `--parallel`: Enable parallel HTML conversion (default: enabled)

## Requirements

- Python 3.10+
- m1f toolkit installed (`pip install -e .` from m1f root)
- Activated virtual environment (`.venv`)
- Internet connection
- Claude API access (only if not using --use-config)

## Notes

- The scraping delay is set to 15 seconds to be respectful of the server
- Always run from the m1f project root directory
- Make sure the virtual environment is activated before running
- Using the provided config file saves 5-8 minutes by skipping Claude analysis
- On Windows, use PowerShell for better command support
- Windows paths use backslashes (`\`) instead of forward slashes (`/`)

======= tests/html2md/parameter_test_coverage.md ======
# m1f-scrape Parameter Test Coverage Analysis

## All Available Parameters

### Input/Output
- `url` - ❌ Not tested with local server (only mocked)
- `-o, --output` - ✅ Tested in integration tests

### Output Control
- `-v, --verbose` - ❌ Not tested
- `-q, --quiet` - ❌ Not tested

### Scraper Options
- `--scraper` - ✅ Partially tested (only beautifulsoup in integration)
- `--scraper-config` - ❌ Not tested

### Crawl Configuration
- `--max-depth` - ✅ Tested (value: 2-3)
- `--max-pages` - ✅ Tested (value: 20)
- `--allowed-path` - ✅ Tested extensively
- `--excluded-paths` - ❌ Not tested (NEW)

### Request Options
- `--request-delay` - ✅ Tested (value: 0.1)
- `--concurrent-requests` - ✅ Tested (value: 2)
- `--user-agent` - ❌ Not tested
- `--timeout` - ❌ Not tested (NEW)
- `--retry-count` - ❌ Not tested (NEW)

### Content Filtering
- `--ignore-get-params` - ❌ Not tested
- `--ignore-canonical` - ❌ Not tested with local server
- `--ignore-duplicates` - ❌ Not tested

### Display Options
- `--list-files` - ❌ Not tested

### Security Options
- `--disable-ssrf-check` - ✅ Implicitly tested (check_ssrf=False used)

### Database Options
- `--show-db-stats` - ❌ Not tested
- `--show-errors` - ❌ Not tested
- `--show-scraped-urls` - ❌ Not tested

## Summary

**Tested with local server (7/24):**
- output, scraper (partial), max-depth, max-pages, allowed-path, request-delay, concurrent-requests, disable-ssrf-check (implicit)

**Not tested with local server (17/24):**
- url, verbose, quiet, scraper-config, excluded-paths, user-agent, timeout, retry-count, ignore-get-params, ignore-canonical, ignore-duplicates, list-files, show-db-stats, show-errors, show-scraped-urls

## Missing Test Coverage

### High Priority (Core functionality)
1. Different scraper backends (httrack, selectolax, playwright)
2. Content filtering (ignore-get-params, ignore-canonical, ignore-duplicates)
3. Excluded paths functionality
4. User agent customization

### Medium Priority (Important options)
1. Timeout and retry behavior
2. Database query options
3. List files option
4. Verbose/quiet output

### Low Priority (Less critical)
1. Scraper-specific config files

======= tests/html2md_server/README.md ======
# HTML2MD Test Suite

A comprehensive test suite for the html2md converter featuring a local web
server with challenging HTML test pages.

## Overview

This test suite provides:

- A Flask-based web server serving complex HTML test pages
- Modern, responsive HTML pages with various challenging structures
- Comprehensive pytest-based test cases
- Real-world documentation examples (M1F and HTML2MD docs)

## Features

### Test Pages

1. **M1F Documentation** - Complete documentation for the Make One File tool
2. **HTML2MD Documentation** - Full documentation for the HTML to Markdown
   converter
3. **Complex Layout Test** - Tests CSS Grid, Flexbox, nested structures, and
   positioning
4. **Code Examples Test** - Multiple programming languages with syntax
   highlighting
5. **Edge Cases Test** - Malformed HTML, special characters, and unusual
   structures
6. **Modern Features Test** - HTML5 elements, web components, and semantic
   markup
7. **Tables and Lists Test** - Complex tables and deeply nested lists
8. **Multimedia Test** - Images, videos, and other media elements

### Test Coverage

- ✅ CSS selector-based content extraction
- ✅ Complex nested HTML structures
- ✅ Code blocks with language detection
- ✅ Tables and lists conversion
- ✅ Special characters and Unicode
- ✅ YAML frontmatter generation
- ✅ Heading level adjustment
- ✅ Parallel processing
- ✅ Edge cases and error handling

## Setup

### Requirements

```bash
pip install flask flask-cors beautifulsoup4 markdownify pytest pytest-asyncio aiohttp
```

### Running the Test Server

```bash
# Start the test server
python tests/html2md_server/server.py

# Server will run at http://localhost:8080
```

### Running Tests

```bash
# Run all tests
pytest tests/test_html2md_server.py -v

# Run specific test
pytest tests/test_html2md_server.py::TestHTML2MDConversion::test_code_examples -v

# Run with coverage
pytest tests/test_html2md_server.py --cov=tools.mf1-html2md --cov-report=html
```

## Test Structure

```
tests/html2md_server/
├── server.py              # Flask test server
├── static/
│   ├── css/
│   │   └── modern.css    # Modern CSS with dark mode
│   └── js/
│       └── main.js       # Interactive features
├── test_pages/
│   ├── index.html        # Test suite homepage
│   ├── m1f-documentation.html
│   ├── html2md-documentation.html
│   ├── complex-layout.html
│   ├── code-examples.html
│   └── ...               # More test pages
└── README.md             # This file
```

## Usage Examples

### Manual Testing

1. Start the server:

   ```bash
   python tests/html2md_server/server.py
   ```

2. Test conversion with various options:

   ```bash
   # Basic conversion
   m1f-html2md \
     --source-dir http://localhost:8080/page \
     --destination-dir ./output

   # With content selection
   m1f-html2md \
     --source-dir http://localhost:8080/page \
     --destination-dir ./output \
     --outermost-selector "article" \
     --ignore-selectors "nav" ".sidebar" "footer"

   # Specific page with options
   m1f-html2md \
     --source-dir http://localhost:8080/page/code-examples \
     --destination-dir ./output \
     --add-frontmatter \
     --heading-offset 1
   ```

### Automated Testing

The test suite includes comprehensive pytest tests:

```python
# Example test structure
class TestHTML2MDConversion:
    async def test_basic_conversion(self, test_server, temp_output_dir):
        """Test basic HTML to Markdown conversion."""

    async def test_content_selection(self, test_server, temp_output_dir):
        """Test CSS selector-based content extraction."""

    async def test_code_examples(self, test_server, temp_output_dir):
        """Test code block conversion with various languages."""
```

## Adding New Test Pages

1. Create a new HTML file in `test_pages/`
2. Add an entry to `TEST_PAGES` in `server.py`
3. Include challenging HTML structures
4. Add corresponding test cases in `test_html2md_server.py`

Example:

```python
# In server.py
TEST_PAGES = {
    'your-new-test': {
        'title': 'Your New Test',
        'description': 'Description of what this tests'
    }
}
```

## Features Tested

### HTML Elements

- Headings (h1-h6)
- Paragraphs and text formatting
- Lists (ordered, unordered, nested)
- Tables (simple and complex)
- Code blocks and inline code
- Links and images
- Blockquotes
- Details/Summary elements

### CSS Layouts

- Flexbox
- CSS Grid
- Multi-column layouts
- Absolute/relative positioning
- Floating elements
- Sticky elements
- Overflow containers

### Special Cases

- Unicode and emoji
- HTML entities
- Special characters in code
- Very long lines
- Empty elements
- Malformed HTML
- Deeply nested structures

## Contributing

To add new test cases:

1. Identify a challenging HTML pattern
2. Create a test page demonstrating the pattern
3. Add test cases to verify correct conversion
4. Document the test purpose and expected behavior

## License

Part of the M1F project. See main project license.

======= tests/html2md_server/requirements.txt ======
# HTML2MD Test Server Requirements

# Web Framework
flask>=2.3.0
flask-cors>=4.0.0

# HTML Processing
beautifulsoup4>=4.12.0
markdownify>=0.11.0
lxml>=4.9.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0
pytest-timeout>=2.1.0

# HTTP Client for Tests
aiohttp>=3.8.0
requests>=2.31.0

# Utilities
pyyaml>=6.0
chardet>=5.2.0
psutil>=5.9.0

# Development
black>=23.0.0
flake8>=6.0.0
mypy>=1.5.0 

======= tests/m1f/README.md ======
# M1F Test Suite

Comprehensive test suite for the m1f (Make One File) tool with 23 test files and ~180 test methods, covering all aspects of functionality, security, and performance.

## 📁 Test Structure

```
tests/m1f/
├── README.md                             # This file
├── conftest.py                           # m1f-specific test fixtures
│
├── Core Functionality Tests
│   ├── test_m1f_basic.py                # Basic operations and CLI options
│   ├── test_m1f_advanced.py             # Advanced features (archives, patterns)
│   ├── test_m1f_integration.py          # End-to-end integration tests
│   ├── test_m1f_edge_cases.py           # Edge cases and special scenarios
│   └── test_m1f.py                      # General functionality tests
│
├── Security & Safety Tests
│   ├── test_security_check.py           # Secret detection features
│   ├── test_path_traversal_security.py  # Path traversal vulnerability tests
│   └── test_content_deduplication.py    # File deduplication logic
│
├── Performance & Optimization Tests
│   ├── test_parallel_processing.py      # Async/parallel operations
│   ├── test_large_file.py              # Large file performance tests
│   └── test_cross_platform_paths.py    # Windows/Linux compatibility
│
├── Encoding & Character Tests
│   ├── test_m1f_encoding.py            # Character encoding handling
│   └── test_m1f_unicode.py             # Unicode handling tests
│
├── File System Tests
│   ├── test_symlinks.py                # Symbolic link handling
│   ├── test_symlinks_relative.py       # Relative symlink tests
│   ├── test_symlinks_deduplication.py  # Symlink deduplication
│   └── test_m1f_file_hash.py          # Filename mtime hash functionality
│
├── Preset System Tests (v3.2+ features)
│   ├── test_m1f_presets_basic.py       # Basic preset functionality
│   ├── test_m1f_presets_integration.py # Advanced preset scenarios
│   └── test_m1f_presets_v3_2.py       # v3.2 preset features
│
├── Advanced Filtering Tests
│   ├── test_multiple_exclude_include_files.py # Complex filtering
│   └── test_m1f_excludes.py            # Exclusion pattern tests
│
├── Test Data & Resources
│   ├── source/                         # Test data organized by scenario
│   │   ├── glob_*/                    # Pattern matching test cases
│   │   ├── exotic_encodings/          # Non-UTF8 encoding samples
│   │   ├── advanced_glob_test/        # Complex nested structures
│   │   ├── code/                      # Sample code files
│   │   ├── docs/                      # Sample documentation
│   │   └── config/                    # Sample configs
│   ├── exclude_paths.txt              # Sample exclusion file
│   └── input_paths.txt                # Sample input paths file
```

## 🧪 Test Categories

### 1. **Core Functionality** 
Tests fundamental m1f operations across multiple test files.

**Basic Operations** (`test_m1f_basic.py`):
- ✅ Basic file combination
- ✅ Separator styles (Standard, Detailed, Markdown, MachineReadable)
- ✅ Timestamp in filenames (`-t` flag)
- ✅ Line ending options (LF/CRLF)
- ✅ Dot file/directory inclusion
- ✅ Path exclusion from file
- ✅ Force overwrite (`-f`)
- ✅ Verbose/quiet modes

**Advanced Features** (`test_m1f_advanced.py`):
- 📦 Archive creation (ZIP, TAR.GZ)
- 🚫 Gitignore pattern support
- 📝 File extension filtering
- 🔍 Input paths with glob patterns
- 🔐 Filename mtime hash
- 🛠️ Disabling default excludes
- 🔢 Binary file inclusion

### 2. **Security & Safety**
Comprehensive security testing to prevent vulnerabilities.

**Secret Detection** (`test_security_check.py`):
- 🔍 Password and API key detection
- ⚙️ Security check modes (skip, warn, abort)
- 📝 Security warning logs
- ✅ Clean file verification

**Path Traversal** (`test_path_traversal_security.py`):
- 🛡️ Path traversal attack prevention
- 📁 Malicious path handling
- 🔒 Sandbox escape prevention
- ⚠️ Security boundary enforcement

**Content Deduplication** (`test_content_deduplication.py`):
- #️⃣ SHA256-based deduplication
- 🔄 Duplicate file detection
- 📊 Deduplication statistics
- 💾 Memory efficiency

### 3. **Performance & Scalability**

**Parallel Processing** (`test_parallel_processing.py`):
- ⚡ Async file operations
- 🔀 Concurrent processing
- 📈 Performance benchmarks
- 🎯 Resource optimization

**Large Files** (`test_large_file.py`):
- 📊 Various file sizes (0.5MB - 10MB)
- 💾 Memory efficiency
- ⚡ Processing speed
- ✅ Content integrity

**Cross-Platform** (`test_cross_platform_paths.py`):
- 🪟 Windows path handling
- 🐧 Linux/macOS compatibility
- 🔀 Path separator normalization
- 📁 Drive letter handling

### 4. **Encoding & Internationalization**

**Encoding Support** (`test_m1f_encoding.py`):
- 🔤 UTF-8, UTF-16, Latin-1
- 🌏 Exotic encodings:
  - Shift-JIS (Japanese)
  - GB2312 (Chinese)
  - EUC-KR (Korean)
  - KOI8-R (Russian)
  - ISO-8859-8 (Hebrew)
  - Windows-1256 (Arabic)
- ⚠️ Encoding error handling
- 💾 BOM handling

**Unicode** (`test_m1f_unicode.py`):
- 🌍 Unicode filename support
- 😀 Emoji in content
- 🎭 Special characters
- 📝 Unicode normalization

### 5. **File System Features**

**Symbolic Links** (3 test files):
- 🔗 Basic symlink handling (`test_symlinks.py`)
- 📍 Relative symlinks (`test_symlinks_relative.py`)
- 🔄 Symlink deduplication (`test_symlinks_deduplication.py`)
- 🚫 Circular reference detection
- 📝 Target resolution

**File Hash** (`test_m1f_file_hash.py`):
- #️⃣ Modification time hashing
- 🔒 Hash consistency
- 🔄 Change detection
- 📁 Directory handling

### 6. **Preset System** (v3.2+)

**Basic Presets** (`test_m1f_presets_basic.py`):
- 🎨 Global preset settings
- 📝 File-specific processors
- 🧹 Content cleaning

**Advanced Presets** (`test_m1f_presets_integration.py`):
- 🔗 Preset inheritance
- 🌍 Environment-based presets
- 🎯 Conditional presets
- 🔧 Complex workflows

**v3.2 Features** (`test_m1f_presets_v3_2.py`):
- 📁 Source/output configuration
- 📋 Input include files
- ⚙️ Runtime behavior settings
- 🔄 CLI argument overrides

### 7. **Advanced Filtering**

**Multiple Files** (`test_multiple_exclude_include_files.py`):
- 📋 Multiple exclude files
- ✅ Multiple include files
- 🔀 Combined exclude/include
- ⚠️ Error handling

**Exclusion Patterns** (`test_m1f_excludes.py`):
- 🎯 Glob pattern exclusions
- 📝 Regex exclusions
- 🔍 Gitignore integration
- 📁 Directory exclusions

## 🧪 Test Fixtures (conftest.py)

**Core Fixtures:**
- `m1f_source_dir` - Source directory for test files
- `m1f_output_dir` - Output directory with auto-cleanup
- `m1f_extracted_dir` - Extraction directory
- `run_m1f` - Direct function testing with mocked args
- `m1f_cli_runner` - Subprocess-based CLI testing
- `create_m1f_test_structure` - Standard test directory creation

**Utilities:**
- Cross-platform path handling
- Automatic cleanup on Windows
- Test file creation helpers
- Directory structure builders

## 🚀 Running Tests

### Run All M1F Tests
```bash
pytest tests/m1f/ -v
```

### Run Specific Categories
```bash
# By marker
pytest tests/m1f/ -m unit
pytest tests/m1f/ -m integration
pytest tests/m1f/ -m encoding
pytest tests/m1f/ -m "not slow"
pytest tests/m1f/ -m requires_git

# By test file pattern
pytest tests/m1f/test_*security*.py -v
pytest tests/m1f/test_*encoding*.py -v
pytest tests/m1f/test_*preset*.py -v
```

### Run Individual Tests
```bash
# Specific test file
pytest tests/m1f/test_m1f_basic.py -v

# Specific test method
pytest tests/m1f/test_m1f_encoding.py::TestM1FEncoding::test_exotic_encodings -v

# Tests matching pattern
pytest tests/m1f/ -k "test_encoding" -v
```

### Debug Options
```bash
# Stop on first failure
pytest tests/m1f/ -x

# Show print statements
pytest tests/m1f/ -s

# Drop into debugger
pytest tests/m1f/ --pdb

# Verbose with full diff
pytest tests/m1f/ -vv
```

## 📊 Coverage Analysis

```bash
# Run with coverage
pytest tests/m1f/ --cov=tools.m1f --cov-report=html --cov-report=term

# View coverage report
open htmlcov/index.html
```

**Coverage Goals:**
- Core functionality: 100%
- Edge cases: >95%
- Error handling: >90%
- Platform-specific: >85%

## 🧪 Test Data Organization

### Pattern Testing (`source/glob_*`)
- Basic glob patterns
- Recursive patterns
- Multiple wildcards
- Directory-specific patterns

### Encoding Samples (`source/exotic_encodings/`)
- Text files in various encodings
- International content
- BOM variations
- Mixed encodings

### Complex Structures (`source/advanced_glob_test/`)
- Deep nesting (5+ levels)
- International filenames
- Mixed file types
- Large directory trees

### Real-World Examples
- Code files (Python, JavaScript, etc.)
- Documentation (Markdown, RST)
- Configuration (YAML, JSON, INI)
- Binary files (images, archives)

## 📝 Writing New Tests

### Test Template
```python
from __future__ import annotations

import pytest
from pathlib import Path
from ..conftest import M1FTestContext

class TestNewFeature:
    """Tests for new m1f feature."""
    
    @pytest.mark.unit
    async def test_feature_basic(self, run_m1f: M1FTestContext):
        """Test basic feature functionality."""
        # Arrange
        test_file = run_m1f.create_file("test.txt", "content")
        
        # Act
        result = await run_m1f.execute([
            str(test_file),
            "-o", str(run_m1f.output_dir / "output.txt")
        ])
        
        # Assert
        assert result.returncode == 0
        assert "expected output" in result.stdout
```

### Best Practices
1. **Use fixtures** - Don't create files manually
2. **Test isolation** - Each test should be independent
3. **Clear naming** - Test name should describe behavior
4. **Appropriate markers** - Use unit/integration/slow markers
5. **Cleanup** - Fixtures handle cleanup automatically
6. **Cross-platform** - Consider Windows/Linux differences

## 🔧 Troubleshooting

### Common Issues

**Windows-Specific:**
- File locking during cleanup
- Path length limitations
- Case-insensitive paths
- Line ending differences

**Encoding Issues:**
- System locale dependencies
- Missing codec support
- BOM handling differences

**Performance:**
- Slow tests not marked
- Resource cleanup delays
- Large test data files

### Solutions
```bash
# Skip slow tests
pytest -m "not slow"

# Run with specific encoding
PYTHONIOENCODING=utf-8 pytest

# Increase timeout
pytest --timeout=300

# Clean test artifacts
rm -rf tests/m1f/output_* tests/m1f/extracted_*
```

## 🛠️ Maintenance

- **Regular cleanup** - Remove obsolete test data
- **Performance monitoring** - Track test suite execution time
- **Coverage tracking** - Maintain high coverage
- **Dependency updates** - Keep test dependencies current
- **Documentation** - Update this README with new tests

======= tests/m1f/exclude_paths.txt ======
# Paths to exclude from processing
# One path per line
code/index.php
docs/png.png
# Empty line below should be ignored

# This is a comment line

======= tests/m1f/input_paths.txt ======
# Input paths for testing
source/code/python/hello.py
source/code/python/utils.py
source/docs/README.md

======= tests/research/README.md ======
# M1F-Research Test Suite

Comprehensive test suite for the m1f-research tool with 5 test files and ~25 test methods, covering research workflows, LLM integration, and content analysis.

## 📁 Test Structure

```
tests/research/
├── README.md                           # This file
├── conftest.py                         # Research-specific test fixtures (if exists)
│
├── Core Workflow Tests
│   ├── test_research_workflow.py       # End-to-end research workflows
│   └── test_scraping_integration.py    # Web scraping integration
│
├── Analysis Tests
│   ├── test_content_analysis.py        # Content analysis and scoring
│   └── test_analysis_templates.py      # Template system tests
│
└── Provider Tests
    └── test_llm_providers.py           # LLM provider integrations
```

## 🧪 Test Categories

### 1. **Research Workflows**

**End-to-End Workflows** (`test_research_workflow.py`):
- 🔄 Complete research pipelines
- 📊 Multi-stage processing
- 🎯 Goal-oriented workflows
- 📝 Report generation
- ⚡ Workflow optimization

**Scraping Integration** (`test_scraping_integration.py`):
- 🌐 Full scraping workflow
- 🔀 Concurrent scraping behavior
- 🔄 Retry mechanisms
- ⏱️ Rate limiting compliance
- 🤖 Robots.txt respect
- 📝 HTML to Markdown conversion
- ⚠️ Error handling
- 📊 Progress tracking
- 📋 Metadata extraction

### 2. **Content Analysis**

**Content Analysis** (`test_content_analysis.py`):
- 🔍 Content filtering pipeline
- 🚫 Spam detection
- 🌍 Language detection
- 📊 Quality scoring
- 🔄 Duplicate detection
- 🤖 LLM-based analysis
- 📋 Template-based scoring
- 🔀 Batch processing
- ⚠️ Error recovery

**Analysis Templates** (`test_analysis_templates.py`):
- 📋 Template loading and parsing
- 🎯 Template application
- 🔧 Custom template creation
- 📊 Scoring adjustments
- 🔄 Template inheritance
- ⚙️ Dynamic templates

### 3. **LLM Provider Integration**

**Provider Tests** (`test_llm_providers.py`):
- 🤖 Provider abstraction layer
- 🔌 Multiple provider support
- 🔄 Fallback mechanisms
- 📊 Response parsing
- ⚠️ Error handling
- 💰 Cost tracking
- 🚦 Rate limit handling
- 🔐 Authentication

## 🧪 Test Fixtures

**Core Fixtures:**
- `default_scraping_config` - Standard scraping configuration
- `default_analysis_config` - Standard analysis configuration
- `mock_llm_provider` - Mock LLM provider for testing
- `mock_aiohttp_session` - Mock HTTP session
- `sample_scraped_content_list` - Sample scraped content
- `temp_dir` - Temporary directory for test files

**Mock Objects:**
- LLM API responses
- Web scraping results
- Content analysis outputs
- Template configurations

## 🚀 Running Tests

### Run All Research Tests
```bash
pytest tests/research/ -v
```

### Run Specific Test Files
```bash
# Workflow tests
pytest tests/research/test_research_workflow.py -v

# Scraping tests
pytest tests/research/test_scraping_integration.py -v

# Analysis tests
pytest tests/research/test_content_analysis.py -v

# LLM provider tests
pytest tests/research/test_llm_providers.py -v
```

### Run with Options
```bash
# Async test support
pytest tests/research/ -v --asyncio-mode=auto

# Show output
pytest tests/research/ -s

# Run specific test
pytest tests/research/test_scraping_integration.py::TestScrapingIntegration::test_full_scraping_workflow -v

# With coverage
pytest tests/research/ --cov=tools.research --cov-report=html
```

## 📊 Test Coverage

**Scraping Integration:**
- URL processing and validation
- Concurrent request handling
- Rate limiting and delays
- Retry logic with backoff
- Robots.txt compliance
- HTML to Markdown conversion
- Error recovery strategies

**Content Analysis:**
- Quality assessment algorithms
- Language detection accuracy
- Spam filtering effectiveness
- Duplicate detection methods
- LLM prompt engineering
- Template matching logic
- Batch processing efficiency

**LLM Integration:**
- Provider initialization
- API request formatting
- Response parsing
- Token usage tracking
- Cost calculation
- Error handling
- Fallback strategies

## 🧪 Testing Patterns

### Async Testing
```python
@pytest.mark.asyncio
async def test_async_workflow():
    """Test async research workflow."""
    async with aiohttp.ClientSession() as session:
        result = await research_function(session)
        assert result.success
```

### Mock LLM Providers
```python
def test_llm_analysis(mock_llm_provider):
    """Test with mocked LLM."""
    mock_llm_provider.analyze.return_value = AsyncMock(
        return_value={"score": 0.9, "summary": "test"}
    )
    # Test implementation
```

### Integration Testing
```python
async def test_full_pipeline():
    """Test complete research pipeline."""
    # Setup
    config = ResearchConfig(...)
    
    # Execute
    results = await run_research_pipeline(config)
    
    # Verify
    assert all(r.analyzed for r in results)
```

## 📝 Writing New Tests

### Test Template
```python
from __future__ import annotations

import pytest
from unittest.mock import AsyncMock
from tools.research import ResearchWorkflow

class TestNewFeature:
    """Tests for new research feature."""
    
    @pytest.mark.asyncio
    async def test_feature(self, mock_llm_provider, sample_scraped_content_list):
        """Test description."""
        # Arrange
        workflow = ResearchWorkflow(
            llm_provider=mock_llm_provider
        )
        
        # Act
        results = await workflow.process(sample_scraped_content_list)
        
        # Assert
        assert len(results) > 0
        assert all(r.processed for r in results)
```

### Best Practices
1. **Use async fixtures** - For async components
2. **Mock external APIs** - Don't make real API calls
3. **Test error paths** - Include failure scenarios
4. **Verify concurrency** - Test parallel execution
5. **Check rate limits** - Ensure compliance

## 🔧 Troubleshooting

### Common Issues

**Async Test Failures:**
- Ensure `pytest-asyncio` is installed
- Use `@pytest.mark.asyncio` decorator
- Handle async context managers properly

**Mock Issues:**
- Use `AsyncMock` for async functions
- Configure return values correctly
- Reset mocks between tests

**Integration Problems:**
- Check fixture dependencies
- Verify test data consistency
- Monitor resource cleanup

### Debug Commands
```bash
# Run with debug logging
pytest tests/research/ -v --log-cli-level=DEBUG

# Run with traceback
pytest tests/research/ --tb=long

# Run specific test with output
pytest tests/research/test_content_analysis.py::test_spam_detection -vvs
```

## 🛠️ Maintenance

- **Mock updates** - Keep mocks synchronized with actual APIs
- **Test data** - Update sample content regularly
- **Performance** - Monitor test execution time
- **Coverage** - Maintain comprehensive test coverage
- **Documentation** - Update when adding new features

======= tests/s1f/README.md ======
# S1F Test Suite

Comprehensive test suite for the s1f (Split One File) tool with 6 test files and ~40 test methods, covering extraction, encoding, and security features.

## 📁 Test Structure

```
tests/s1f/
├── README.md                          # This file
├── conftest.py                        # s1f-specific test fixtures
│
├── Core Tests
│   ├── test_s1f_basic.py             # Core extraction functionality
│   ├── test_s1f.py                   # General functionality tests
│   └── test_s1f_async.py             # Asynchronous operations
│
├── Encoding Tests
│   ├── test_s1f_encoding.py          # Character encoding preservation
│   └── test_s1f_target_encoding.py   # Encoding conversion tests
│
├── Security Tests
│   └── test_path_traversal_security.py # Path traversal protection
│
└── Test Resources
    ├── output/                        # Pre-generated M1F bundles
    ├── extracted/                     # Extraction target directory
    └── source/                        # Source files for testing
```

## 🧪 Test Categories

### 1. **Core Functionality**

**Basic Extraction** (`test_s1f_basic.py`):
- ✅ All M1F separator styles (Standard, Detailed, Markdown, MachineReadable)
- ✅ File path preservation
- ✅ Directory structure reconstruction
- ✅ Content integrity verification
- ✅ Metadata extraction
- ✅ Force overwrite (`-f`) option
- ✅ Timestamp handling

**General Operations** (`test_s1f.py`):
- 📋 Command-line interface testing
- 🔍 Format auto-detection
- 📁 Output directory creation
- ⚠️ Error handling
- 📊 Statistics reporting

**Async Operations** (`test_s1f_async.py`):
- ⚡ Asynchronous file extraction
- 🔀 Concurrent processing
- 📈 Performance optimization
- 💾 Memory efficiency

### 2. **Encoding & Character Handling**

**Encoding Preservation** (`test_s1f_encoding.py`):
- 🔤 UTF-8, UTF-16, Latin-1 preservation
- 🌏 Exotic encoding support
- 💾 BOM handling
- ✅ Binary file extraction
- 📝 Encoding metadata

**Target Encoding** (`test_s1f_target_encoding.py`):
- 🔄 Encoding conversion during extraction
- 🎯 Target encoding specification
- ⚠️ Conversion error handling
- 📊 Encoding statistics

### 3. **Security Features**

**Path Traversal Protection** (`test_path_traversal_security.py`):
- 🛡️ Path traversal attack prevention
- 📁 Malicious path sanitization
- 🔒 Sandbox enforcement
- ⚠️ Security warnings
- ✅ Safe path validation

## 🧪 Test Fixtures (conftest.py)

**Core Fixtures:**
- `s1f_output_dir` - Output directory with auto-cleanup
- `s1f_extracted_dir` - Extraction directory
- `create_combined_file` - Creates test M1F files
- `run_s1f` - Direct function testing
- `s1f_cli_runner` - Subprocess CLI testing
- `create_m1f_output` - Uses real M1F tool for test input

**Separator Styles:**
- Standard: `############ filename ############`
- Detailed: `### START: filename ###`
- Markdown: `## filename`
- MachineReadable: JSON metadata format

## 🚀 Running Tests

### Run All S1F Tests
```bash
pytest tests/s1f/ -v
```

### Run Specific Categories
```bash
# Core functionality
pytest tests/s1f/test_s1f_basic.py -v

# Encoding tests
pytest tests/s1f/test_*encoding*.py -v

# Security tests
pytest tests/s1f/test_*security*.py -v

# Async tests
pytest tests/s1f/test_*async*.py -v
```

### Run with Options
```bash
# Show output
pytest tests/s1f/ -s

# Stop on first failure
pytest tests/s1f/ -x

# Verbose with full diff
pytest tests/s1f/ -vv

# Run specific test
pytest tests/s1f/test_s1f_basic.py::test_extract_standard -v
```

## 📊 Test Coverage

**Core Features:**
- All M1F format variations
- Path preservation accuracy
- Content integrity (SHA-256)
- Metadata handling

**Edge Cases:**
- Empty files
- Binary files
- Large files
- Nested directories
- Special characters
- Unicode filenames

**Error Handling:**
- Corrupted M1F files
- Missing separators
- Invalid paths
- Encoding errors

## 🧪 Test Data

### Pre-generated M1F Files
The test suite uses pre-generated M1F bundles in various formats:
```bash
output/standard.txt       # Standard separator style
output/detailed.txt       # Detailed separator style
output/markdown.txt       # Markdown separator style
output/machinereadable.txt # JSON metadata style
```

### Creating Test Data
Test data is automatically generated by fixtures using the real M1F tool:
```python
# Example from conftest.py
def create_m1f_output(source_dir, output_file, separator_style):
    """Creates M1F bundle for testing."""
    result = subprocess.run([
        "m1f",
        str(source_dir),
        "-o", str(output_file),
        "--separator-style", separator_style,
        "--force"
    ])
```

## 📝 Writing New Tests

### Test Template
```python
from __future__ import annotations

import pytest
from pathlib import Path

class TestNewFeature:
    """Tests for new s1f feature."""
    
    @pytest.mark.unit
    def test_feature(self, run_s1f, create_combined_file):
        """Test description."""
        # Arrange
        m1f_file = create_combined_file(
            "test.txt", 
            "content",
            separator_style="Standard"
        )
        
        # Act
        result = run_s1f([
            str(m1f_file),
            "-o", "output_dir"
        ])
        
        # Assert
        assert result.returncode == 0
        assert Path("output_dir/test.txt").exists()
```

### Best Practices
1. **Use fixtures** - Don't create M1F files manually
2. **Test all formats** - Verify with all separator styles
3. **Verify integrity** - Check content matches original
4. **Clean paths** - Fixtures handle cleanup
5. **Cross-platform** - Consider path separators

## 🔧 Troubleshooting

### Common Issues

**Format Detection:**
- Ensure M1F files have correct separators
- Check for file corruption
- Verify encoding compatibility

**Path Issues:**
- Windows path length limits
- Case sensitivity differences
- Path separator normalization

**Encoding Problems:**
- System locale settings
- Missing codec support
- BOM handling

### Debug Commands
```bash
# Run with debugging
pytest tests/s1f/ --pdb

# Check test output
pytest tests/s1f/ -s --log-cli-level=DEBUG

# Run single test with tracing
pytest tests/s1f/test_s1f_basic.py::test_extract_standard -vvs
```

## 🛡️ Security Testing

The test suite includes security tests for:
- Path traversal attempts (`../../../etc/passwd`)
- Absolute path injections
- Symbolic link attacks
- Directory escape attempts

## 🚀 Performance

- Tests use async I/O where applicable
- Parallel extraction support
- Memory-efficient streaming
- Large file handling

## 🛠️ Maintenance

- **Test data** - Regenerate M1F files after format changes
- **Fixtures** - Keep fixtures simple and focused
- **Coverage** - Maintain >90% code coverage
- **Performance** - Monitor test execution time

======= tools/research/README.md ======
# m1f-research

> **Note**: This documentation has been moved to
> [docs/06_research/](../../docs/06_research/)

AI-powered research tool that automatically finds, scrapes, and bundles
information on any topic.

## Overview

m1f-research extends the m1f toolkit with intelligent research capabilities. It
uses LLMs to:

- Find relevant URLs for any research topic
- Scrape and convert web content to clean Markdown
- Analyze content for relevance and extract key insights
- Create organized research bundles

## Quick Start

```bash
# Basic research
m1f-research "microservices best practices"

# Research with more sources
m1f-research "react state management" --urls 30 --scrape 15

# Research with manual URL list
m1f-research "python async" --urls-file my-links.txt

# Resume an existing job
m1f-research --resume abc123

# Add more URLs to existing job
m1f-research --resume abc123 --urls-file more-links.txt

# List all research jobs
m1f-research --list-jobs

# Check job status
m1f-research --status abc123

# Use different LLM provider
m1f-research "machine learning" --provider gemini

# Interactive mode
m1f-research --interactive
```

## Installation

m1f-research is included with the m1f toolkit. Ensure you have:

1. m1f installed with the research extension
2. An API key for your chosen LLM provider:
   - Claude: Set `ANTHROPIC_API_KEY`
   - Gemini: Set `GOOGLE_API_KEY`

## Features

### 🗄️ Job Management

- **Persistent Jobs**: All research jobs are tracked in a SQLite database
- **Resume Support**: Continue interrupted research or add more URLs
- **Job History**: View all past research with statistics
- **Per-Job Database**: Each job has its own database for URL/content tracking

### 🔍 Intelligent Search

- Uses LLMs to find high-quality, relevant URLs
- Focuses on authoritative sources
- Mixes different content types (tutorials, docs, discussions)
- **Manual URL Support**: Add your own URLs via --urls-file

### 📥 Smart Scraping

- **Per-Host Delay Management**: Only delays after 3+ requests to same host
- Concurrent scraping with intelligent scheduling
- Automatic HTML to Markdown conversion
- Handles failures gracefully
- **Content Deduplication**: Tracks content by checksum

### 🧠 Content Analysis

- Relevance scoring (0-10 scale)
- Key points extraction
- Content summarization
- Duplicate detection

### 📦 Organized Bundles

- **Hierarchical Output**: YYYY/MM/DD directory structure
- **Prominent Bundle Files**: 📚_RESEARCH_BUNDLE.md and 📊_EXECUTIVE_SUMMARY.md
- Clean Markdown output
- Table of contents
- Source metadata
- Relevance-based ordering

## Usage Examples

### Basic Research

```bash
# Research a programming topic
m1f-research "golang error handling"

# Output saved to: ./research-data/golang-error-handling-20240120-143022/
```

### Advanced Options

```bash
# Specify output location and name
m1f-research "kubernetes security" \
  --output ./research \
  --name k8s-security

# Use a specific template
m1f-research "react hooks" --template technical

# Skip analysis for faster results
m1f-research "python asyncio" --no-analysis

# Dry run to see what would happen
m1f-research "rust ownership" --dry-run
```

### Configuration File

```bash
# Use a custom configuration
m1f-research "database optimization" --config research.yml
```

## Configuration

### Command Line Options

| Option             | Description                   | Default          |
| ------------------ | ----------------------------- | ---------------- |
| `--urls`           | Number of URLs to find        | 20               |
| `--scrape`         | Number of URLs to scrape      | 10               |
| `--output`         | Output directory              | ./research-data  |
| `--name`           | Bundle name                   | auto-generated   |
| `--provider`       | LLM provider                  | claude           |
| `--model`          | Specific model                | provider default |
| `--template`       | Research template             | general          |
| `--concurrent`     | Max concurrent scrapes        | 5                |
| `--no-filter`      | Disable filtering             | false            |
| `--no-analysis`    | Skip analysis                 | false            |
| `--interactive`    | Interactive mode              | false            |
| `--dry-run`        | Preview only                  | false            |
| **Job Management** |                               |                  |
| `--resume`         | Resume existing job by ID     | None             |
| `--list-jobs`      | List all research jobs        | false            |
| `--status`         | Show job status by ID         | None             |
| `--urls-file`      | File with URLs (one per line) | None             |

### Configuration File (.m1f.config.yml)

```yaml
research:
  # LLM settings
  llm:
    provider: claude
    model: claude-3-opus-20240229
    temperature: 0.7

  # Default counts
  defaults:
    url_count: 30
    scrape_count: 15

  # Scraping behavior
  scraping:
    timeout_range: "1-3"
    max_concurrent: 5
    retry_attempts: 2

  # Content analysis
  analysis:
    relevance_threshold: 7.0
    min_content_length: 100
    prefer_code_examples: true

  # Output settings
  output:
    directory: ./research-data
    create_summary: true
    create_index: true

  # Research templates
  templates:
    technical:
      description: "Technical documentation and code"
      url_count: 30
      analysis_focus: implementation

    academic:
      description: "Academic papers and theory"
      url_count: 20
      analysis_focus: theory
```

## Templates

Pre-configured templates optimize research for different needs:

### technical

- Focuses on implementation details
- Prioritizes code examples
- Higher URL count for comprehensive coverage

### academic

- Emphasizes theoretical content
- Looks for citations and references
- Filters for authoritative sources

### tutorial

- Searches for step-by-step guides
- Prioritizes beginner-friendly content
- Includes examples and exercises

### general (default)

- Balanced approach
- Mixes different content types
- Suitable for most topics

## Output Structure

Research bundles are organized with hierarchical date structure:

```
./research-data/
├── research_jobs.db              # Main job tracking database
├── latest_research.md           # Symlink to most recent bundle
└── 2025/
    └── 07/
        └── 22/
            └── abc123_topic-name/
                ├── research.db           # Job-specific database
                ├── 📚_RESEARCH_BUNDLE.md # Main research bundle
                ├── 📊_EXECUTIVE_SUMMARY.md # Executive summary
                ├── research-bundle.md    # Standard bundle
                ├── metadata.json         # Research metadata
                └── search_results.json   # Found URLs
```

### Bundle Format

```markdown
# Research: [Your Topic]

Generated on: 2024-01-20 14:30:22 Total sources: 10

---

## Table of Contents

1. [Source Title 1](#1-source-title-1)
2. [Source Title 2](#2-source-title-2) ...

---

## Summary

[Research summary and top sources]

---

## 1. Source Title

**Source:** https://example.com/article **Relevance:** 8.5/10

### Key Points:

- Important point 1
- Important point 2

### Content:

[Full content in Markdown]

---
```

## Providers

### Claude (Anthropic)

- Default provider
- Best for: Comprehensive research, nuanced analysis
- Set: `ANTHROPIC_API_KEY`

### Claude Code SDK

- Use `--provider claude-cli` for Claude Code SDK integration
- Provides proper session management and streaming
- No API key needed if using Claude Code authentication

### Gemini (Google)

- Fast and efficient
- Best for: Quick research, technical topics
- Set: `GOOGLE_API_KEY`

### CLI Tools

- Use local tools like `gemini-cli`
- Best for: Privacy, offline capability
- Example: `--provider gemini-cli`

## Tips

1. **Start broad, then narrow**: Use more URLs initially, let analysis filter
2. **Use templates**: Match template to your research goal
3. **Interactive mode**: Great for exploratory research
4. **Combine with m1f**: Feed research bundles into m1f for AI analysis

## Troubleshooting

### No API Key

```
Error: API key not set for ClaudeProvider
```

Solution: Set environment variable or pass in config

### Rate Limiting

```
Error: 429 Too Many Requests
```

Solution: Reduce `--concurrent` or increase timeout range

### Low Quality Results

- Increase `--urls` for more options
- Adjust `relevance_threshold` in config
- Try different `--template`

## Database Architecture

### Main Database (research_jobs.db)

Tracks all research jobs:

- Job ID, query, status, timestamps
- Configuration used
- Statistics (URLs found, scraped, analyzed)

### Per-Job Database (research.db)

Tracks job-specific data:

- URLs (source, status, checksums)
- Content (markdown, metadata)
- Analysis results (scores, key points)

### Smart Delay Management

The scraper implements intelligent per-host delays:

- No delay for first 3 requests to a host
- Random 1-3 second delay after threshold
- Allows fast parallel scraping of different hosts

## Future Features

- Multi-source research (GitHub, arXiv, YouTube)
- Knowledge graph building
- Research collaboration
- Custom source plugins
- Web UI
- Export to various formats (PDF, DOCX)
- Integration with note-taking tools

## Contributing

m1f-research is part of the m1f project. Contributions welcome!

- Report issues: [GitHub Issues](https://github.com/m1f/m1f/issues)
- Submit PRs: Follow m1f contribution guidelines
- Request features: Open a discussion

======= tools/shared/README.md ======
# Shared Utilities for m1f Tools

This module provides common functionality that can be used across all m1f tools.

## Overview

The `tools/shared` module contains reusable components for:

- Prompt loading and management
- Configuration file handling
- Path and text utilities

## Components

### Prompt Loader

Universal prompt loading system with caching and fallback support:

```python
from tools.shared.prompts import PromptLoader, load_prompt, format_prompt

# Create a loader with search paths
loader = PromptLoader([
    Path("my_tool/prompts"),
    Path("shared/prompts")
])

# Load a prompt
prompt = loader.load("analysis/synthesis.md")

# Load and format in one step
formatted = loader.format("analysis/synthesis.md",
    query="machine learning",
    summaries="..."
)

# Use the global loader
prompt = load_prompt("analysis/synthesis.md")
```

### Configuration Loader

Support for JSON, YAML, and TOML configuration files:

```python
from tools.shared.config import load_config_file, save_config_file, merge_configs

# Load configuration
config = load_config_file("config.yaml")

# Load with defaults and environment overrides
config = load_config_with_defaults(
    path="config.yaml",
    defaults={"timeout": 30},
    env_prefix="M1F_TOOL_"
)

# Merge multiple configs
final_config = merge_configs(defaults, file_config, cli_config)
```

### Path Utilities

Common path operations:

```python
from tools.shared.utils import ensure_path, get_project_root, find_files

# Ensure path exists and create parents
path = ensure_path("output/results.txt", create_parents=True)

# Find project root
root = get_project_root()

# Find all Python files
for py_file in find_files(root, "**/*.py", exclude_dirs=[".venv", "__pycache__"]):
    print(py_file)
```

### Text Utilities

Text processing helpers:

```python
from tools.shared.utils import truncate_text, clean_whitespace, extract_json_from_text

# Truncate with word boundaries
truncated = truncate_text(long_text, max_length=100, break_on_word=True)

# Clean whitespace while preserving paragraphs
cleaned = clean_whitespace(messy_text, preserve_paragraphs=True)

# Extract JSON from mixed content
json_str = extract_json_from_text(response_with_json)
```

## Adding to Your Tool

1. Import what you need:

```python
from tools.shared.prompts import PromptLoader
from tools.shared.config import load_config_file
from tools.shared.utils import ensure_path
```

2. Add your tool's prompt directory to the loader:

```python
loader = PromptLoader([
    Path(__file__).parent / "prompts",
    Path(__file__).parent.parent / "shared/prompts"
])
```

3. Use the utilities in your code:

```python
# Load and format a prompt
prompt = loader.format("my_prompt.md", variable="value")

# Load configuration
config = load_config_file("config.yaml")

# Ensure output path exists
output_path = ensure_path("output/result.txt", create_parents=True)
```

## Prompt Organization

Prompts should be organized by tool and category:

```
tools/shared/prompts/
├── research/           # Research tool prompts
│   ├── analysis/       # Analysis prompts
│   ├── bundle/         # Bundle creation prompts
│   └── llm/           # LLM interaction prompts
├── html2md/           # HTML to Markdown prompts
└── common/            # Shared prompts
```

## Best Practices

1. **Prompt Loading**: Always use the PromptLoader for consistency and caching
2. **Configuration**: Use `load_config_with_defaults()` for robust config
   handling
3. **Paths**: Use `ensure_path()` to avoid path-related errors
4. **Text Processing**: Use the provided utilities instead of reimplementing

## Contributing

When adding new shared functionality:

1. Place it in the appropriate submodule
2. Add comprehensive docstrings
3. Include type hints
4. Add unit tests
5. Update this README

======= tools/html2md_tool/prompts/analyze_individual_file.md ======
# Individual HTML File Analysis

You are analyzing a single HTML file to understand its structure for optimal
content extraction.

## Your Task

Read the HTML file: {filename}

Analyze this file's structure and write your findings to: {output_path}

## Analysis Criteria

For this HTML file, document:

### 1. Content Structure

```
Main Content Location:
- Primary container: [exact selector]
- Parent hierarchy: [body > ... > main]
- Semantic tags used: [main, article, section, etc.]
- Content-specific classes: [.content, .prose, .markdown-body, etc.]
- Content boundaries: [where content starts/ends]
```

### 2. Navigation & UI Elements

```
Elements to Exclude:
- Header/Navigation: [selectors]
- Sidebar: [selectors]
- Footer: [selectors]
- Breadcrumbs: [selectors]
- TOC/Page outline: [selectors]
- Meta information: [selectors]
- Interactive widgets: [selectors]
```

### 3. Special Content Types

```
Within Main Content:
- Code blocks: [how they're marked]
- Callout boxes: [info, warning, tip patterns]
- Tables: [table wrapper classes]
- Images/Media: [figure elements, wrappers]
- Examples/Demos: [interactive elements to preserve]
```

### 4. Page-Specific Observations

```
Page Type: [landing/guide/api/reference]
Unique Patterns: [anything specific to this page]
Potential Issues: [edge cases noticed]
```

## Output Format

Write your analysis to {output_path} in this exact format:

```
FILE: {filename}
URL PATH: [relative path]

CONTENT STRUCTURE:
- Main container: [selector]
- Backup selectors: [alternatives if main doesn't work]
- Content confidence: [High/Medium/Low]

EXCLUDE PATTERNS:
- Navigation: [selectors]
- UI Chrome: [selectors]
- Metadata: [selectors]

SPECIAL FINDINGS:
- [Any unique patterns]
- [Edge cases]
- [Warnings]

SUGGESTED SELECTORS:
outermost_selector: "[primary selector]"
ignore_selectors:
  - "[exclude 1]"
  - "[exclude 2]"
  - "[exclude 3]"
```

**CRITICAL REQUIREMENTS**:

1. **NEVER use empty strings** ("") as selectors
2. **Remove any empty or whitespace-only selectors** from lists
3. **Validate all selectors** are non-empty and properly formatted CSS selectors
4. Focus on this ONE file only - don't generalize to other files
5. **IMPORTANT**: After writing the analysis file, print "ANALYSIS_COMPLETE_OK"
   on the last line to confirm completion

======= tools/html2md_tool/prompts/analyze_selected_files.md ======
# HTML Structure Analysis for Optimal Content Extraction

use deep thinking The user wants a more systematic approach:

1. Create a task list
2. Analyze each file individually and save results
3. Then synthesize all analyses into final config This will produce much better
   results than trying to analyze all files at once.

## Context

The file m1f/selected_html_files.txt contains representative HTML files from the
documentation site.

## Task List

### Phase 1: Individual File Analysis

For each HTML file listed in m1f/selected_html_files.txt:

1. **Read the file** using the Read tool
2. **Perform deep structural analysis** (see analysis criteria below)
3. **Write detailed findings** to a separate analysis file:
   - File 1 → Write analysis to m1f/analysis/html_analysis_1.txt
   - File 2 → Write analysis to m1f/analysis/html_analysis_2.txt
   - etc. (continue for all files in the list)

### Phase 2: Synthesis

4. **Read all analysis files** (m1f/analysis/html_analysis_1.txt through
   m1f/analysis/html_analysis_N.txt where N is the number of files analyzed)
5. **Identify common patterns** across all analyses
6. **Create final YAML configuration** based on the synthesized findings

## Deep Analysis Criteria for Each File

When analyzing each HTML file, document:

### 1. Content Structure

```
Main Content Location:
- Primary container: [exact selector]
- Parent hierarchy: [body > ... > main]
- Semantic tags used: [main, article, section, etc.]
- Content-specific classes: [.content, .prose, .markdown-body, etc.]
- Content boundaries: [where content starts/ends]
```

### 2. Navigation & UI Elements

```
Elements to Exclude:
- Header/Navigation: [selectors]
- Sidebar: [selectors]
- Footer: [selectors]
- Breadcrumbs: [selectors]
- TOC/Page outline: [selectors]
- Meta information: [selectors]
- Interactive widgets: [selectors]
```

### 3. Special Content Types

```
Within Main Content:
- Code blocks: [how they're marked]
- Callout boxes: [info, warning, tip patterns]
- Tables: [table wrapper classes]
- Images/Media: [figure elements, wrappers]
- Examples/Demos: [interactive elements to preserve]
```

### 4. Page-Specific Observations

```
Page Type: [landing/guide/api/reference]
Unique Patterns: [anything specific to this page]
Potential Issues: [edge cases noticed]
```

## Analysis File Format

Each analysis file (m1f/analysis/html_analysis_N.txt) should follow this format:

```
FILE: [filename]
URL PATH: [relative path]

CONTENT STRUCTURE:
- Main container: [selector]
- Backup selectors: [alternatives if main doesn't work]
- Content confidence: [High/Medium/Low]

EXCLUDE PATTERNS:
- Navigation: [selectors]
- UI Chrome: [selectors]
- Metadata: [selectors]

SPECIAL FINDINGS:
- [Any unique patterns]
- [Edge cases]
- [Warnings]

SUGGESTED SELECTORS:
outermost_selector: "[primary selector]"
ignore_selectors:
  - "[exclude 1]"
  - "[exclude 2]"
  - "[exclude 3]"
```

## Final Output

After analyzing all files and reading the analysis results, create the file
m1f_extract.yml

The file should have the results of you analyses and have this structure:

````yaml
# Complete configuration file for m1f-html2md
# All sections are optional - only include what differs from defaults

# Source and destination paths (usually provided via CLI)
source: ./html
destination: ./markdown

# Extractor configuration
extractor:
  parser: "html.parser"  # BeautifulSoup parser
  encoding: "utf-8"
  decode_errors: "ignore"
  prettify: false

# Conversion options - Markdown formatting preferences
conversion:
  # Primary content selector (use comma-separated list for multiple)
  outermost_selector: "main.content, article.documentation"
  
  # Elements to remove from the content
  ignore_selectors:
    # Navigation (found in X/N files)
    - "nav"
    - ".navigation"
    
    # Headers/Footers (found in X/N files)
    - "header.site-header"
    - "footer.site-footer"
    
    # [Continue with all common exclusions]
  
  strip_tags: ["script", "style", "noscript"]
  keep_html_tags: [] # HTML tags to preserve in output
  heading_style: "atx" # atx (###) or setext (underlines)
  bold_style: "**" # ** or __
  italic_style: "*" # * or _
  link_style: "inline" # inline or reference
  list_marker: "-" # -, *, or +
  code_block_style: "fenced" # fenced (```) or indented
  heading_offset: 0 # Adjust heading levels (e.g., 1 = h1→h2)
  generate_frontmatter: true # Add YAML frontmatter with metadata
  preserve_whitespace: false
  wrap_width: 0 # 0 = no wrapping

# Asset handling configuration
assets:
  download_images: false
  image_directory: "images"
  link_prefix: ""
  process_links: true

# File handling options
file_extensions: [".html", ".htm"]
exclude_patterns: [".*", "_*", "node_modules", "__pycache__"]
target_encoding: "utf-8"

# Processing options
parallel: true # Enable parallel processing
max_workers: 4
overwrite: false # Overwrite existing files

# Synthesis notes (not used by the tool, just for documentation)
notes: |
  Analysis Summary:
  - Analyzed N files representing different page types
  - Primary selector works on X/N files
  - Fallback selectors provide Y% coverage

  Key Findings:
  - [Main pattern discovered]
  - [Secondary pattern]
  - [Edge cases to watch]

  Confidence: [High/Medium/Low] based on consistency across files
````

**CRITICAL REQUIREMENTS**:

1. Complete ALL tasks in the task list sequentially
2. The individual analysis files are crucial for creating an accurate final
   configuration
3. **NEVER use empty strings** ("") as selectors - every selector must have
   actual content
4. **Remove any empty or whitespace-only selectors** from lists before
   outputting
5. **Validate all selectors** are non-empty and properly formatted CSS selectors

**FILE MANAGEMENT**:

- Use Write tool to create analysis files in m1f/analysis/ directory as
  specified
- You may create temporary files if needed for analysis
- **IMPORTANT**: Clean up ALL temporary files you have created
- Only keep the required analysis files: m1f/analysis/html_analysis_1.txt
  through m1f/analysis/html_analysis_N.txt (where N is the number of files
  analyzed)
- Delete any .py, .sh, or other temporary files you create during analysis

======= tools/html2md_tool/prompts/convert_html_to_md.md ======
# Convert HTML to Clean, High-Quality Markdown

## Context:

You are converting scraped documentation HTML to clean Markdown. The HTML may
contain navigation, ads, and other non-content elements that must be excluded.

## Content Extraction Rules:

### INCLUDE:

- Main article/documentation content
- Headings within the content area
- Code blocks and inline code
- Lists (ordered and unordered)
- Tables
- Images with their alt text
- Links (convert to Markdown format)
- Blockquotes
- Important callouts/alerts within content

### EXCLUDE:

- Site navigation (top nav, sidebars, breadcrumbs)
- Headers and footers outside main content
- "Edit this page" or "Improve this doc" links
- Social sharing buttons
- Comment sections
- Related articles/suggestions
- Newsletter signup forms
- Cookie notices
- JavaScript-rendered placeholders
- Meta information (unless part of the content flow)
- Table of contents (unless embedded in content)
- Page view counters
- Advertisements

## Markdown Quality Standards:

### 1. Structure Preservation

- Maintain the original heading hierarchy
- Don't skip heading levels
- Preserve the logical flow of information

### 2. Code Formatting

```markdown
# Inline code

Use `backticks` for inline code, commands, or file names

# Code blocks

​`language code here ​`

# Shell commands

​`bash $ command here ​`
```

### 3. Special Content Types

**API Endpoints:** Format as inline code: `GET /api/v1/users`

**File Paths:** Format as inline code: `/etc/config.yaml`

**Callout Boxes:** Convert to blockquotes with type indicators:

> **Note:** Important information **Warning:** Critical warning **Tip:** Helpful
> suggestion

**Tables:** Use clean Markdown table syntax with proper alignment

### 4. Link Handling

- Convert relative links to proper Markdown: `[text](url)`
- Preserve anchor links: `[Section](#section-id)`
- Remove dead or navigation-only links

### 5. Image Handling

- Use descriptive alt text: `![Description of image](image-url)`
- If no alt text exists, describe the image content
- Skip purely decorative images

## Final Quality Checklist:

- ✓ No HTML tags remaining
- ✓ No broken Markdown syntax
- ✓ Clean, readable formatting
- ✓ Proper spacing between sections
- ✓ Consistent code block language tags
- ✓ No duplicate content
- ✓ No navigation elements
- ✓ Logical content flow preserved

{html_content}

======= tools/html2md_tool/prompts/select_files_from_project.md ======
# Strategic HTML File Selection for CSS Selector Analysis

From the list of available HTML files provided above, select the most
representative files for CSS selector analysis.

## Your Mission:

Select exactly 5 representative HTML files that will give us the BEST insight
into the site's structure for creating robust CSS selectors.

## Selection Strategy:

### 1. Diversity is Key

Choose files that represent different:

- **Sections**: API docs, guides, tutorials, references, landing pages
- **Depths**: Root level, deeply nested, mid-level pages
- **Layouts**: Different page templates if identifiable from paths

### 2. Pattern Recognition

Look for URL patterns that suggest content types:

- `/api/` or `/reference/` → API documentation
- `/guide/` or `/tutorial/` → Step-by-step content
- `/docs/` → General documentation
- `/blog/` or `/changelog/` → Time-based content
- `index.html` → Section landing pages
- Long paths with multiple segments → Detailed topic pages

### 3. Avoid Redundancy

Skip:

- Multiple files from the same directory pattern
- Obviously auto-generated sequences (e.g., /api/v1/method1, /api/v1/method2)
- Redirect or error pages if identifiable

### 4. Prioritize High-Value Pages

Select files that likely have:

- Rich content structure (not just navigation pages)
- Different content layouts
- Representative examples of the site's documentation style

## Output Format:

Return EXACTLY 5 file paths, one per line. No explanations, no formatting, no
numbering. Do not include any text before or after the file paths. Just the file
paths, nothing else.

Example format: docs/getting-started/index.html
api/reference/authentication.html guides/advanced/performance-tuning.html
tutorials/quickstart.html concepts/architecture/overview.html

IMPORTANT: After listing the files, print "FILE_SELECTION_COMPLETE_OK" on the
last line to confirm completion.

======= tools/html2md_tool/prompts/synthesize_config.md ======
# Configuration Synthesis from Individual File Analyses

You have analyzed multiple HTML files individually. Now synthesize their
findings into a unified configuration that will be saved as
`html2md_config.yaml`.

## Your Task

Read the analysis files:

- m1f/analysis/html_analysis_1.txt
- m1f/analysis/html_analysis_2.txt
- m1f/analysis/html_analysis_3.txt
- m1f/analysis/html_analysis_4.txt
- m1f/analysis/html_analysis_5.txt

Based on these analyses, create an optimal YAML configuration that works across
all files.

## Analysis Process

1. **Read all 5 analysis files**
2. **Identify common patterns** across analyses
3. **Find selectors that work on multiple files**
4. **Create prioritized fallback selectors**
5. **Combine all exclusion patterns**

## Output YAML Configuration

Create a YAML configuration in this exact format:

````yaml
# Complete configuration file for m1f-html2md
# All sections are optional - only include what differs from defaults

# Source and destination paths (usually provided via CLI)
source: ./html
destination: ./markdown

# Extractor configuration
extractor:
  parser: "html.parser"  # BeautifulSoup parser
  encoding: "utf-8"
  decode_errors: "ignore"
  prettify: false

# Conversion options - Markdown formatting preferences
conversion:
  # Primary content selector (use comma-separated list for multiple)
  outermost_selector: "main.content, article.documentation"
  
  # Elements to remove from the content
  ignore_selectors:
    # Navigation (found in X/N files)
    - "nav"
    - ".navigation"
    
    # Headers/Footers (found in X/N files)
    - "header.site-header"
    - "footer.site-footer"
    
    # [Continue with all common exclusions]
  
  strip_tags: ["script", "style", "noscript"]
  keep_html_tags: [] # HTML tags to preserve in output
  heading_style: "atx" # atx (###) or setext (underlines)
  bold_style: "**" # ** or __
  italic_style: "*" # * or _
  link_style: "inline" # inline or reference
  list_marker: "-" # -, *, or +
  code_block_style: "fenced" # fenced (```) or indented
  heading_offset: 0 # Adjust heading levels (e.g., 1 = h1→h2)
  generate_frontmatter: true # Add YAML frontmatter with metadata
  preserve_whitespace: false
  wrap_width: 0 # 0 = no wrapping

# Asset handling configuration
assets:
  download_images: false
  image_directory: "images"
  link_prefix: ""
  process_links: true

# File handling options
file_extensions: [".html", ".htm"]
exclude_patterns: [".*", "_*", "node_modules", "__pycache__"]
target_encoding: "utf-8"

# Processing options
parallel: false # Enable parallel processing
max_workers: 4
overwrite: false # Overwrite existing files

# Synthesis notes (not used by the tool, just for documentation)
notes: |
  Analysis Summary:
  - Analyzed N files representing different page types
  - Primary selector works on X/N files
  - Fallback selectors provide Y% coverage

  Key Findings:
  - [Main pattern discovered]
  - [Secondary pattern]
  - [Edge cases to watch]

  Confidence: [High/Medium/Low] based on consistency across files
````

## Selection Criteria

**Primary Content Selector (outermost_selector)**:

- Choose selector that works on most files (80%+ coverage)
- If no single selector works on most, combine multiple with commas
- Prefer semantic selectors (main, article) over class-based
- This goes in conversion.outermost_selector

**Ignore Selectors**:

- Include selectors found in majority of files
- Group by type (navigation, headers, footers, etc.)
- Add comments showing coverage (found in X/N files)

**Critical Requirements**:

1. **NEVER include empty strings** ("") in any selector list
2. **All selectors must be valid CSS selectors**
3. **Remove whitespace-only entries**
4. **Test that primary selector + alternatives provide good coverage**
5. **Ensure ignore selectors don't accidentally exclude wanted content**

Output only the YAML configuration - no additional explanation needed.

IMPORTANT: After outputting the YAML configuration, print
"SYNTHESIS_COMPLETE_OK" on the last line to confirm completion.

======= tools/m1f/prompts/perfect_bundle_prompt.md ======
# Perfect Bundle Creation Prompt for m1f-claude

## 🎯 CREATE PERFECT TOPIC-SPECIFIC BUNDLES FOR THIS PROJECT

============================================================

The basic bundles (complete.txt and docs.txt) have already been created. Now
create additional topic-specific bundles following BEST PRACTICES.

## 📚 REQUIRED READING (IN THIS ORDER):

1. READ: @m1f/m1f.txt for m1f documentation and bundle configuration syntax
2. READ: @m1f/project_analysis_dirlist.txt for directory structure
3. READ: @m1f/project_analysis_filelist.txt for complete file listing

⚠️ IMPORTANT: Read ALL three files above before proceeding!

## 🏆 BEST PRACTICES FOR PERFECT BUNDLES

### 1. MODULAR ARCHITECTURE PRINCIPLE

- Identify each logical module, tool, or subsystem in the project
- Create one bundle per module/tool (e.g., auth-module, payment-module,
  user-module)
- Each module bundle should be self-contained and meaningful

### 2. USE PRECISE INCLUDES, NOT BROAD EXCLUDES

Instead of excluding everything except what you want, use precise includes:

```yaml
# ❌ BAD - Too broad, relies on excludes
sources:
  - path: "."
    excludes: ["tests/", "docs/", "scripts/", "node_modules/"]

# ✅ GOOD - Precise includes
sources:
  - path: "tools/"
    include_extensions: [".py"]
    includes: ["auth/**", "auth.py", "utils.py", "__init__.py"]
```

### 3. BUNDLE GROUPING STRATEGY

Organize bundles into logical groups:

- `documentation` - All documentation bundles
- `source` - Source code bundles by module
- `tests` - Test code bundles
- `config` - Configuration bundles
- `complete` - Aggregated bundles

### 4. NUMBERED OUTPUT FILES

Use numbered prefixes for proper sorting:

```yaml
output: "m1f/project/87_module1_docs.txt"  # Documentation
output: "m1f/project/94_module1_code.txt"  # Source code
output: "m1f/project/95_module2_code.txt"  # Source code
output: "m1f/project/99_complete.txt"      # Complete bundle
```

### 5. HIERARCHICAL BUNDLES

Create aggregated bundles that combine related bundles:

- `all-docs` - Combines all documentation
- `all-tests` - Combines all tests
- `all-frontend` - Combines all frontend code
- `complete` - The ultimate bundle with everything

### 6. SHARED FILES STRATEGY

When files are used by multiple modules (like utils, constants, types):

- Include them in each relevant module bundle
- This ensures each bundle is self-contained

## 🔍 PROJECT ANALYSIS STEPS

### STEP 1: Identify Project Architecture

Analyze the directory structure to find:

- Monorepo with packages? → Create bundle per package
- Multiple apps/services? → Create bundle per app
- Modular architecture? → Create bundle per module
- Plugin/Extension system? → Create bundle per plugin
- Frontend/Backend split? → Create bundles for each

### STEP 2: Find Logical Boundaries

Look for natural boundaries in the code:

- Directory names that indicate modules (auth/, payment/, user/)
- File naming patterns (auth.service.ts, auth.controller.ts)
- Configuration files that define modules
- Import patterns that show dependencies

### STEP 3: Design Bundle Hierarchy

Plan your bundles in this order:

1. Module/tool-specific bundles (most granular)
2. Category bundles (tests, docs, config)
3. Aggregated bundles (all-docs, all-frontend)
4. Complete bundle (everything)

## 📝 BUNDLE CREATION RULES

### NAMING CONVENTIONS

- Use lowercase with hyphens: `user-service`, `auth-module`
- Be descriptive but concise
- Group prefix when applicable: `frontend-components`, `backend-api`

### OUTPUT FILE PATTERNS

```
m1f/{project_name}/
├── 80-89_*_docs.txt     # Documentation bundles
├── 90-93_*_config.txt   # Configuration bundles
├── 94-98_*_code.txt     # Source code bundles
└── 99_*_complete.txt    # Complete/aggregated bundles
```

### SOURCES CONFIGURATION

Always use the most specific configuration:

```yaml
sources:
  - path: "src/modules/auth"
    include_extensions: [".ts", ".js"]
    includes: ["**/*.service.ts", "**/*.controller.ts"]
  - path: "src/shared"
    includes: ["auth-utils.ts", "auth-types.ts"]
```

## 🚨 CRITICAL RULES - MUST FOLLOW

1. **NO DEFAULT EXCLUDES**: Don't exclude node_modules, .git, **pycache**, etc.
2. **NO BINARY/ASSET BUNDLES**: Skip images, fonts, compiled files
3. **MAX 20 BUNDLES**: Including existing complete and docs
4. **USE INCLUDES OVER EXCLUDES**: Be precise about what to include
5. **SELF-CONTAINED BUNDLES**: Each bundle should be useful standalone

## 🎯 IMPLEMENTATION CHECKLIST

□ Read all three required files completely □ Identify the project's modular
structure □ Plan bundle hierarchy (modules → categories → aggregated) □ Design
precise `includes` patterns for each bundle □ Use numbered output files for
sorting □ Group bundles logically □ Create aggregated bundles where valuable □
Keep total count under 20 bundles □ Use MultiEdit to add all bundles at once

## 💡 EXAMPLE PATTERNS TO RECOGNIZE

### For a Multi-Service Project:

```yaml
bundles:
  # Service-specific bundles
  auth-service:
    group: "services"
    output: "m1f/project/94_auth_service.txt"
    sources:
      - path: "services/auth"
        include_extensions: [".js", ".ts"]
      - path: "shared"
        includes: ["auth/**", "types/auth.ts"]

  user-service:
    group: "services"
    output: "m1f/project/95_user_service.txt"
    sources:
      - path: "services/user"
        include_extensions: [".js", ".ts"]
      - path: "shared"
        includes: ["user/**", "types/user.ts"]
```

### For a Plugin-Based System:

```yaml
bundles:
  plugin-core:
    group: "core"
    output: "m1f/project/94_plugin_core.txt"
    sources:
      - path: "core"
        include_extensions: [".py"]
      - path: "plugins"
        includes: ["__init__.py", "base.py"]

  plugin-auth:
    group: "plugins"
    output: "m1f/project/95_plugin_auth.txt"
    sources:
      - path: "plugins/auth"
      - path: "core"
        includes: ["plugin_utils.py"]
```

## ⚡ FINAL STEPS

1. Analyze the project structure deeply
2. Design bundles that reflect the project's architecture
3. Use precise includes to create focused bundles
4. Test your mental model: "Would each bundle be useful alone?"
5. Create the configuration with MultiEdit

Remember: The goal is bundles that are **modular**, **focused**, and
**self-contained**!

======= tools/m1f/prompts/segmentation_prompt.md ======
# 🎯 CREATE PERFECT TOPIC-SPECIFIC BUNDLES FOR THIS PROJECT

The basic bundles (complete.txt and docs.txt) have already been created. Now
create additional topic-specific bundles following BEST PRACTICES.

📚 REQUIRED READING (IN THIS ORDER):

1. READ: @m1f/m1f.txt for m1f documentation and bundle configuration syntax
2. READ: @m1f/project_analysis_dirlist.txt for directory structure
3. READ: @m1f/project_analysis_filelist.txt for complete file listing

⚠️ IMPORTANT: Read ALL three files above before proceeding!

🏆 BEST PRACTICES FOR PERFECT BUNDLES:

1. **SIZE GUIDELINES** - Optimize for different use cases!
   - Claude Code: Ideally under 180KB per bundle for best performance
   - Claude AI: Ideally under 5MB per bundle
   - Complete/full bundles can be larger (even 40MB+) for comprehensive analysis
   - Split large topics into focused bundles when targeting specific tasks

2. **MODULAR ARCHITECTURE** - One bundle per logical module/tool/service

3. **USE PRECISE INCLUDES** - Don't exclude everything except what you want!
   Instead, use precise 'includes' patterns:

   ```yaml
   sources:
     - path: "src/auth"
       include_extensions: [".ts", ".js"]
     - path: "shared"
       includes: ["auth-utils.ts", "auth-types.ts"]
   ```

   For documentation chapters/sections:

   ```yaml
   sources:
     - path: "src" # Use "src" not "src/"
       includes: ["ch04-*.md", "chapter-04/*.md"]
     - path: "." # Use "." for root directory
       includes: ["README.md", "CONTRIBUTING.md"]
   ```

4. **HIERARCHICAL NAMING** - Use category-number-topic pattern:
   - api-01-core-basics
   - api-02-core-advanced
   - guide-01-getting-started

5. **ESSENTIAL BUNDLES** - Always include:
   - quick-reference (< 180KB)
   - common-errors (< 180KB)
   - best-practices (< 180KB)

🚨 CRITICAL RULES:

1. FOLLOW SIZE GUIDELINES - Create focused bundles under 180KB for Claude Code
   when possible
2. NO DEFAULT EXCLUDES (node_modules, .git, **pycache**, vendor/ already
   excluded)
3. NO IMAGE/BINARY BUNDLES
4. MAXIMUM 30-40 bundles (more granular = better for targeted AI assistance)
5. Each bundle should be SELF-CONTAINED and appropriately sized for its purpose
6. ALWAYS TEST YOUR PATHS - Verify directories exist before adding to config
7. USE RELATIVE PATHS from project root (not absolute paths)

📋 ALREADY CREATED BUNDLES:

- complete: Full project bundle
- docs: All documentation files

🔍 PROJECT ANALYSIS STEPS:

STEP 1: Identify Architecture Type

- Monorepo? → Bundle per package
- Multi-app? → Bundle per app + shared bundles
- Plugin system? → Bundle per plugin + core
- Modular? → Bundle per module

STEP 2: Find Natural Boundaries Look for:

- Directory names indicating modules (auth/, user/, payment/)
- Plugin/theme directories (wp-content/plugins/_, wp-content/themes/_)
- Feature boundaries (admin/, public/, includes/)

STEP 3: Design Bundle Hierarchy

1. Module-specific bundles (most granular)
2. Category bundles (all-tests, all-docs)
3. Aggregated bundles (all-frontend, all-backend)
4. Complete bundle (everything)

📊 PROJECT ANALYSIS SUMMARY:

- Project Type: {project_type}
- Languages: {languages}
- Total Files: {total_files}

**Main Code Directories:** {main_code_dirs}

📝 **User-Provided Project Information:**

- **Description:** {user_project_description}
- **Priorities:** {user_project_priorities}

Please take the user's description and priorities into account when creating
bundles. For example:

- If performance is a priority, create focused performance-critical code bundles
- If security is important, create security-related bundles (auth, validation,
  etc.)
- If documentation is key, create more granular documentation bundles
- If maintainability matters, organize bundles by architectural layers

📝 IMPLEMENTATION APPROACH:

Example for optimal bundle sizes:

```yaml
# For API documentation (split to stay under 180KB)
api-01-core-options:
  description: "Core API - Options API"
  output: "m1f/api-01-core-options.txt"
  sources:
    - path: "src/api"
      includes: ["options-*.md"]

api-02-core-reactivity:
  description: "Core API - Reactivity system"
  output: "m1f/api-02-core-reactivity.txt"
  sources:
    - path: "src/api"
      includes: ["reactivity-*.md"]

# Quick reference bundle
quick-reference:
  description: "Quick reference and cheat sheet"
  output: "m1f/quick-reference.txt"
  sources:
    - path: "docs"
      includes: ["cheatsheet.md", "quick-*.md"]
    - path: "."
      includes: ["README.md"]

# Common errors bundle
common-errors:
  description: "Common errors and solutions"
  output: "m1f/common-errors.txt"
  sources:
    - path: "docs"
      includes: ["errors/*.md", "troubleshooting.md"]
```

⚡ ACTION PLAN:

1. Read all required files thoroughly
2. VERIFY PATHS: Check project_analysis_dirlist.txt to ensure all paths exist
3. Estimate content sizes and plan bundles based on purpose
4. Design bundles with PRECISE INCLUDES (not broad excludes)
5. Use hierarchical naming (category-number-topic)
6. Create essential bundles (quick-ref, errors, best-practices)
7. Keep focused task bundles under 180KB for Claude Code when practical
8. Add all bundles with MultiEdit in one operation

⚠️ COMMON MISTAKES TO AVOID:

- Don't use paths like "dot" when you mean "."
- Don't create bundles for non-existent directories
- Don't forget to check if files actually exist in the paths
- Don't use absolute paths like "/home/user/project"
- Don't create bundles smaller than 10KB (they likely have path errors)

Remember: Each bundle should answer "What would I need to understand this
module?" - size appropriately based on the use case!

======= tools/m1f/prompts/verification_prompt.md ======
# 🔍 VERIFY AND IMPROVE M1F CONFIGURATION

Your task is to verify the .m1f.config.yml that was just created and improve it
if needed.

📋 VERIFICATION CHECKLIST:

1. **Read .m1f.config.yml** - Check the current configuration
2. **Check Generated Bundles** - Look in m1f/ directory for .txt files
3. **Verify Bundle Quality**:
   - Are focused/task bundles ideally under 180KB for Claude Code usage?
   - Are larger reference bundles under 5MB for Claude AI?
   - Complete/full bundles can be larger - that's OK!
   - Do they contain the expected content?
   - Are there any errors or warnings?
4. **Test a Bundle** - Read at least one generated bundle (e.g.,
   @m1f/{project_name}\_complete.txt)
5. **Check for Common Issues**:
   - Redundant excludes (node_modules, .git, etc. are auto-excluded)
   - Missing important files
   - Bundles that are too large or too small
   - Incorrect separator_style (should be Standard or omitted)
   - Wrong sources format (should use 'sources:' array, not 'source_directory:')

🛠️ IMPROVEMENT ACTIONS:

If you find issues:

1. **Fix Configuration Errors** - Update .m1f.config.yml
2. **Optimize Bundle Organization** - Better grouping or splitting
3. **Add Missing Bundles** - If important areas aren't covered
4. **Remove Redundant Bundles** - If there's too much overlap
5. **Fix Size Issues** - Split large bundles or combine small ones

📝 SPECIFIC CHECKS:

1. Run: `ls -lah m1f/` to see all generated bundles and their sizes
2. SIZE GUIDELINES:
   - Task-focused bundles: Ideally < 180KB for Claude Code
   - Reference bundles: Ideally < 5MB for Claude AI
   - Complete/full bundles: Can be much larger (40MB+ is fine)
   - TOO SMALL: Bundles under 10KB likely have configuration errors
3. Check for m1f-update errors in the output above
4. Read the complete bundle (e.g., @m1f/{project_name}\_complete.txt) to verify
   content inclusion
5. Ensure each bundle serves a clear, distinct purpose
6. CRITICAL: Check for bundles under 10KB - these often indicate:
   - Wrong file paths in includes
   - Non-existent directories
   - Incorrect glob patterns Action: Remove these bundle sections from the
     config!

⚠️ SIZE OPTIMIZATION GUIDELINES: For bundles intended for Claude Code that
exceed 180KB:

1. Consider splitting into smaller, more focused bundles
2. Use more specific includes patterns
3. Create sub-bundles for large topics (e.g., api-core-1, api-core-2) Note: This
   is a guideline - some bundles naturally need to be larger!

📊 PROJECT CONTEXT:

- Type: {project_type}
- Languages: {languages}
- Total Files: {total_files}

🎯 EXPECTED OUTCOME:

After verification:

1. The .m1f.config.yml should be optimal for this project
2. All bundles should generate without errors
3. Each bundle should be appropriately sized for its purpose:
   - Task-focused bundles: Ideally < 180KB for Claude Code
   - Reference bundles: Ideally < 5MB for Claude AI
   - Complete bundles: Any size that captures the full scope
4. The configuration should follow all best practices

If everything looks good, just confirm. If improvements are needed, make them!

📈 SIZE OPTIMIZATION STRATEGIES:

For bundles that are too large:

```yaml
# Instead of this (too large):
api-documentation:
  sources:
    - path: "docs/api"

# Do this (split by topic):
api-01-authentication:
  sources:
    - path: "docs/api"
      includes: ["auth*.md", "login*.md", "session*.md"]

api-02-data-models:
  sources:
    - path: "docs/api"
      includes: ["models/*.md", "schema*.md"]

api-03-endpoints:
  sources:
    - path: "docs/api"
      includes: ["endpoints/*.md", "routes*.md"]
```

For bundles that are too small (<10KB):

```yaml
# If you see this in ls -lah output:
# 108   m1f/some-bundle.txt
# 2.1K  m1f/another-bundle.txt

# Check the bundle content:
cat m1f/some-bundle.txt
# Output: "# No files processed from /path/to/nowhere"

# ACTION: Remove the bundle from config:
# DELETE this entire section:
some-bundle:
  description: "..."
  sources:
    - path: "nonexistent/path"  # <-- This path doesn't exist!
```

🔍 FINAL VERIFICATION: After making any changes, run `m1f-update` again and
verify:

1. All bundles generate without errors
2. No bundles are under 10KB (unless intentionally small)
3. Task-focused bundles are ideally under 180KB
4. The configuration follows best practices

⚠️ PATH VERIFICATION CHECKLIST: Before finalizing, double-check:

- All paths in sources exist in the project
- Paths use relative format (e.g., "src/api" not "/home/user/src/api")
- Include patterns match actual files (check with `ls` command)
- No typos in directory names (e.g., "dot" vs ".")

======= tools/scrape_tool/scrapers/README.md ======
# HTML2MD Web Scrapers

This module provides a pluggable architecture for web scraping backends in the
HTML2MD tool.

## Architecture

The scraper system is built around:

- `WebScraperBase`: Abstract base class defining the scraper interface
- `ScraperConfig`: Configuration dataclass for all scrapers
- `create_scraper()`: Factory function to instantiate scrapers
- `SCRAPER_REGISTRY`: Registry of available backends

## Available Scrapers

### BeautifulSoup (`beautifulsoup`, `bs4`)

- **Purpose**: General-purpose web scraping for static sites
- **Features**: Async support, encoding detection, metadata extraction
- **Best for**: Most websites without JavaScript requirements

### HTTrack (`httrack`)

- **Purpose**: Complete website mirroring
- **Features**: Professional mirroring, preserves structure
- **Best for**: Creating offline copies of entire websites
- **Requires**: System installation of HTTrack

## Usage

```python
from tools.html2md.scrapers import create_scraper, ScraperConfig

# Configure scraper
config = ScraperConfig(
    max_depth=5,
    max_pages=100,
    request_delay=0.5,
    user_agent="Mozilla/5.0 ..."
)

# Create scraper instance
scraper = create_scraper('beautifulsoup', config)

# Use scraper
async with scraper:
    # Scrape single page
    page = await scraper.scrape_url('https://example.com')

    # Scrape entire site
    async for page in scraper.scrape_site('https://example.com'):
        print(f"Scraped: {page.url}")
```

## Adding New Scrapers

To add a new scraper backend:

1. Create a new file in this directory (e.g., `playwright.py`)
2. Create a class inheriting from `WebScraperBase`
3. Implement required methods:
   - `scrape_url()`: Scrape a single URL
   - `scrape_site()`: Scrape an entire website
4. Register in `__init__.py`:

   ```python
   from .playwright import PlaywrightScraper

   SCRAPER_REGISTRY['playwright'] = PlaywrightScraper
   ```

## Configuration

All scrapers share common configuration options through `ScraperConfig`:

- `max_depth`: Maximum crawl depth
- `max_pages`: Maximum pages to scrape
- `allowed_domains`: List of allowed domains
- `exclude_patterns`: URL patterns to exclude
- `request_delay`: Delay between requests
- `concurrent_requests`: Number of concurrent requests
- `user_agent`: User agent string
- `timeout`: Request timeout in seconds

Backend-specific options can be added as needed in the scraper implementation.

======= tools/shared/prompts/research/bundle/subtopic_grouping.md ======
# Subtopic Grouping Prompt

Analyze these research results for "{query}" and group them into logical
subtopics.

Content items: {summaries}

Provide a JSON response with this structure: {{
    "subtopics": [
        {{
            "name": "Subtopic Name",
            "description": "Brief description",
            "item_indices": [0, 2, 5]  // indices of items belonging to this subtopic
        }} ] }}

Create 3-7 subtopics that logically organize the content. Each item should
belong to exactly one subtopic. Return ONLY valid JSON, no other text.

======= tools/shared/prompts/research/bundle/topic_summary.md ======
# Topic Summary Prompt

Generate a 1-2 sentence overview of the following resources about "{topic}":

{summaries}

Write a concise summary that captures what these resources collectively offer
about this topic.

======= tools/shared/prompts/research/llm/content_analysis.md ======
# Content Analysis Prompt

Analyze the following content for: "{analysis_type}"

Content: {content}

Provide your analysis in JSON format with appropriate fields based on the
analysis type. For relevance analysis, include a score from 0-10. For other
types, provide structured insights.

Return ONLY valid JSON, no other text.

======= tools/shared/prompts/research/llm/web_search.md ======
# Web Search Prompt

Search for the {num_results} most relevant and high-quality URLs for the
following research query: "{query}"

Requirements:

1. Focus on authoritative sources (documentation, tutorials, research papers,
   reputable blogs)
2. Prioritize recent content when relevant
3. Include a mix of content types (tutorials, references, discussions)
4. Avoid low-quality sources (spam, content farms, outdated information)

Return the results as a JSON array with this format: [ {{ "url":
"https://example.com/article", "title": "Article Title", "description": "Brief
description of the content and why it's relevant" }} ]

Return ONLY the JSON array, no other text.
